\documentclass[leqno]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{seraf}
\usepackage{tikz}
\usepackage{todonotes}\presetkeys{todonotes}{color=blue!20}{}
\usepackage{bbm}
\usepackage{enumerate}
\usepackage{url}
\usepackage{isabelle,isabellesym}

\title{A Formally Verified Proof of the \protect\\ Central Limit Theorem}
\author{Luke Serafin}
%\date{\today}

% theorem environments
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}

\newcommand{\bldset}[2]{\{{#1}\mid{#2}\}}
\newcommand{\bldseq}[2]{\langle{#1}\mid{#2}\rangle}
\renewcommand{\E}{\mathbb E}
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand\sinc{\mathop{\text{sinc}}\nolimits}
\newcommand\Si{\text{Si}}
\newcommand\floor[1]{\lfloor {#1} \rfloor}
\newcommand\sgn{\mathop{\text{sgn}}\nolimits}
\newcommand\osc{\mathop{\text{osc}}\nolimits}

\begin{document}

\maketitle

\begin{abstract}
This thesis describes the results of a collaborative effort to formalize the proof of the central limit theorem of probability theory. That project was carried out in the Isabelle proof assistant, and builds upon and extends the libraries for mathematical analysis, in particular measure-theoretic probability theory. The formalization introduces the notion of weak convergence (or convergence in distribution) required to state the central limit theorem, and uses characteristic functions (Fourier transforms) to demonstrate convergence to the standard normal distribution under the hypotheses of the central limit theorem. Supporting such reasoning motivated significant changes to the measure-theoretic integration libraries of Isabelle.
\end{abstract}

\tableofcontents

\newpage

\section{Introduction}

Consider a toss of a fair coin. If we treat a result of tails as having value zero and a result of heads as having value one, we may treat the coin toss as a random variable, say $X$.\footnote{An intuitive understanding of probabilistic language suffices for the present section; more precise definitions for many concepts will be discussed in section \ref{sec:prelim}.} Thus $X$ is supported on $\{0,1\}$, and
\[ \P(X = 0) = \P(X = 1) = \frac{1}{2}. \]
Hence the expected value of $X$ is
\[ \E(X) = 0 \cdot \P(X = 0) + 1 \cdot \P(X = 1) = \frac{1}{2}. \]

Now suppose we toss the coin repeatedly, thus generating an infinite sequence $\bldseq{X_n}{n \in \N}$ of random variables which are pairwise independent and have the same distribution as $X$. By the strong law of large numbers, the mean $\overline X_n = \frac{1}{n} \sum_{i \le n} X_i$ converges almost surely to $\E(X) = \frac{1}{2}$. But clearly after a finite number of trials there is a nonzero probability that the value of $\overline X_n$ will differ from $\E(X)$. In fact, for $n$ odd the probability of deviation is $1$, because in that case it is impossible for $\frac{1}{n} \sum_{i \le n} X_i$ to have the value $\frac{1}{2}$ at any element of the sample space. Nevertheless $|\overline X_n - \E(X)|$ must converge to zero, and so the probability of large deviations of the mean $\overline X_n$ from the expected value $\E(X)$ is small. Exactly how small is made precise by De Moivre's central limit theorem.

In 1733 De Moivre privately circulated a proof\footnote{This historical information is drawn from \cite{fischer}, and references to original works may be found there.} which, in modern terminology, shows that $n^{-1/2} \overline X_n$ converges to a normal distribution. This material was later published in the 1738 second edition of his book {\em The Doctrine of Chances,} the first edition of which was first published in 1712 and is widely regarded as the first textbook on probability theory. De Moivre also considered the case of what we might call a biased coin (an event which has value one with probability $p$ and zero with probability $1-p$, for some $p \in (0,1)$), and realized that his convergence theorem continues to hold in that case.

De Moivre's result was generalized by Laplace in the period between about 1776 and 1812 to sums of random variables with various other distributions. For example, in 1776 Laplace proved that $n^{-1/2} \overline X_n$ converges to a normal distribution in the case where the $X_n$'s are uniformly distributed. The particular problem Laplace considered in that paper was finding the distribution of the average inclination of a random sample of comets, the distribution for a single comet being assumed uniform between $0^\circ$ and $90^\circ$. Over the next three decades Laplace developed the conceptual and analytical tools to extend this convergence theorem to sums of independent identically distributed random variables with ever more general distributions, and this work culminated in his treatise {\em Th\'eorie analytique des probabilit\'es}. This included the development of the method of characteristic functions to study the convergence of sums of random variables, a move which firmly established the usefulness of analytic methods in probability theory (in particular Fourier analysis, the characteristic function of a random variable being exactly the Fourier transform of that variable).

Laplace's theorem, which later became known as the central limit theorem (a designation due to P\'olya and stemming from its importance both in the theory and applications of probability), states in modern terms that the normalized sum of a sequence of independent and identically distributed random variables with finite, nonzero variance converges to a normal distribution. All of this imprecise language will be made precise later on. In the work of Laplace all the main ingredients of the proof of the central limit theorem are present, though of course the theorem was refined and extended as probability underwent the radical changes necessitated by its move to measure-theoretic foundations in the first half of the twentieth century.

Gauss was one of the first to recognize the importance of the normal distribution to the estimation of measurement errors, and it is notable that the usefulness of the normal distribution in this context is largely a consequence of the central limit theorem, for errors occurring in practice are frequently the result of many independent factors which sum to an overall error in a way which can be regarded as approximated by a sum of independent and identically distributed random variables. The normal distribution also arose with surprising frequency in a wide variety of empirical contexts: from the heights of men and women to the velocities of molecules in a gas. This gave the central limit theorem the character of a natural law, as seen in the following poetic quote from Sir Francis Galton in 1889 \cite{galton}:
\begin{quote}
 I know of scarcely anything so apt to impress the imagination as the wonderful form of cosmic order expressed by the ``Law of Frequency of Error.'' The law would have been personified by the Greeks and deified, if they had known of it. It reigns with serenity and in complete self-effacement, amidst the wildest confusion. The huger the mob, and the greater the apparent anarchy, the more perfect is its sway. It is the supreme law of Unreason. Whenever a large sample of chaotic elements are taken in hand and marshaled in the order of their magnitude, an unsuspected and most beautiful form of regularity proves to have been latent all along.
\end{quote}
Many more details on the history of the central limit theorem and its proof can be found in \cite{fischer}.

Standards of rigour have evolved a great deal over the course of the history of the central limit theorem, and around the turn of the twentieth century a completely precise notion of proof, developed by Frege, Russell, and many others, finally became available to mathematicians. Actually writing proofs which conform to the precise requirements of this notion did not become the new norm of mathematical practice, however, largely because it is impractical for human mathematicians to work at that level of formal detail. The burden of writing an entirely precise proof in first-order logic (say) simply does not offer sufficient gain for a human mathematician to undertake it. However, advances in automated computing technology around the middle of the twentieth century quickly progressed to the point where a computer could be programmed to take on the cumbersome burden of verifying all the details of a proof which a human outlined at a high level. This is the domain of interactive theorem proving.

One significant mathematical result to be verified using an interactive proof assistant was the prime number theorem, formalized between 2003 and 2004 at Carnegie Mellon University by Jeremy Avigad, Kevin Donnelly, David Gray, and Paul Raff. Thoughts on that formalization, which was carried out with the Isabelle proof assistant, are recorded in \cite{avigad-etal-pnt}. Though the prime number theorem is traditionally considered a landmark result of analytic number theory, it should be noted that the proof formalized by Avigad and collaborators did not employ complex analysis, but was rather the elementary proof of Selberg \cite{selberg-pnt}, using results and methods due to Erd{\H{o}}s. Thus the proof of the prime number theorem demonstrated that significant mathematical results could be formalized quite effectively in Isabelle, but did not provide a test of the usefullness of Isabelle for formalizing results based on deep theory. In 2009 John Harrison published a formalization of an analytic proof of the prime number theorem \cite{harrison-pnt}.

When the author approached Avigad seeking a research project, Avigad saw an opportunity to carry out in Isabelle a formalization relying on deep analytical theory, and suggested that the author help develop Isabelle's integration libraries by choosing an interesting result to formalize. The author's choice was the central limit theorem, often abbreviated CLT.

A theorem which both played a fundamental role in the development of modern probability theory and has far-reaching applications seemed to us a perfect candidate for formalization, especially because the measure-theoretic libraries of Isabelle are still under active development and we saw an opportunity to contribute to them by formalizing the characteristic function arguments used to prove the CLT. The formalization was completed between 2011 and 2013, and improvements to the proof scripts are ongoing. The formalization was a joint effort between Jeremy Avigad, Johannes H\"olzl (Technische Universit\"at M\"unchen), and the author. A preliminary report \cite{prelim} was written by all three collaborators and presented at the Vienna Summer of Logic by H\"olzl.
All the proof scripts from our formalization which have not yet been moved into Isabelle's libraries are found at \url{https://github.com/avigad/isabelle}.

The fact that our effort to formalize the central limit theorem succeeded in a few months of dedicated formalization effort (interspersed among longer stretches of slower progress) testifies to the maturity of the analysis and measure theory libraries in Isabelle, though of course much remains to be added and many improvements are possible.

Here is the result we verified in Isabelle:

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ prob{\isacharunderscore}space{\isacharparenright}\ central{\isacharunderscore}limit{\isacharunderscore}theorem{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ X\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isasymmu}\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isasymsigma}\ {\isacharcolon}{\isacharcolon}\ real\ \isakeyword{and}\isanewline
\ \ \ \ S\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\isanewline
\ \ \ \ X{\isacharunderscore}indep{\isacharcolon}\ {\isachardoublequoteopen}indep{\isacharunderscore}vars\ {\isacharparenleft}{\isasymlambda}i{\isachardot}\ borel{\isacharparenright}\ X\ UNIV{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}integrable{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ integrable\ M\ {\isacharparenleft}X\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}mean{\isacharunderscore}{\isadigit{0}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ expectation\ {\isacharparenleft}X\ n{\isacharparenright}\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isasymsigma}{\isacharunderscore}pos{\isacharcolon}\ {\isachardoublequoteopen}{\isasymsigma}\ {\isachargreater}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}square{\isacharunderscore}integrable{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ integrable\ M\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ {\isacharparenleft}X\ n\ x{\isacharparenright}\isactrlsup {\isadigit{2}}{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}variance{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ variance\ {\isacharparenleft}X\ n{\isacharparenright}\ {\isacharequal}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}distrib{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ distr\ M\ borel\ {\isacharparenleft}X\ n{\isacharparenright}\ {\isacharequal}\ {\isasymmu}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{defines}\isanewline
\ \ \ \ {\isachardoublequoteopen}S\ n\ {\isasymequiv}\ {\isasymlambda}x{\isachardot}\ {\isasymSum}i{\isacharless}n{\isachardot}\ X\ i\ x{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\isanewline
\ \ \ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ distr\ M\ borel\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ S\ n\ x\ {\isacharslash}\ sqrt\ {\isacharparenleft}n\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isacharparenright}\ \isanewline
\ \ \ \ \ \ \ \ {\isacharparenleft}density\ lborel\ std{\isacharunderscore}normal{\isacharunderscore}density{\isacharparenright}{\isachardoublequoteclose}
\end{isabellebody}

\medskip

At the time of writing the full proof document is 4499 lines, which is 98 pages after processing with Isabelle's \LaTeX\ facilities. This excludes a large amount of library development which has already been moved to HOL-Probability, but is still dramatically shorter than the proof of the prime number theorem, which excluding previously developed library material and a proof of the law of quadratic reciprocity was still in the neighborhood of 500 pages, or 22,300 lines \linebreak (\cite{avigad-etal-pnt}, p. 8). The fact that the relatively deep measure-theoretic proof of the central limit theorem can be successfully formalized with such comparatively little library augmentation testifies to the maturity of the analysis libraries in Isabelle.

\section{Probabilistic Prelimilaries} \label{sec:prelim}

Readers familiar with the basics of measure-theoretic probability theory may wish to skip to the next section, though this section still serves to establish notation. Readers lacking this background will find a brief introduction here, just sufficient to give an idea of what concepts are behind the proof of the central limit theorem in the next section. Those who wish to learn the measure-theoretic foundations of probability theory should consult a standard work on the subject, such as \cite{billingsley}.

\subsection{Measure Spaces}

We begin with an explication of the idea of a measure. It is intuitively obvious that some sets of points have a definite ``size:'' A line segment has a length, a circle has an area, a cone has a volume, etc. The notion of a measure is intended to make precise this intuitive notion of the ``size'' of a set. We shall see later how probabilities are interpreted in terms of measures.

\begin{definition}
Let $X$ be a set, and $\Sigma \subseteq X$ be a collection of subsets of $X$ which contains $\emptyset$ and is closed under complements and countable unions (from which it immediately follows that $X \in \Sigma$ and that $\Sigma$ is closed under countable intersections). A {\em measure} on $\Sigma$ (often simply called a measure on $X$ when the intended collection $\Sigma$ is clear from the context) is a function $\mu\colon \Sigma \rightarrow [0, \infty]$ with the property that $\mu(\emptyset) = 0$ and which is countably additive, which means that for every pairwise disjoint collection $\bldset{A_n}{n \in \N}$ of elements of $\Sigma$,
\[ \mu\left(\bigcup_{n = 0}^\infty A_n\right) = \sum_{n=0}^\infty \mu(A_n). \]
\end{definition}

For $A \in \Sigma$ as in the definition, the value $\mu(A)$ is called the {\em measure} of $A$ and corresponds to the intuitive notions of size, length, area, volume, etc. Note that the measure of a set may be infinite; indeed, if $\mu$ is a measure on $\R$ such that $\mu(n, n+1] = 1$ for $n \in \N$ (as should be the case if $\mu$ measures the length of intervals), it is immediate from the definition of a measure that $\mu(\R) = \infty$.

A collection $\Sigma$ of subsets of a set $X$ satisfying the hypothesis in the above definition (i.e. containing $\emptyset$ and closed under complements and countable unions) is called a $\sigma$-algebra. The elements of $\Sigma$ are called the {\em measurable sets,} and a set with an associated $\sigma$-algebra but no associated measure is called a {\em measurable space.} 

One might ask why a measure should not determine a size for every subset of $X$; one important reason is that there is no translation-invariant measure $\mu$ on $\R$ which assigns intervals the expected length (i.e. $\mu [a,b] = b - a$ for $a < b$) and is defined for all subsets of $\R$. A measure $\mu$ on $\R$ is called {\em translation-invariant} iff for every measurable $A \subseteq \R$ and every $x \in \R$, $\mu(A + x) = \mu(A)$, where $A + x$, the translate of $A$ by $x$, is $\bldset{a + x}{a \in A}$. 

Suppose now for contradiction that $\mu$ is a translation-invariant measure on $\R$ which measures all subsets of $\R$ (so the measurable space on which $\mu$ is defined is $(\R, \mathcal P(\R))$, where $\mathcal P(\R)$ is the powerset of $\R$) and satisfies $\mu [a,b] = b - a$ for $a < b$. Consider the equivalence relation $\sim$ on $\R$ defined by $x \sim y$ iff $|x - y| \in \Q$. Because the rationals are dense in $\R$ it is clear that each equivalence class contains an element of the closed unit interval. Using the axiom of choice, select one element of the intersection of each equivalence class with $[0,1]$ (this use of the axiom of choice is essential; there are models of set theory in which there exists a translation-invariant measure $\lambda$ defined for all subsets of $\R$ and assigning to intervals the expected length). Denote this collection by $V = \bldset{r_\alpha}{\alpha \in I}$, where $I$ is some index set. Enumerate the rationals in $[-1,1]$ as $\bldset{q_n}{n \in \N}$, and for each $n$ define $V_n = V + q_n$. Since $\mu$ is translation-invariant, all elements of the collection $\bldset{V_n}{n \in \N}$ receive the same measure. Let $E = \bigcup_{n \in \N} V_n$; it is clear from the definition of the $V_n$'s that $[0,1] \subseteq E \subseteq [-1,2]$. Furthermore, it is an immediate consequence of countable (in this case finite) additivity that for any measure $\nu$ on any space, if $A$ and $B$ are measurable and $A \subseteq B$, then $\nu(A) \le \nu(B)$ (note $B = A \cup (B \setminus A)$ and this union is disjoint). Hence because $\mu$ assigns intervals their expected length, we have $1 \le \mu(E) \le 3$. However, by countable additivity

\[ \mu(E) = \mu\left(\bigcup_{n=0}^\infty V_n\right) = \sum_{n=0}^\infty \mu(V_n). \]

Since $\mu(V_n)$ is the same for all $n$, the sum on the right is infinite if it is not zero, and we have obtained a contradiction. This counterexample is due to Vitali \cite{vitali}.

The standard solution to the nonexistence problem noted in the preceding paragraph is to restrict which sets are assigned measures---hence the $\sigma$-algebra $\Sigma$ in the definition of a measure. This allows ``bad'' sets such as $V$ from the counterexample to be excluded from receiving a measure, and is essential to a useful theory of measure.

Since measures extend the notion of length of intervals, it is natural to suppose that all intervals should be measurable (let us say open intervals, for definiteness). If all open intervals are measurable, then all sets in the $\sigma$-algebra generated by the open intervals---the intersection of all $\sigma$-algebrae containing all the open intervals, an object which is easily verified to be a $\sigma$-algebra---must also be meaurable. The $\sigma$-algebra generated by all open intervals in $\R$ is called the {\em Borel} $\sigma$-algebra on $\R$, and more generally for any topological space the associated Borel $\sigma$-algebra is the $\sigma$-algebra generated by the open sets. Most measures encountered in our formalization are Borel measures, that is, measures defined on the Borel $\sigma$-algebra.

A note regarding limits: For a sequence $\bldseq{a_n}{n \in \N}$ of real numbers or real-valued functions, the notation $a_n \rightarrow a$ is used to indicate the sequence converges (in a sense which should be clear from the context) to the limit $a$. $a_n \uparrow a$ and $a_n \downarrow a$ indicate the convergence is monotone in the obvious direction. For $\bldseq{A_n}{n \in \N}$, $A_n \uparrow A$ indicates $\bigcup_{n \in \N} A_n = A$ and $A_n \subseteq A_{n+1}$ for each $n$, while $A_n \downarrow A$ indicates $\bigcap_{n \in \N} A_n = A$ and $A_{n+1} \subseteq A_n$ for each $n$. It is an easy consequence of countable additivity that if each $A_n$ and $A$ are measurable subsets of some measure space $(X, \Sigma, \mu)$ and $A_n \uparrow A$, then $\mu(A_n) \uparrow \mu(A)$, and similarly if $A_n \downarrow A$ then $\mu(A_n) \downarrow A$. These are called the upward and downward continuity of the measure $\mu$, respectively.

There is a unique Borel measure $\lambda$ on $\R$, called Lebesgue measure, which assigns to each interval the expected length: $\lambda [a,b] = b - a$ for $a < b$. As expected, this measure has the property that $\lambda \{x\} = 0$ for any single real $x$: Note that $[x - 1/n, x + 1/n] \downarrow \{x\}$, and so $\lambda \{x\} = \lim_{n \rightarrow \infty} 2/n = 0$. A set with measure zero is called {\em null}. In general, if $\mu$ is a measure on a measurable space $(X, \Sigma)$, $x \in X$, and $\mu \{x\} = 0$, $x$ is called a continuity point of $\mu$. It is possible in general for there to be singletons of positive measure; if $\mu \{x\} > 0$, $x$ is called an atom of $\mu$. A measure is called continuous just in case it has no atoms.

\medskip

How does all this talk of measures relate to probability? Well, in probability theory, one wishes to assign probabilities to events. The probability that a fair coin turns up heads should be $\frac{1}{2}$, the probability that a randomly selected element of the unit interval $[0,1]$ is between $\frac{1}{3}$ and $\frac{2}{3}$ should be $\frac{1}{3}$, etc. How can these events be modelled formally? Let $\Omega$ be the set of all possible states of the world (or simply the set of all possible worlds, if one is of a philosophical bent); an event is simply a collection of such states (namely the collection where the event occurs). Thus for the toss of a fair coin we may take $\Omega = \{H, T\}$, where $H$ is a world where the coin turns up heads, and $T$ a world where it turns up tails. The event that the coin turns up heads is simply $\{H\}$. Similarly, for randomly selecting an element of the unit interval we may take $\Omega = [0,1]$, $\omega \in \Omega$ being a world where the selected element is $\omega$. The event that the selected number is between $\frac{1}{3}$ and $\frac{2}{3}$ is then simply $(\frac{1}{3}, \frac{2}{3})$. The space $\Omega$ is called the {\em sample space} in probability theory.

It is intuitively clear that the probability of the impossible event $\emptyset$ is zero, and that the probability of a union of disjoint events should be the sum of their probabilities. It is therefore reasonable to suppose probability determines a measure, $\P$, on some collection of events (which we might consider ``observable''). Vacuously $\emptyset$ is observable, and it is clear that if an event $E$ is observable then so should be its complement, and that if events $\bldset{E_n}{n \in \N}$ are observable then so should be their union. Thus the collection of observable events should be a $\sigma$-algebra. It should be noted that in probability theory, the term ``event'' is generally reserved for what we have termed ``observable event,'' and we shall follow this convention in the sequel.

Measures determined by probabilities of events are naturally called {\em probability measures.} An important feature of such measures, and indeed the sole criterion in the mathematical definition of a probability measure, is that $\P(X) = 1$. Probabilities cannot be arbitrarily large, and it is assumed to be certain that something in the sample space is the true state of the world (so the sample space is exhaustive). A measure $\mu$ is called {\em finite} iff $\mu(X) < \infty$, and modulo the zero measure the theory of finite measures is the same as the theory of probability measures (any nonzero finite measure $\mu$ can be scaled by $\frac{1}{\mu(X)}$ to obtain a probability measure).

\subsection{Independent Events}

Consider now tossing two coins successively. It is intuitively clear that the outcome of the first toss does not influence in any way the outcome of the second. Taking the sample space as $\Omega = \{HH, HT, TH, TT\}$ and assigning each singleton event (e.g. $\{HH\}$, the event that both tosses come up heads) equal probability (so $1/4$), the event that the first coin comes up heads is $E_1 = \{HH, HT\}$, while the event that the second comes up heads is $E_2 = \{HH, TH\}$. Note that $\P(E_1) = \P(E_2) = 1/2$, and $\P(E_1 \cap E_2) = \P(\{HH\}) = 1/4 = \P(E_1) \P(E_2)$. It turns out that this multiplicative rule for computing probabilities of intersections is a useful formal explication of the intuitive notion of independence (this can be explained in terms of conditional probabilities; we refer the reader to any elementary account of probability).

\begin{definition}
Let $(\Omega, \mathcal F, \P)$ be a probability space, and $E_1, E_2 \in \mathcal F$. $E_1$ and $E_2$ are {\em independent} (written $E_1 \indep E_2$) iff $\P(E_1 \cap E_2) = \P(E_1) \P(E_2)$.
\end{definition}

For a larger collection $E_1, \ldots, E_n$ of events, we want independence to entail
\[ \P\left(\bigcap_{i=1}^n E_i\right) = \prod_{i=1}^n \P(E_i). \]
Pairwise independence is too weak for this---in tossing a coin twice, the events $\{HH,HT\}$, $\{HH,TH\}$, and $\{HT,TH\}$ are pairwise independent each with probability $1/2$, but their intersection is impossible (empty), and does not have probability $1/8$. We instead use

\begin{definition}
Events $E_1, \ldots, E_n$ are {\em independent} iff
\[ \P\left(\bigcap_{i=1}^n E_i\right) = \prod_{i=1}^n \P(E_i). \]
\end{definition}

This does not generalize directly to an infinite collection of events; the definition employed in that case is

\begin{definition}
A collection $\mathcal E \subseteq \mathcal F$ of events is {\em independent} iff every finite subcollection $\{E_1, \ldots, E_n\} \subseteq \mathcal E$ is independent.
\end{definition}

We spoke earlier of the $\sigma$-algebra of events being the collection of ``observable'' events, and indeed $\sigma$-algebrae are useful for keeping track of information acquired by observation. Roughly, obtaining information about the state of the world can make more events observable. For example, if a coin is flipped twice but the result of the second flip is hidden, the states $HH$, $HT$ and the states $TH$, $TT$ are indistinguishable, and a reasonable $\sigma$-algebra of observable events is $\mathcal F = \{\emptyset, \{HH, HT\},\{TH, TT\}, \{HH, HT, TH, TT\}\}$. If, however, the result of the second flip is revealed, singleton events such as $\{HH\}$ become observable, and the $\sigma$-algebra of observable events should accordingly be expanded to the full powerset of the sample space $\{HH, HT, TH, TT\}$.

If observations are independent, the refined $\sigma$-algebrae they give rise to should also be independent; this is made precise by extending the notion of independence to $\sigma$-algebrae:

\begin{definition}
A collection $\bldset{\mathcal F_\alpha}{\alpha \in I}$ of $\sigma$-algebrae ($I$ an index set of arbitrary cardinality) is {\em independent} iff for each choice of precisely one set $E_\alpha$ from each $\sigma$-algebra $\mathcal F_\alpha$, the collection $\bldset{E_\alpha}{\alpha \in I}$ of events is independent.
\end{definition}

For $\mathcal F$, $\mathcal G$ $\sigma$-algebrae, the notation $\mathcal F \indep \mathcal G$ means of course that $\mathcal F$ and $\mathcal G$ are independent.

\subsection{Random Variables}

Often one wishes to talk about real-valued statistics associated to sample points rather than the sample points themselves; examples include the waiting time for a train, the length of a manufactured screw, or the average height of the Danish population. These can be thought of as functions from the sample space $\Omega$ to the real line $\R$ (or perhaps the extended reals $[-\infty, \infty]$; the bus may {\em never} arrive). In order to be accessible to probability theory, the ``interesting'' events associated with such statistics should be measurable; in particular, for $X$ such a statistic and $a < b$, the preimage $X\inv[(a,b)] = \{\omega \in \Omega\colon a < X(\omega) < b\}$ should be measurable. This is handled by the notion of a measurable function:

\begin{definition}
Let $(X_1, \Sigma_1)$, $(X_2, \Sigma_2)$ be measurable spaces. A function $f\colon X_1 \rightarrow X_2$ is {\em measurable} (with respect to $(\Sigma_1, \Sigma_2)$) iff for every $E \in \Sigma_2$, $f\inv[E] \in \Sigma_1$.
\end{definition}

Note the similarity to the definition of continuity from topology. For $(\Omega, \mathcal F, \P)$ a probability space, a {\em random variable} is simply a measurable function \linebreak $X\colon \Omega \rightarrow \R$, where $\R$ is assumed to be equipped with the $\sigma$-algebra of Borel sets (sometimes the codomain is taken instead as $[-\infty, \infty]$). This makes precise the notion of a probabilistically accessible real-valued statistic on a sample space.

It should be noted that when talking about probabilities and events in the context of random variables, evaluation is often left implicit. For example \linebreak $\P(X > 0)$ is an abusive notation for $\P\bldset{\omega \in \Omega}{X(\omega) > 0}$.

A random variable $X$ induces a probability measure $\mu_X$ on the real line via $\mu_X (A) = \P(X \in A)$; in this case we say $X$ is distributed as $\mu_X$ and write $X \sim \mu_X$.

Events can be viewed as random variables via their indicator functions (called characteristic functions outside probability, the term characteristic function in probability denoting a Fourier transform). In general, for $A \subseteq X$, the indicator function $\mathbbm 1_A$ is the function which has value one at elements of $A$ and zero elsewhere. In case $A$ is a measurable set in a probability space, the indicator function of $A$ is a random variable.

Random variables make precise the notion of an ``observation'' alluded to while discussing independence of $\sigma$-algebrae in the preceding section: one can observe the clock while waiting for the train to arrive, or measure the average height of a random sample drawn from the Danish population, etc. The amount of information that knowing the value of a random variable makes available is determined by the $\sigma$-algebra generated by the random variable, which we now define.

\begin{definition}
Let $X$ be a random variable defined on a probability space $(\Omega, \mathcal F, \P)$. The {\em $\sigma$-algebra generated by $X$}, $\sigma(X)$, is the $\sigma$-algebra generated by the collection of preimages of Borel sets (or equivalently open intervals) under $X$, i.e. $\bldset{X\inv[A]}{A \in \mathcal B}$, where $\mathcal B$ is the collection of Borel subsets of $\R$.
\end{definition}

Note that $\sigma(X)$ is a $\sigma$-algebra on the real line.

Now we can define the notion of independence for random variables:

\begin{definition}
A collection $\bldset{X_\alpha}{\alpha \in I}$ of random variables on a probability space $(\Omega, \mathcal F, \P)$ ($I$ an index set of arbitrary cardinality) is {\em independent} iff the collection $\bldset{\sigma(X_\alpha)}{\alpha \in I}$ is independent.
\end{definition}

Thus random variables $X$, $Y$ are independent (written $X \indep Y$) iff the information obtained by learning each of their values is independent.


\subsection{Integration}

Frequently in applications of probability one is interested in the average value of a random variable, called its expected value. In computing this average, sample points are weighted by their probabilities. For example, if a weighted coin turns up heads with probability $2/3$ and tails with probability $1/3$, and we bet a dollar that it will come up heads (and so gain one dollar if it does and lose one dollar if it doesn't), our expected gain is $(2/3)1 + (1/3)(-1) = 1/3$. For a continuous random variable $X$ (such as the waiting time for a train or the length of a screw), this weighted sum takes the form of a weighted integral, called the integral with respect to a probability measure $\mu$ (the measure on the domain of the random variable) and denoted $\int X \, d\mu$. This integral is over the entire space; sometimes one wishes to take an integral over a subset $A$ of the space (effectively regarding the random variable $X$ as zero outside $A$); this is $\int_A X \, d\mu = \int X \mathbbm 1_A \, d\mu$.

Taking such weighted integrals is by no means limited to random variables; if $(X, \Sigma, \mu)$ is any measure space and $f\colon X \rightarrow \R$, we may consider $\int f \, d\mu$, and $\int_A f \, d\mu$ for any $A \subseteq X$. This general integral with respect to a measure is called the Lebesgue integral; it simultaneously generalizes weighted discrete sums, Riemann integrals, and much more.

Note that the integral of a function may fail to exist; for example, the integral\footnote{Note that for $f\colon X \rightarrow \R$ and $(X,\Sigma,\mu)$ a measure space, $\int f(x) \, \mu(dx)$ denotes the integral of $f$ with respect to $\mu$.} $\int_{[0,\infty)} x \, \lambda(dx)$ is infinite (which may be regarded as having value $\infty$ or being undefined, depending on context), while the integral $\int x \, \lambda(dx)$ does not exist. Functions $f$ for which $\int f \, d\mu < \infty$ (which implicitly assumes this integral exists) are called {\em $\mu$-integrable}, or simply integrable if the measure is clear from the context.

For a full account of Lebesgue integration see \cite{billingsley}. Here we shall briefly outline some properties of integration which will be used later.First, the integral is linear in full generality:
\[ \int (cf + g) \, d\mu = c\int f \, d\mu + \int g \, d\mu \]
for any integrable $f,g\colon X \rightarrow \R$ and any $c \in \R$. Second, the monotone convergence theorem holds: If $\bldseq{f_n}{n \in \N}$ are measurable functions, $f_n\colon X \rightarrow [0,\infty]$ and $f_n \le f_{n+1}$ for each $n$, then the pointwise limit $f$ is measurable, and furthermore
\[ \int f_n \, d\mu \uparrow \int f \, d\mu. \]
Here, the value $\infty$ is allowed for the integrals.
Finally, the dominated convergence theorem holds: If $\int g \, d\mu < \infty$, and $\bldseq{f_n}{n \in \N}$ is a sequence of measurable functions $f_n\colon X \rightarrow \R$, and $|f_n| \le g$ for each $n$, then the pointwise limit $f$ is integrable, and furthermore
\[ \int f_n \, d\mu \rightarrow \int f d\mu. \]
In the special case where $g$ is a constant ($\int g \, d\mu$ exists in this case if its domain is a finite measure space, such as a probability space), this result is called the bounded convergence theorem.

For $X$ a random variable defined on a probability space $(\Omega, \mathcal F, \P)$, the integral $\int X \, d\P$ is called the {\em expected value}, {\em expectation}, or {\em mean} of $X$ and denoted $\E(X)$, while $\E((X - \E(X))^2)$ is called the {\em variance} of $X$. The mean is the ``center of mass'' of the distribution of $X$, while its variance indicates how ``spread out'' the mass of its distribution is.

\subsection{Normal Distributions}

As mentioned in the introduction, the familiar bell-shaped curve of the normal distribution was discovered to arise frequently in empirical investigations involving errors or deviance from the mean, and the central limit theorem largely explains this frequent appearance. To proceed further with reasoning about the central limit theorem, it will of course be necessary to define precisely what such a distribution is. For this we need the notion of the density of a probability measure.

\begin{definition}
Let $f\colon \R \rightarrow \R$ be a function. A Borel measure $\mu$ on $\R$ is said to have {\em density} $f$ (with respect to Lebesgue measure $\lambda$) iff for every Borel set $A$, $\mu(A) = \int_A f \, d\lambda$.
\end{definition}

Not all measures have densities; it is straightforward to verify that a probability measure such that $\mu \{0\} = 1$---a unit mass at zero---has no density. However, normal distributions do have densities, and are most conveniently described in terms of those densities.

\begin{definition}
Let $\mu \in \R$, $\sigma > 0$. The {\em normal distribution} with mean $\mu$ and variance $\sigma^2$, denoted $\mathcal N_{\mu, \sigma^2}$, is the Borel measure with density
\[ \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}. \]
\end{definition}

The reason for labelling the variance of a normal distribution with $\sigma^2$ is that $\sigma$, the square root of the variance, is a quantity of importance in statistics, called the standard deviation. In general, the square root of the variance of a distribution is called its standard deviation, but that quantity will not be of importance to us. Variance is a more convenient quantity for our purposes, because the variance of the sum of two independent random variables is the sum of their variances.

The normal distribution $\mathcal N_{0,1}$ is called the {\em standard normal distribution}. Note that for any normal distribution $\mathcal N_{\mu, \sigma^2}$, $\frac{\mathcal N_{\mu, \sigma^2} - \mu}{\sigma^2}$ is a standard normal distribution. In general, any random variable with finite mean and finite, nonzero variance can be ``normalized'' to a random variable with mean zero and unit variance by subtracting the mean and dividing by the variance; this will be of importance for ensuring convergence to a standard normal distribution in the central limit theorem.

\subsection{Convergence of Random Variables}

Especially in the context of the central limit theorem, one is interested in the convergence of a sequence $\bldseq{X_n}{n \in \N}$ of random variables to a given random variable $X$. Pointwise convergence is generally uninteresting because it often fails on a negligible set of sample points (negligible in the sense that it has measure zero, and so may be safely ignored for most purposes in probability theory); the notion of convergence almost surely (pointwise convergence except on a set of measure zero; called convergence almost everywhere in general probability theory) fixes this problem, but is still a very strong condition. A weaker condition is that for every $\eps > 0$ $\lim_{n \rightarrow \infty} \P(|X_n - X| > \eps) = 0$. Intuitively, this says that the sequence $\bldseq{X_n}{n \in \N}$ eventually becomes very close to $X$ outside a very small (though not necessarily measure zero) set. However, this notion of convergence, called convergence in probability (convergence in measure in general measure theory) is still too strong for the central limit theorem.

For the convergence of the central limit theorem, we want to say that the distribution of the normalized sum of independent random variables with finite, nonzero variance ``resembles more and more'' the standard normal distribution. This is made precise by the notion of convergence in distribution, or weak convergence (weak* convergence in the sense of functional analysis), which will be defined and discussed in the course of our treatment of the formalization of the CLT. Weak convergence of a sequence $\bldseq{X_n}{n \in \N}$ of random variables to a weak limit $X$ is denoted $X_n \Rightarrow X$, and this makes sense also for the distributions of the random variables ($\mu_n \Rightarrow \mu$, where $X_n \sim \mu_n$ and $X \sim \mu$).

\subsection{Convolutions and Characteristic Functions}

\begin{definition}
Let $\mu$, $\nu$ be Borel measures on $\R$. The {\em convolution} $\mu * \nu$ is defined by
\[ (\mu * \nu)(B) = \int \nu(B - x) \mu(dx), \]
where $B \subseteq \R$ is a Borel set and $B - x = \bldset{y - x}{y \in B}$ (which is easily verified to also be a Borel set).
\end{definition}

It turns out that the distribution of the sum of two independent random variables is the convolution of their distributions. More precisely, if $X$ and $Y$ are random variables on a probability space $(\Omega, \mathcal F, \P)$ and $X \sim \mu$ and $Y \sim \nu$, then for any Borel set $B \subseteq \R$,
$\P(X + Y \in B) = (\mu * \nu)(B)$. If $\mu$, $\nu$ have densities $f$, $g$, respectively, then $\mu * \nu$ has density $f * g$, the convolution of the functions $f$ and $g$, which is defined by
\[ (f * g)(x) = \int g(x - t) f(t) \, dt. \]
For proofs of these remarks and more information about convolutions, see \cite{billingsley} or any standard treatment of measure theory.

The notion of a Fourier transform is central to harmonic analysis (see \cite{katznelson} or any standard text on the subject); the {\em Fourier transform} $\hat \mu$ of a measure $\mu$ on $\R$ with the Borel $\sigma$-algebra is given by
\[ \hat \mu (x) = \int e^{itx} \, \mu(dt). \]
In case $\mu$ has density $f$, $\hat \mu$ is also denoted $\hat f$ and called the Fourier transform of $f$. Note that
\[ \hat f(x) = \int e^{ix f(t)} \, dt. \]
In a probabilistic context, the Fourier transform of a random variable or distribution is called its {\em characteristic function}; these will be discussed in more detail in section \ref{sec:char}.

The importance of characteristic functions for the proof of the CLT is largely the fact that weak convergence of a sequence of random variables (or distributions) is equivalent to pointwise convergence of their characteristic functions; this is very useful because pointwise convergence is much easier to work with analytically. Also, for any measures $\mu$, $\nu$ on $\R$ with the Borel $\sigma$-algebra, the Fourier transform of $\mu * \nu$ is simply $\hat \mu \hat \nu$, the pointwise product of $\hat \mu$ and $\hat \nu$. Thus if $X$, $Y$ are independent random variables with characteristic functions $\phi$, $\psi$, respectively, the characteristic function of $X + Y$ is simply $\phi\psi$. This is helpful because pointwise products are in general much easier to work with than convolutions. In particular, the $n$-fold convolution which would arise when computing the distribution of a sum of $n$ independent identically distributed random variables (as occurs in the statement of the central limit theorem) is replaced by the $n$th power of their characteristic functions, a much more approachable object. All this will be discussed more thoroghly in section \ref{sec:char}.

\section{Summary of the Proof} \label{sec:summary}

Before finally diving into the details of the formalization, we pause to give a quick overview of how the proof will succeed. Our model proof for the central limit theorem was that found in Billingsley's classic text {\em Probability and Measure} \cite{billingsley}, and we refer the reader seeking additional details to that excellent work.

As noted in the preliminaries, if $X$ and $Y$ are independent random variables with distributions $\mu$ and $\nu$, respectively, the distribution of their sum is the convolution of their distributions: $X + Y \sim \mu * \nu$. Thus if $\bldseq{X_k}{k \le n}$ is a sequence of independent random variables all with distribution $\mu$, the sum $\sum_{k \le n} X_k$ is distributed as the $n$-fold convolution of $\mu$ with itself. However, this $n$-fold convolution is a technically inconvenient object to work with, and to study the asymptotic distribution of $\sum_{k \le n} X_k$ as $n \rightarrow \infty$, it turns out to be technically advantageous to take Fourier transforms of the random variables, or to put this in probabilistic language, to study their characteristic functions. The advantage of this method of characteristic functions is twofold: first, if $X$ and $Y$ are independent then the characteristic function of $X + Y$ is simply the product of the characteristic function of $X$ and that of $Y$; and secondly, a sequence $\bldseq{X_n}{n \in \N}$ converges in distribution to a random variable $X$ if and only if the corresponding characteristic functions converge pointwise. This is a significant advantage because products are far easier to work with than convolutions, as is pointwise convergence easier than convergence in distribution. This shift of focus from random variables to their characteristic functions is justified by the L\'evy inversion theorem, which entails that two random variables with the same characteristic function have the same distribution.

We can now express the idea of the proof of the central limit theorem: The characteristic function of the average of $n$ independent identically distributed random variables with unit variance is shown to converge pointwise to the characteristic function of the standard normal distribution. The general result for averages of variables with finite nonzero variance can then be deduced by normalizing general variables to have zero mean and unit variance. Proving the case of zero mean and unit variance is reasonably straightforward, though it requires several delicate estimates based on Taylor series and complex variables, all of which require rather tedious formalization. The bulk of the work in our formalization, however, was in supporting the use of characteristic functions to study the distributions of sums of independent random variables, by proving the L\'evy inversion and continuity theorems.

The L\'evy inversion theorem is the result which justifies using characteristic functions to study probability distributions, for it demonstrates that if two distributions have the same characteristic function, they are in fact the same distribution. The proof of this theorem employs something akin to kernel methods from harmonic analysis, using the function\footnote{The notation $\int_a^b f(x) \, dx$, familiar from calculus, denotes simply the Lebesgue integral of $f$ over the interval $[a,b]$ with respect to Lebesgue measure.}
\[ \Si(t) = \int_0^t \frac{\sin x}{x} \, dx \]
to ``concentrate'' near points of interest. This requires, among other things, proving that $\lim_{t \rightarrow \infty} \Si(t) = \pi/2$, which we accomplished using Fubini's theorem (see Billingsley \cite{billingsley}, pp. 235--236) and required tedious verification of many ``obvious'' facts about integrals (including the validity of integration by substitution). Deriving uniqueness from the L\'evy continuity theorem required using the fact that the complement of a countable subset of $\R$ is dense in $\R$ and the $\pi$-$\lambda$ theorem from measure theory (the latter having already been formalized by H\"olzl).

Verification of the L\'evy continuity theorem required proving the portmanteau theorem, more calculations with integrals (and another use of Fubini's theorem), and use of the theory of tightness of sequences of probability measures. The portmanteau theorem establishes that convergence in distribution is equivalent to various definitions of weak* convergence in the sense of functional analysis; we verified equivalence to two such definitions, as done in Billingsley \cite{billingsley}. The proof of the portmanteau theorem uses Skorohod's theorem, which states that if a sequence $\bldseq{\mu_n}{n \in \N}$ of probability measures converges in distribution to a probability measure $\mu$, then there exists a sequence of random variables $\bldseq{X_n}{n \in \N}$ and a random variable $X$, all defined on a common probability space, such that $X_n \sim \mu_n$, $X \sim \mu$, and $X_n \rightarrow X$ pointwise. The proof of this result requires only elementary analysis.

The theory of tightness of sequences of measures gives an analogue in the space of probability measures of the Weierstrass theorem that every bounded sequence of reals has a convergent subsequence. Tightness is the requisite analogue of boundedness: Roughly a sequence of probability measures is called tight iff no mass ``escapes to infinity.'' The sequence $\bldseq{\mu_n}{n \in \N}$, where $\mu_n$ is a unit mass at $n$, gives an example of how mass can ``escape to infinity.'' The key result regarding tightness of a sequence $\bldseq{\mu_n}{n \in \N}$ of probability measures is that it is equivalent to the condition that for every subsequence $\bldseq{\mu_{n_k}}{k \in \N}$ there exists a subsubsequence $\bldseq{\mu_{n_{k_j}}}{j \in \N}$ which converges in distribution to some probability measure. A corollary of this result is that if a sequence $\bldseq{\mu_n}{n \in \N}$ is tight, and it can be shown that every subsequence which has a weak limit must converge in distribution to a given probability measure $\mu$, then in fact $\mu_n \Rightarrow \mu$.

The proof of the main result concerning tight sequences of measures requires the Helly selection theorem, which is of importance also in functional analysis. This is another analogue of Weierstrass theorem, this time giving that if \linebreak $\bldseq{F_n}{n \in \N}$ is any sequence of distribution functions\footnote{The distribution function $F$ of a Borel probability measure $\mu$ on $\R$ is given by $F(x) = \mu(-\infty, x]$; these functions are treated in section \ref{sec:cdf}.} then it has a subsequence $\bldseq{F_{n_k}}{k \in \N}$ which converges vaguely to some nondecreasing, right-continuous function $F$ (which may not be a distribution function because its limit at $\infty$ may be less than $1$). Vague convergence is defined the same way as weak convergence, and differs only in not requiring that the limit function have limit $1$ at $\infty$. The Helly selection theorem is proven using the method of diagonal subsequences to obtain values for the requisite function $F$ at rationals, and extending to all reals by right-continuity.\footnote{This summary is not quite accurate, but provides reasonable intuition. The actual proof is given in section \ref{sec:helly}.} The elementary analytical arguments involved in this were straightforward but tedious to verify.

\section{The Isabelle Interactive Proof Assistant}

Before giving details of our formalization, we pause for a quick overview of some relevant features of the Isabelle interactive proof assistant that we employed. Readers familiar with this system may wish to skip to section \ref{sec:form}, though some of the material on axiomatic type classes and locales in section \ref{sec:loc} and on the implementation of general limits using a definition involving filters in section \ref{sec:filterlim} may still be of interest.

\subsection{Overview of Isabelle}

When the author first decided to undertake an interactive formalization project, he knew nothing about the available proof assistants, and chose Isabelle with Avigad's advice. Other possibilities considered were Coq and HOL-Light, a variant of the HOL system. The Coq assistant \cite{coq-ref} had the best support for algebraic reasoning (in the manner of abstract algebra), and an attractive implementation of dependent type theory (which allows types to depend on parameters, e.g. the type of integers modulo $n$ depends on the natural number $n$). However, Coq is intended to formalize proofs in constructive logic, and constructive analysis is in general very different from classical analysis. This could be overcome by adding the law of the excluded middle (or something entailing it, such as the axiom of choice) as an axiom. That solution is slightly inelegant, but the main reason for deciding against using Coq was the fact that it had far less powerful automated tools than our other options. HOL-Light \cite{harrison-hol-light} arguably had the most extensive support for analysis (the Jordan curve theorem \cite{hales-jordan} and other significant results had already been formalized in this system, and it was the system of choice for the Flyspeck project \cite{hales-kepler}, a now-completed effort to formalize Tom Hales' proof of the Kepler conjecture), but its user-interface was more difficult than that of the others (the user must directly type ML code). Isabelle had both good analysis libraries and a good user interface, and furthermore was the system chosen by H\"olzl and collaborators for the development of measure-theory libraries, making it a clearly optimal choice for the formalization of the central limit theorem.

The Isabelle system was initially developed by Larry Paulson at Cambridge University and Tobias Nipkow at Technische Universit\"at M\"unchen, and has grown to include a large number of additional developers and library contributers. Isabelle is generic in the sense that it provides a small, trusted core reasoner (known as ``Isabelle/Pure'') and allows extension in any direction over that. It employs an LCF-style architecture \cite{gordon-lcf} to ensure extensions preserve soundness. The extension of Pure which has received the most attention by library developers is Isabelle/HOL, where HOL stands for higher-order logic. Our formalization was carried out in Isabelle/HOL-Probability, an extension of the HOL main library incorporating a significant amount of measure-theoretic probability theory.

In simple form, higher-order logic is a conservative extension of first-order logic incorporating quantification over predicates and functions, higher-order predicates and functions (e.g. a predicate $T(R)$ which holds iff $R$ is a transitive binary relation), and quantification over these. This can be augmented by a definite description operator (\texttt{THE} in Isabelle), and the extension remains conservative roughly because definite descriptions can be eliminated via Russell's well-known interpretation \cite{russell-knowledge-acquaintance-description}. The indefinite description operator \texttt{SOME} included in Isabelle/HOL is a more radical departure, for its presence entails the axiom of choice (which can be easily stated in higher-order logic), and thus breaks conservativity of the HOL extension. However, the axiom of choice (or at least some weak variant of it) is essential to the usual development of mathematical analysis, and so the indefinite description operator is a welcome addition for our purposes.

One might reasonably ask why higher-order logic rather than set theory is used as the basis of our formalization. Pragmatically, the Isabelle support for higher-order logic is far better than that for set theory, but why is this? A number of advantages exist, including functions as primitives, type-checking and type inference, and the additional resources provided by the type system for pruning the search space of automated procedures. However, all these advantages could in principle be obtained in a system based on set theory, say by augmenting ordinary set theory with ``weak types.'' Further discussion of the tradeoffs between higher-order logic and set theory in the context of automated deduction, and possibilities for combining the two approaches, are found in \cite{gordon-hol-set}.

We shall now briefly describe some of the Isabelle infrastructure and tools we used while formalizing the central limit theorem. Readers seeking to gain some working knowledge of Isabelle are advised to consult Nipkow's tutorial introduction \cite{nipkow-prog-prove} and the wealth of resources available at \linebreak \url{http://isabelle.in.tum.de/}. A high-level overview can also be found at that website.

We mentioned earlier that one of our reasons for choosing Isabelle was its friendly user-interface, and this is provided by the Isar proof-scripting language \cite{wenzel-isar}, developed by Markus Wenzel as part of his doctoral thesis at Technische Universit\"at M\"unchen. The goal was to provide a more human-readable paradigm for proof scripts, and we certainly agree that Wenzel achieved his goal. The old style for proof scripts consisted in repeatedly applying tactics (using the \texttt{apply} method) to refine a goal into subgoals until all these are proved. Figure \ref{fig:tact} gives an example of a tactic-style proof from our formalization, while figure \ref{fig:isar} gives an example of an Isar proof. These styles can also be combined, as seen in figure \ref{fig:mix}. Clearly Isar offers a great improvement in readability, and hence in ease of maintenance, for proof scripts.

\begin{figure}
\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ ex{\isacharunderscore}{\isadigit{1}}{\isadigit{8}}{\isacharunderscore}{\isadigit{4}}{\isacharunderscore}{\isadigit{2}}{\isacharunderscore}ubdd{\isacharunderscore}integral{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ x\isanewline
\ \ \isakeyword{assumes}\ pos{\isacharcolon}\ {\isachardoublequoteopen}{\isadigit{0}}\ {\isacharless}\ x{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}LBINT\ u{\isacharequal}{\isadigit{0}}{\isachardot}{\isachardot}{\isasyminfinity}{\isachardot}\ {\isasymbar}exp\ {\isacharparenleft}{\isacharminus}u\ {\isacharasterisk}\ x{\isacharparenright}\ {\isacharasterisk}\ sin\ x{\isasymbar}\ {\isacharequal}\ {\isasymbar}sin\ x{\isasymbar}\ {\isacharslash}\ x{\isachardoublequoteclose}\ \isanewline
\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ interval{\isacharunderscore}integral{\isacharunderscore}FTC{\isacharunderscore}nonneg\ {\isacharbrackleft}\isakeyword{where}\ F\ {\isacharequal}\ {\isachardoublequoteopen}{\isasymlambda}u{\isachardot}\ {\isadigit{1}}{\isacharslash}x\ {\isacharasterisk}\ {\isacharparenleft}{\isadigit{1}}\ {\isacharminus}\ exp\ {\isacharparenleft}{\isacharminus}u\ {\isacharasterisk}\ x{\isacharparenright}{\isacharparenright}\ {\isacharasterisk}\ {\isasymbar}sin\ x{\isasymbar}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isakeyword{and}\ A\ {\isacharequal}\ {\isadigit{0}}\ \isakeyword{and}\ B\ {\isacharequal}\ {\isachardoublequoteopen}abs\ {\isacharparenleft}sin\ x{\isacharparenright}\ {\isacharslash}\ x{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ force\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ ex{\isacharunderscore}{\isadigit{1}}{\isadigit{8}}{\isacharunderscore}{\isadigit{4}}{\isacharunderscore}{\isadigit{2}}{\isacharunderscore}deriv{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ auto\isanewline
\ \ \isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ zero{\isacharunderscore}ereal{\isacharunderscore}def{\isacharparenright}{\isacharplus}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp{\isacharunderscore}all\ add{\isacharcolon}\ ereal{\isacharunderscore}tendsto{\isacharunderscore}simps{\isacharparenright}\isanewline
\ \ \isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ filterlim{\isacharunderscore}mono\ {\isacharbrackleft}of\ {\isacharunderscore}\ {\isachardoublequoteopen}nhds\ {\isadigit{0}}{\isachardoublequoteclose}\ {\isachardoublequoteopen}at\ {\isadigit{0}}{\isachardoublequoteclose}{\isacharbrackright}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{prefer}\isamarkupfalse%
\ {\isadigit{2}}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ at{\isacharunderscore}le{\isacharcomma}\ simp{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ divide{\isacharunderscore}real{\isacharunderscore}def{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}mult{\isacharunderscore}left{\isacharunderscore}zero{\isacharparenright}{\isacharplus}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subgoal{\isacharunderscore}tac\ {\isachardoublequoteopen}{\isadigit{0}}\ {\isacharequal}\ {\isadigit{1}}\ {\isacharminus}\ {\isadigit{1}}{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}erule\ ssubst{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}diff{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subgoal{\isacharunderscore}tac\ {\isachardoublequoteopen}{\isadigit{1}}\ {\isacharequal}\ exp\ {\isadigit{0}}{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}erule\ ssubst{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}compose{\isacharbrackleft}OF\ tendsto{\isacharunderscore}exp{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ isCont{\isacharunderscore}def\ {\isacharbrackleft}symmetric{\isacharbrackright}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}minus{\isacharunderscore}cancel{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}mult{\isacharunderscore}left{\isacharunderscore}zero{\isacharcomma}\ rule\ tendsto{\isacharunderscore}ident{\isacharunderscore}at{\isacharparenright}\isanewline
\ \ \isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ divide{\isacharunderscore}real{\isacharunderscore}def{\isacharparenright}{\isacharplus}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subgoal{\isacharunderscore}tac\ {\isachardoublequoteopen}abs\ {\isacharparenleft}sin\ x{\isacharparenright}\ {\isacharasterisk}\ inverse\ x\ {\isacharequal}\ {\isadigit{1}}\ {\isacharasterisk}\ abs\ {\isacharparenleft}sin\ x{\isacharparenright}\ {\isacharasterisk}\ inverse\ x{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}erule\ ssubst{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}mult{\isacharparenright}{\isacharplus}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ auto\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}eq{\isacharunderscore}intros{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}const{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ filterlim{\isacharunderscore}compose{\isacharbrackleft}OF\ exp{\isacharunderscore}at{\isacharunderscore}bot{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{unfolding}\isamarkupfalse%
\ filterlim{\isacharunderscore}uminus{\isacharunderscore}at{\isacharunderscore}bot\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ mult{\isachardot}commute{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ filterlim{\isacharunderscore}tendsto{\isacharunderscore}pos{\isacharunderscore}mult{\isacharunderscore}at{\isacharunderscore}top{\isacharbrackleft}OF\ tendsto{\isacharunderscore}const\ pos\ filterlim{\isacharunderscore}ident{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{done}\isamarkupfalse%
\end{isabellebody}
\caption{A tactic-style proof.}
\label{fig:tact}
\end{figure}

\begin{figure}
\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ pair{\isacharunderscore}sigma{\isacharunderscore}finite{\isacharparenright}\ Fubini{\isacharunderscore}integrable{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharunderscore}\ {\isasymRightarrow}\ {\isacharunderscore}{\isacharcolon}{\isacharcolon}{\isacharbraceleft}banach{\isacharcomma}\ second{\isacharunderscore}countable{\isacharunderscore}topology{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ f{\isacharbrackleft}measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}f\ {\isasymin}\ borel{\isacharunderscore}measurable\ {\isacharparenleft}M{\isadigit{1}}\ {\isasymOtimes}\isactrlsub M\ M{\isadigit{2}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isakeyword{and}\ integ{\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}integrable\ M{\isadigit{1}}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ {\isasymintegral}\ y{\isachardot}\ norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}\ {\isasympartial}M{\isadigit{2}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isakeyword{and}\ integ{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}AE\ x\ in\ M{\isadigit{1}}{\isachardot}\ integrable\ M{\isadigit{2}}\ {\isacharparenleft}{\isasymlambda}y{\isachardot}\ f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}integrable\ {\isacharparenleft}M{\isadigit{1}}\ {\isasymOtimes}\isactrlsub M\ M{\isadigit{2}}{\isacharparenright}\ f{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}rule\ integrableI{\isacharunderscore}bounded{\isacharparenright}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymintegral}\isactrlsup {\isacharplus}\ p{\isachardot}\ norm\ {\isacharparenleft}f\ p{\isacharparenright}\ {\isasympartial}{\isacharparenleft}M{\isadigit{1}}\ {\isasymOtimes}\isactrlsub M\ M{\isadigit{2}}{\isacharparenright}{\isacharparenright}\ {\isacharequal}\ {\isacharparenleft}{\isasymintegral}\isactrlsup {\isacharplus}\ x{\isachardot}\ {\isacharparenleft}{\isasymintegral}\isactrlsup {\isacharplus}\ y{\isachardot}\ norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}\ {\isasympartial}M{\isadigit{2}}{\isacharparenright}\ {\isasympartial}M{\isadigit{1}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ M{\isadigit{2}}{\isachardot}nn{\isacharunderscore}integral{\isacharunderscore}fst\ {\isacharbrackleft}symmetric{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ {\isacharparenleft}{\isasymintegral}\isactrlsup {\isacharplus}\ x{\isachardot}\ {\isasymbar}{\isasymintegral}y{\isachardot}\ norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}\ {\isasympartial}M{\isadigit{2}}{\isasymbar}\ {\isasympartial}M{\isadigit{1}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}intro\ nn{\isacharunderscore}integral{\isacharunderscore}cong{\isacharunderscore}AE{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ integ{\isadigit{2}}\isanewline
\ \ \isacommand{proof}\isamarkupfalse%
\ eventually{\isacharunderscore}elim\isanewline
\ \ \ \ \isacommand{fix}\isamarkupfalse%
\ x\ \isacommand{assume}\isamarkupfalse%
\ {\isachardoublequoteopen}integrable\ M{\isadigit{2}}\ {\isacharparenleft}{\isasymlambda}y{\isachardot}\ f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ f{\isacharcolon}\ {\isachardoublequoteopen}integrable\ M{\isadigit{2}}\ {\isacharparenleft}{\isasymlambda}y{\isachardot}\ norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymintegral}\isactrlsup {\isacharplus}y{\isachardot}\ ereal\ {\isacharparenleft}norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}{\isacharparenright}\ {\isasympartial}M{\isadigit{2}}{\isacharparenright}\ {\isacharequal}\ ereal\ {\isacharparenleft}LINT\ y{\isacharbar}M{\isadigit{2}}{\isachardot}\ norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ nn{\isacharunderscore}integral{\isacharunderscore}eq{\isacharunderscore}integral{\isacharparenright}\ simp\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ ereal\ {\isasymbar}LINT\ y{\isacharbar}M{\isadigit{2}}{\isachardot}\ norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}{\isasymbar}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{using}\isamarkupfalse%
\ f\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ abs{\isacharunderscore}of{\isacharunderscore}nonneg{\isacharbrackleft}symmetric{\isacharbrackright}\ integral{\isacharunderscore}nonneg{\isacharunderscore}AE{\isacharparenright}\isanewline
\ \ \ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymintegral}\isactrlsup {\isacharplus}y{\isachardot}\ ereal\ {\isacharparenleft}norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}{\isacharparenright}\ {\isasympartial}M{\isadigit{2}}{\isacharparenright}\ {\isacharequal}\ ereal\ {\isasymbar}LINT\ y{\isacharbar}M{\isadigit{2}}{\isachardot}\ norm\ {\isacharparenleft}f\ {\isacharparenleft}x{\isacharcomma}\ y{\isacharparenright}{\isacharparenright}{\isasymbar}{\isachardoublequoteclose}\ \isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\ \ \isacommand{qed}\isamarkupfalse%
\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharless}\ {\isasyminfinity}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ integ{\isadigit{1}}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ integrable{\isacharunderscore}iff{\isacharunderscore}bounded\ integral{\isacharunderscore}nonneg{\isacharunderscore}AE{\isacharparenright}\isanewline
\ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymintegral}\isactrlsup {\isacharplus}\ p{\isachardot}\ norm\ {\isacharparenleft}f\ p{\isacharparenright}\ {\isasympartial}{\isacharparenleft}M{\isadigit{1}}\ {\isasymOtimes}\isactrlsub M\ M{\isadigit{2}}{\isacharparenright}{\isacharparenright}\ {\isacharless}\ {\isasyminfinity}{\isachardoublequoteclose}\ \isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\isacommand{qed}\isamarkupfalse%
\ fact%
\end{isabellebody}
\caption{An Isar proof.}
\label{fig:isar}
\end{figure}

\begin{figure}
\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ Billingsley{\isacharunderscore}ex{\isacharunderscore}{\isadigit{1}}{\isadigit{7}}{\isacharunderscore}{\isadigit{5}}{\isacharcolon}\ \isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}set{\isacharunderscore}integrable\ lborel\ {\isacharparenleft}einterval\ {\isacharparenleft}{\isacharminus}{\isasyminfinity}{\isacharparenright}\ {\isasyminfinity}{\isacharparenright}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ inverse\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ x{\isacharcircum}{\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ {\isachardoublequoteopen}LBINT\ x{\isacharequal}{\isacharminus}{\isasyminfinity}{\isachardot}{\isachardot}{\isasyminfinity}{\isachardot}\ inverse\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ x{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharequal}\ pi{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}x{\isachardot}\ {\isacharminus}\ {\isacharparenleft}pi\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharless}\ x\ {\isasymLongrightarrow}\ x\ {\isacharasterisk}\ {\isadigit{2}}\ {\isacharless}\ pi\ {\isasymLongrightarrow}\ {\isacharparenleft}tan\ has{\isacharunderscore}real{\isacharunderscore}derivative\ {\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}tan\ x{\isacharparenright}\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}at\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ tan{\isacharunderscore}sec{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ pi{\isacharunderscore}half\ cos{\isacharunderscore}is{\isacharunderscore}zero\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}metis\ cos{\isacharunderscore}gt{\isacharunderscore}zero{\isacharunderscore}pi\ less{\isacharunderscore}divide{\isacharunderscore}eq{\isacharunderscore}numeral{\isadigit{1}}{\isacharparenleft}{\isadigit{1}}{\isacharparenright}\ less{\isacharunderscore}numeral{\isacharunderscore}extra{\isacharparenleft}{\isadigit{3}}{\isacharparenright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ DERIV{\isacharunderscore}tan\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}metis\ cos{\isacharunderscore}gt{\isacharunderscore}zero{\isacharunderscore}pi\ less{\isacharunderscore}divide{\isacharunderscore}eq{\isacharunderscore}numeral{\isadigit{1}}{\isacharparenleft}{\isadigit{1}}{\isacharparenright}\ power{\isadigit{2}}{\isacharunderscore}less{\isacharunderscore}{\isadigit{0}}\ power{\isacharunderscore}inverse\ \isanewline
\ \ \ \ \ \ power{\isacharunderscore}zero{\isacharunderscore}numeral{\isacharparenright}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}x{\isachardot}\ {\isacharminus}\ {\isacharparenleft}pi\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharless}\ x\ {\isasymLongrightarrow}\ x\ {\isacharasterisk}\ {\isadigit{2}}\ {\isacharless}\ pi\ {\isasymLongrightarrow}\ isCont\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ {\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}tan\ x{\isacharparenright}\isactrlsup {\isadigit{2}}{\isacharparenright}\ x{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ isCont{\isacharunderscore}add{\isacharcomma}\ force{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ power{\isadigit{2}}{\isacharunderscore}eq{\isacharunderscore}square{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ isCont{\isacharunderscore}mult{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ isCont{\isacharunderscore}tan{\isacharparenright}\isanewline
\ \ \ \ \isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ pi{\isacharunderscore}half\ cos{\isacharunderscore}is{\isacharunderscore}zero\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}metis\ cos{\isacharunderscore}gt{\isacharunderscore}zero{\isacharunderscore}pi\ less{\isacharunderscore}divide{\isacharunderscore}eq{\isacharunderscore}numeral{\isadigit{1}}{\isacharparenleft}{\isadigit{1}}{\isacharparenright}\ less{\isacharunderscore}numeral{\isacharunderscore}extra{\isacharparenleft}{\isadigit{3}}{\isacharparenright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}LBINT\ x{\isacharequal}{\isacharminus}{\isasyminfinity}{\isachardot}{\isachardot}{\isasyminfinity}{\isachardot}\ inverse\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ x{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharequal}\ pi{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ interval{\isacharunderscore}integral{\isacharunderscore}substitution{\isacharunderscore}nonneg{\isacharbrackleft}of\ {\isachardoublequoteopen}{\isacharminus}pi{\isacharslash}{\isadigit{2}}{\isachardoublequoteclose}\ {\isachardoublequoteopen}pi{\isacharslash}{\isadigit{2}}{\isachardoublequoteclose}\ tan\ {\isachardoublequoteopen}{\isasymlambda}x{\isachardot}\ {\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}tan\ x{\isacharparenright}{\isacharcircum}{\isadigit{2}}{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharcolon}\ derivative{\isacharunderscore}eq{\isacharunderscore}intros\ simp\ add{\isacharcolon}\ ereal{\isacharunderscore}tendsto{\isacharunderscore}simps\ filterlim{\isacharunderscore}tan{\isacharunderscore}at{\isacharunderscore}left\ add{\isacharunderscore}nonneg{\isacharunderscore}eq{\isacharunderscore}{\isadigit{0}}{\isacharunderscore}iff{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}erule\ {\isacharparenleft}{\isadigit{1}}{\isacharparenright}\ {\isadigit{1}}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}erule\ {\isacharparenleft}{\isadigit{1}}{\isacharparenright}\ {\isadigit{2}}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ minus{\isacharunderscore}divide{\isacharunderscore}left{\isacharparenright}{\isacharplus}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ filterlim{\isacharunderscore}tan{\isacharunderscore}at{\isacharunderscore}right{\isacharparenright}\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}set{\isacharunderscore}integrable\ lborel\ {\isacharparenleft}einterval\ {\isacharparenleft}{\isacharminus}{\isasyminfinity}{\isacharparenright}\ {\isasyminfinity}{\isacharparenright}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ inverse\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ x{\isacharcircum}{\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ interval{\isacharunderscore}integral{\isacharunderscore}substitution{\isacharunderscore}nonneg{\isacharbrackleft}of\ {\isachardoublequoteopen}{\isacharminus}pi{\isacharslash}{\isadigit{2}}{\isachardoublequoteclose}\ {\isachardoublequoteopen}pi{\isacharslash}{\isadigit{2}}{\isachardoublequoteclose}\ tan\ {\isachardoublequoteopen}{\isasymlambda}x{\isachardot}\ {\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}tan\ x{\isacharparenright}{\isacharcircum}{\isadigit{2}}{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharcolon}\ derivative{\isacharunderscore}eq{\isacharunderscore}intros\ simp\ add{\isacharcolon}\ ereal{\isacharunderscore}tendsto{\isacharunderscore}simps\ filterlim{\isacharunderscore}tan{\isacharunderscore}at{\isacharunderscore}left\ add{\isacharunderscore}nonneg{\isacharunderscore}eq{\isacharunderscore}{\isadigit{0}}{\isacharunderscore}iff{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}erule\ {\isacharparenleft}{\isadigit{1}}{\isacharparenright}\ {\isadigit{1}}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}erule\ {\isacharparenleft}{\isadigit{1}}{\isacharparenright}\ {\isadigit{2}}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ minus{\isacharunderscore}divide{\isacharunderscore}left{\isacharparenright}{\isacharplus}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ filterlim{\isacharunderscore}tan{\isacharunderscore}at{\isacharunderscore}right{\isacharparenright}\isanewline
\isacommand{qed}\isamarkupfalse%
\end{isabellebody}
\caption{A mixed-style proof.}
\label{fig:mix}
\end{figure}

Nevertheless, often it is easier to hack through a tactic-style proof than to carefully structure an Isar proof, and so a significant amount of our formalization is still written in tactic style. Most of the tactic-style proofs involve fiddly calculations in one way or another, and we see both an opportunity to clean up our own proof scripts (rewriting long tactic-style proofs in Isar is one of the main goals of our continued development of the proof scripts) and to improve the usability of Isabelle for doing fiddly calculations without resorting to a tactic-style proof. It seems likely advances in Isar, Isabelle's libraries, and Isabelle's automated tools could all benefit this latter goal.

To help the user prove theorems more efficiently, Isabelle provides support for proof automation. The basic tools for this are the equational-reasoning simplifier \texttt{simp} (though more functionality is being continually built into this tool), the higher-order tableau prover \texttt{auto} (which uses extensive heuristic reasoning that can be influenced by the user), and the first-order sequent prover \texttt{blast}, though many variants and alternatives are available. In addition, the \texttt{sledgehammer} tool \cite{paulson-sledgehammer} provides a link to an extensible suite of external provers. Proofs generated by \texttt{sledgehammer} tools can be inserted into Isabelle proof scripts via proof text automatically generated by \texttt{sledgehammer}; typically these will employ the Isabelle-native SMT solver\footnote{SMT stands for Satisfiability Modulo Theories; an SMT solver demonstrates satisfiability of a normal form in the presence of assumptions from a background theory. A quick overview can be found in \cite{demoura-bjorner-smt}.} \texttt{metis}. The tools \texttt{simp} and \texttt{auto} and their variants can be influenced by the user by declaring results to be simplification rules \texttt{[simp]} or introduction rules \texttt{[intro]}, which enables their use by \texttt{simp} or \texttt{auto}, respectively. All these tools were extensively employed in our formalization.

\subsection{Types and Locales} \label{sec:loc}

The existence of the type \texttt{nat} of natural numbers must be guaranteed by an axiom of infinity (because otherwise higher-order logic has models where all types are finite), but everything else can be built up from there. Integers (type \texttt{int}) are defined as equivalence classes of pairs of natural numbers, and rationals (type \texttt{rat}) as equivalence classes of pairs of integers, both in the usual manner (see for example \cite{enderton}). Real numbers (type \texttt{real}) are defined as equivalence classes of Cauchy sequences of rational numbers (see \cite{suppes}; perhaps a more common method of construction in analysis texts is that via Dedekind cuts). Extended reals (type \texttt{ereal}) are defined as the sum type of $\{-\infty\}$, $\R$, and $\{\infty\}$, with the expected ordering and operations. Complex numbers are defined as pairs of real numbers.

All this is supported by Isabelle's system of polymorphic type constructors, which we briefly describe. Full detail can be found in the Isabelle/HOL documentation available at \url{http://isabelle.in.tum.de/documentation.html}. The fact that a variable $x$ has type $\alpha$ can be indicated with the annotation \texttt{$x$::$\alpha$}, though Isabelle's polymorphic type inference system often eliminates the need for such annotations. If $\alpha$ and $\beta$ are types, the type $\alpha \Rightarrow \beta$ is the type of functions with domain $\alpha$ and codomain $\beta$ (note that this is more commonly denoted $\alpha \rightarrow \beta$ in the literature on higher-order logic), while $\alpha \times \beta$ is the type of pairs with first element of type $\alpha$ and second of type $\beta$. If $\alpha$ is a type, so is \texttt{$\alpha$ set}, the type of sets of elements of type $\alpha$. These could be interpreted as predicates (functions of type \texttt{$\alpha \Rightarrow$ bool}), where \texttt{bool} is the type with precisely two elements \texttt{true}, \texttt{false}), but it is harmless and notationally useful to take these as separate types.

Types and type variables (such as $\alpha$ in \texttt{$\alpha$ set}) can belong to axiomatic type classes, for example the annotation \texttt{$\alpha$::linordered\_field} indicates that $\alpha$ is a type with the structure of an ordered field (and so $\alpha$ possesses binary operations $+$ and $\cdot$, unary operations $-$ and $\phantom{t}\inv$, constants $0$ and $1$, and a binary relation $\le$ which satisfy the axioms of a linearly ordered field). See \cite{haftmann} for further details. Types can also be organized into locales, which allows them to be structured into hierarchies (as is familiar in an informal setting from algebra). For example, if the locale \texttt{field} is a sublocale of the locale \texttt{ring}, then any theorem proved for rings can be used for fields. A type can be shown to instantiate a locale with the reserved words \texttt{instance} and \texttt{instance proof}. Further information on locales can be found in \cite{ballarin}. Syntax for locales will arise as we examine the proof scripts developed for the central limit theorem.

\subsection{Limits and Filters} \label{sec:filterlim}

Because it is interesting and different than what is found in standard concrete presentations of analysis, we describe the flexible method of filterlimits used in the Isabelle limit libraries. Full detail can be found in \cite{hoelzl-filter}.

\begin{definition}
Let $X$ be a set. A {\em filter} over $X$ is a nonempty set $\mathcal F \subseteq \mathcal P(X)$ such that
\begin{enumerate}
\item If $A \subseteq B$ and $A \in \mathcal F$, then $B \in \mathcal F$.
\item If $A, B \in \mathcal F$, then $A \cap B \in \mathcal F$.
\end{enumerate}
\end{definition}

Filters can be thought of as ``large'' sets, in some vague sense. $\mathcal P(X)$ is the {\em trivial} filter, and often must be excluded (say by the condition that $\emptyset \notin \mathcal F$). In Isabelle, predicates are employed instead of sets in the definition of a filter.

We now turn to some examples of filters. Please note that none of the notation used here is standard. The verification that these actually are filters is elementary, and the interested reader may regard it as an exercise.
\begin{enumerate}
\item If $A \subseteq X$, the filter $\mathfrak P_A = \bldset{B \subseteq X}{A \subseteq B}$ is called the {\em principal filter} over $A$. A filter which is not equal to $\mathfrak P_A$ for any $A \subseteq X$ is called {\em nonprincipal}. In case $A = \{a\}$ is a singleton, $\mathfrak P_{\{a\}}$ is denoted $\mathfrak P_a$ and called the principal filter over $a$.
\item For $X$ infinite, the smallest nonprincipal filter on $X$ is the {\em cofinite filter} $\bldset{A \subseteq X}{|X \setminus A| < \infty}$.
\item If $\tau$ is a topology on $X$,
\[ \mathcal N_x^\tau = \bldset{A \subseteq X}{\exists U \in \tau. \ x \in U \subseteq A} \]
is the {\em neighborhood filter} on $X$, while
\[ \mathcal N_{(x)}^\tau = \bldset{B \subseteq X}{\exists A \in \mathcal N_x^\tau. \ B = A \setminus \{x\}} \]
is the {\em punctured neighborhood filter}. The superscript $\tau$ can be omitted when there is no danger of ambiguity.
\item If $\le$ is a linear order on $X$, there are two natural filters on $X$ ``going to infinity'' in the two possible directions. These are
\[ \mathcal U = \bldset{A \subseteq X}{\forall x \in A. \ x \le y \Longrightarrow y \in A}, \]
the filter of {\em upper sets}, and
\[ \mathcal L = \bldset{A \subseteq X}{\forall x \in A. \ y \le x \Longrightarrow y \in A}, \]
the filter of {\em lower sets}.
\item We can also define left and right ``punctured half-neighborhood filters'' for a linear order $(X,\le)$:
\[ \mathcal H_x^+ = \bldset{A \subseteq X}{\exists y > x. \ \forall z \in X. \ x \le z \le y \Longrightarrow z \in A} \]
is the right punctured half-neighborhood filter of $x$, while
\[ \mathcal H_x^- = \bldset{A \subseteq X}{\exists y < x. \ \forall z \in X. \ y \le z \le x \Longrightarrow z \in A} \]
is the left punctured half-neighborhood filter.
\end{enumerate}

A property $P$ is said to hold {\em eventually} with respect to a filter $\mathcal F$ iff \linebreak $\bldset{x}{Px} \in \mathcal F$. For example, if $\mathfrak P_a$ is the principal filter over $a$, a property holds eventually with respect to $\mathfrak P_a$ iff it holds at $a$. A property holds eventually with respect to the cofinite filter iff it holds at all but finitely many points, and it holds eventually with respect to the neighborhood filter $\mathcal N_x$ of $x$ iff it holds in some neighborhood of $x$. A property which holds eventually with respect to $\mathcal U$ may be thought of as holding ``at $\infty$,'' and analogously for $\mathcal L$.

A filter $\mathcal G$ is {\em finer than} $\mathcal F$ iff fewer properties hold eventually for $\mathcal G$ than for $\mathcal F$, equivalently iff $\mathcal G \subseteq \mathcal F$. For example, if $(X, \tau)$ is a topological space and $x \in X$, we have that $\mathcal N_x$ is finer than $\mathcal N_{(x)}$, which is in turn finer than $\mathfrak P_x$.

Convergence is now easily defined: A function $f$ converges to a filter $\mathcal G$ with respect to a filter $\mathcal F$ iff $f(\mathcal F)$ is finer than $\mathcal G$, where $f(\mathcal F) = \bldset{A}{f\inv[A] \in \mathcal F}$ (H\"olzl calls this the {\em filtermap} operation). In case $\mathcal G$ is $\mathcal N_{(x)}$ for some $x$ in a topological space, we say that $f$ converges to $x$ with respect to the filter $\mathcal F$. The extra filter $\mathcal G$ is useful for saying such things as that a function $f$ converges to $\mathcal U$, or in intuitive terms $f \rightarrow \infty$; this is easily expressible with the two-filter definition of convergence but would be lost if the filter to which a function converges were always assumed to be a puncturedneighborhood filter. Also, limits from the left and right can be expressed in terms of $\mathcal H_x^-$ and $\mathcal H_x^+$ rather than requiring separate definitions. This filterlimit framework gives rise to an amazing amount of flexibility which was very useful when formalizing the CLT; further examples and explanation are found in \cite{hoelzl-filter}.

\section{The Formalized Proof} \label{sec:form}

Having given an overview of the proof we formalized and the system in which it was carried out, we turn now to the details. Along the way, we shall try to point out best practices, pitfalls, and opportunities for improvement which we encountered in the course of our formalization. Full proof scripts are often included, but not generally intended to be read in full detail. A quick skim of these scripts should give a flavour of how they work, and we always include an informal proof first.

Why include formal proofs at all? It is a common practice when presenting a formalization to omit all formal proofs and just indicate the informal proofs of formalized statements. This implicitly assumes that the proof scripts are far less readable than their informal counterparts, which is certainly true to an extent, but it is our hope that the readability of proof scripts has improved to the point that the reader may benefit by at least skimming them. At the very least this will give side-by-side comparisons of formal to informal mathematics, a comparison sometimes difficult to make when reading papers on formalization. If scripts are particularly long or difficult to read, we omit them (of course the full formalization is available in the project git repository \linebreak \url{https://github.com/avigad/isabelle}).

\subsection{Distribution Functions} \label{sec:cdf}

Often it is more convenient to work with a real-valued function determining a measure on $\R$ than directly with the measure, and an obvious way to accomplish this for finite measures is to study the distribution function of the measure, which when evaluated at an argument gives the amount of mass below that argument.

\begin{definition}
Let $\mu$ be a finite measure on $\R$. The (cumulative) distribution function $F_\mu$ is defined by $F_\mu(x) = \mu (-\infty, x]$.
\end{definition}

In Isabelle, this is rendered as

\medskip

\begin{isabellebody}
\isacommand{definition}\isamarkupfalse%
\isanewline
\ \ cdf\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure\ {\isasymRightarrow}\ real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}cdf\ M\ {\isasymequiv}\ {\isasymlambda}x{\isachardot}\ measure\ M\ {\isacharbraceleft}{\isachardot}{\isachardot}x{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ cdf{\isacharunderscore}def{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}cdf\ M\ x\ {\isacharequal}\ measure\ M\ {\isacharbraceleft}{\isachardot}{\isachardot}x{\isacharbraceright}{\isachardoublequoteclose}%
\end{isabellebody}

\medskip

The lemma gives what is intuitively the definition; the actual definition uses lambda abstraction. If $\tau(x)$ is a term, $\lambda x. \, \tau(x)$ is the function which, when evaluated at input $a$, gives $\tau(a)$. This is a standard notation in higher-order logic; for more details we refer the reader to any standard textbook treatment of the subject, for example \cite{andrews}.

Before proving that the distribution function of a measure uniquely determines that measure, let us note some general properties of distribution functions. For convenience we assume the measures we are working with are probability measures; other nonzero finite measures can be normalized to probability measures, and the zero measure is trivial.

\begin{theorem}
The distribution function $F_\mu$ of a finite measure $\mu$ is nondecreasing and right-continuous and satisfies $\lim_{x \rightarrow -\infty} F_\mu(x) = 0$ and \linebreak $\lim_{x \rightarrow \infty} F_\mu(x) = 1$.
\end{theorem}

$F_\mu$ nondecreasing follows from monotonicity of $\mu$; right-continuity and \linebreak $\lim_{x \rightarrow -\infty} F_\mu(x) = 0$ follow from continuity of $\mu$ from above as if $x_n \downarrow x$ then $(-\infty, x_n] \downarrow (-\infty, x]$ and $(-\infty, -n] \downarrow \emptyset$. The fact that $\lim_{x \rightarrow \infty} F_\mu(x) = 1$ follows from continuity of $\mu$ from below as $(-\infty, n] \uparrow \R$.

\medskip

In Isabelle this expands to

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ cdf{\isacharunderscore}nondecreasing\ {\isacharbrackleft}rule{\isacharunderscore}format{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymforall}x\ y{\isachardot}\ x\ {\isasymle}\ y\ {\isasymlongrightarrow}\ cdf\ M\ x\ {\isasymle}\ cdf\ M\ y{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ cdf{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ finite{\isacharunderscore}measure{\isacharunderscore}mono{\isacharparenright}%
\isanewline\isanewline%
\isacommand{lemma}\isamarkupfalse%
\ cdf{\isacharunderscore}is{\isacharunderscore}right{\isacharunderscore}cont{\isacharcolon}\ {\isachardoublequoteopen}continuous\ {\isacharparenleft}at{\isacharunderscore}right\ a{\isacharparenright}\ {\isacharparenleft}cdf\ M{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ continuous{\isacharunderscore}within\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}at{\isacharunderscore}right{\isacharunderscore}sequentially{\isacharbrackleft}\isakeyword{where}\ b{\isacharequal}{\isachardoublequoteopen}a\ {\isacharplus}\ {\isadigit{1}}{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{fix}\isamarkupfalse%
\ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\ \isakeyword{and}\ x\ \isacommand{assume}\isamarkupfalse%
\ f{\isacharcolon}\ {\isachardoublequoteopen}decseq\ f{\isachardoublequoteclose}\ {\isachardoublequoteopen}f\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ a{\isachardoublequoteclose}\isanewline
\ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ cdf\ M\ {\isacharparenleft}f\ n{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ measure\ M\ {\isacharparenleft}{\isasymInter}i{\isachardot}\ {\isacharbraceleft}{\isachardot}{\isachardot}\ f\ i{\isacharbraceright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ cdf{\isacharunderscore}def\ \isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}intro\ finite{\isacharunderscore}Lim{\isacharunderscore}measure{\isacharunderscore}decseq{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ {\isacharbackquoteopen}decseq\ f{\isacharbackquoteclose}\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp{\isacharcolon}\ decseq{\isacharunderscore}def{\isacharparenright}\isanewline
\ \ \ \ \isacommand{done}\isamarkupfalse%
\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymInter}i{\isachardot}\ {\isacharbraceleft}{\isachardot}{\isachardot}\ f\ i{\isacharbraceright}{\isacharparenright}\ {\isacharequal}\ {\isacharbraceleft}{\isachardot}{\isachardot}\ a{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ decseq{\isacharunderscore}le{\isacharbrackleft}OF\ f{\isacharbrackright}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharcolon}\ order{\isacharunderscore}trans\ LIMSEQ{\isacharunderscore}le{\isacharunderscore}const{\isacharbrackleft}OF\ f{\isacharparenleft}{\isadigit{2}}{\isacharparenright}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ cdf\ M\ {\isacharparenleft}f\ n{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ cdf\ M\ a{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ cdf{\isacharunderscore}def{\isacharparenright}\isanewline
\isacommand{qed}\isamarkupfalse%
\ simp%
\isanewline\isanewline%
\isacommand{lemma}\isamarkupfalse%
\ cdf{\isacharunderscore}lim{\isacharunderscore}at{\isacharunderscore}bot{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}cdf\ M\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{0}}{\isacharparenright}\ at{\isacharunderscore}bot{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\ \isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}{\isacharparenleft}{\isacharpercent}x\ {\isacharcolon}{\isacharcolon}\ real{\isachardot}\ {\isacharminus}\ cdf\ M\ {\isacharparenleft}{\isacharminus}\ x{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{0}}{\isacharparenright}\ at{\isacharunderscore}top{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}at{\isacharunderscore}topI{\isacharunderscore}sequentially{\isacharunderscore}real{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ mono{\isacharunderscore}def\ cdf{\isacharunderscore}nondecreasing\ cdf{\isacharunderscore}lim{\isacharunderscore}neg{\isacharunderscore}infty{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ cdf{\isacharunderscore}lim{\isacharunderscore}neg{\isacharunderscore}infty\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}metis\ minus{\isacharunderscore}zero\ tendsto{\isacharunderscore}minus{\isacharunderscore}cancel{\isacharunderscore}left{\isacharparenright}\isanewline
\ \ \isacommand{from}\isamarkupfalse%
\ filterlim{\isacharunderscore}compose\ {\isacharbrackleft}OF\ {\isadigit{1}}{\isacharcomma}\ OF\ filterlim{\isacharunderscore}uminus{\isacharunderscore}at{\isacharunderscore}top{\isacharunderscore}at{\isacharunderscore}bot{\isacharbrackright}\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}thesis\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}metis\ {\isachardoublequoteopen}{\isadigit{1}}{\isachardoublequoteclose}\ filterlim{\isacharunderscore}at{\isacharunderscore}bot{\isacharunderscore}mirror\ minus{\isacharunderscore}zero\ tendsto{\isacharunderscore}minus{\isacharunderscore}cancel{\isacharunderscore}left{\isacharparenright}\isanewline
\isacommand{qed}\isamarkupfalse%
\isanewline\isanewline%
\isacommand{lemma}\isamarkupfalse%
\ cdf{\isacharunderscore}lim{\isacharunderscore}at{\isacharunderscore}top{\isacharunderscore}prob{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}cdf\ M\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{1}}{\isacharparenright}\ at{\isacharunderscore}top{\isachardoublequoteclose}\ \isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ prob{\isacharunderscore}space\ {\isacharbrackleft}symmetric{\isacharbrackright}{\isacharcomma}\ rule\ cdf{\isacharunderscore}lim{\isacharunderscore}at{\isacharunderscore}top{\isacharparenright}%
\end{isabellebody}

\medskip

The annotation \texttt{[rule\_format]} indicates that the universally quantified variables may be freely instantiated by Isabelle's automated tools, and that the implication may be used to refine a subgoal (replacing the consequent with the antecedent). 

In turn, any function with the properties listed in the preceding theorem is the distribution function of a probability measure on $\R$:

\begin{theorem}
Suppose $F\colon \R \rightarrow \R$ is nondecreasing, right-continuous, and satisfies $\lim_{x \rightarrow -\infty} F(x) = 0$ and $\lim_{x \rightarrow \infty} F(x) = 1$. Then there exists a Borel probability measure $\mu$ on $\R$ such that $F = F_\mu$.
\end{theorem}

The requisite measure $\mu$ is constructed by defining $\mu (a,b] = F(b) - F(a)$ and extending this to the Borel $\sigma$-algebra using the Carath\'eodory extension theorem, which Johannes H\"olzl had already formalized. In Isabelle this is

\newpage

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ real{\isacharunderscore}distribution{\isacharunderscore}interval{\isacharunderscore}measure{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ F\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ nondecF\ {\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}\ x\ y{\isachardot}\ x\ {\isasymle}\ y\ {\isasymLongrightarrow}\ F\ x\ {\isasymle}\ F\ y{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ right{\isacharunderscore}cont{\isacharunderscore}F\ {\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}a{\isachardot}\ continuous\ {\isacharparenleft}at{\isacharunderscore}right\ a{\isacharparenright}\ F{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ lim{\isacharunderscore}F{\isacharunderscore}at{\isacharunderscore}bot\ {\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}F\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{0}}{\isacharparenright}\ at{\isacharunderscore}bot{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ lim{\isacharunderscore}F{\isacharunderscore}at{\isacharunderscore}top\ {\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}F\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{1}}{\isacharparenright}\ at{\isacharunderscore}top{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ {\isacharparenleft}interval{\isacharunderscore}measure\ F{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{let}\isamarkupfalse%
\ {\isacharquery}F\ {\isacharequal}\ {\isachardoublequoteopen}interval{\isacharunderscore}measure\ F{\isachardoublequoteclose}\isanewline
\ \ \isacommand{interpret}\isamarkupfalse%
\ prob{\isacharunderscore}space\ {\isacharquery}F\isanewline
\ \ \isacommand{proof}\isamarkupfalse%
\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}ereal\ {\isacharparenleft}{\isadigit{1}}\ {\isacharminus}\ {\isadigit{0}}{\isacharparenright}\ {\isacharequal}\ {\isacharparenleft}SUP\ i{\isacharcolon}{\isacharcolon}nat{\isachardot}\ ereal\ {\isacharparenleft}F\ {\isacharparenleft}real\ i{\isacharparenright}\ {\isacharminus}\ F\ {\isacharparenleft}{\isacharminus}\ real\ i{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}intro\ LIMSEQ{\isacharunderscore}unique{\isacharbrackleft}OF\ {\isacharunderscore}\ LIMSEQ{\isacharunderscore}SUP{\isacharbrackright}\ lim{\isacharunderscore}ereal{\isacharbrackleft}THEN\ iffD{\isadigit{2}}{\isacharbrackright}\ tendsto{\isacharunderscore}intros\isanewline
\ \ \ \ \ \ \ \ \ lim{\isacharunderscore}F{\isacharunderscore}at{\isacharunderscore}bot{\isacharbrackleft}THEN\ filterlim{\isacharunderscore}compose{\isacharbrackright}\ lim{\isacharunderscore}F{\isacharunderscore}at{\isacharunderscore}top{\isacharbrackleft}THEN\ filterlim{\isacharunderscore}compose{\isacharbrackright}\isanewline
\ \ \ \ \ \ \ \ \ lim{\isacharunderscore}F{\isacharunderscore}at{\isacharunderscore}bot{\isacharbrackleft}THEN\ filterlim{\isacharunderscore}compose{\isacharbrackright}\ filterlim{\isacharunderscore}real{\isacharunderscore}sequentially\isanewline
\ \ \ \ \ \ \ \ \ filterlim{\isacharunderscore}uminus{\isacharunderscore}at{\isacharunderscore}top{\isacharbrackleft}THEN\ iffD{\isadigit{1}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ \ \ \ \ {\isacharparenleft}auto\ simp{\isacharcolon}\ incseq{\isacharunderscore}def\ intro{\isacharbang}{\isacharcolon}\ diff{\isacharunderscore}mono\ nondecF{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ {\isacharparenleft}SUP\ i{\isacharcolon}{\isacharcolon}nat{\isachardot}\ emeasure\ {\isacharquery}F\ {\isacharbraceleft}{\isacharminus}\ real\ i{\isacharless}{\isachardot}{\isachardot}real\ i{\isacharbraceright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ emeasure{\isacharunderscore}interval{\isacharunderscore}measure{\isacharunderscore}Ioc{\isacharparenright}\ {\isacharparenleft}simp{\isacharunderscore}all\ add{\isacharcolon}\ nondecF\ right{\isacharunderscore}cont{\isacharunderscore}F{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ emeasure\ {\isacharquery}F\ {\isacharparenleft}{\isasymUnion}i{\isacharcolon}{\isacharcolon}nat{\isachardot}\ {\isacharbraceleft}{\isacharminus}\ real\ i{\isacharless}{\isachardot}{\isachardot}real\ i{\isacharbraceright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ SUP{\isacharunderscore}emeasure{\isacharunderscore}incseq{\isacharparenright}\ {\isacharparenleft}auto\ simp{\isacharcolon}\ incseq{\isacharunderscore}def{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymUnion}i{\isachardot}\ {\isacharbraceleft}{\isacharminus}\ real\ {\isacharparenleft}i{\isacharcolon}{\isacharcolon}nat{\isacharparenright}{\isacharless}{\isachardot}{\isachardot}real\ i{\isacharbraceright}{\isacharparenright}\ {\isacharequal}\ space\ {\isacharquery}F{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ UN{\isacharunderscore}Ioc{\isacharunderscore}eq{\isacharunderscore}UNIV{\isacharparenright}\isanewline
\ \ \ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}emeasure\ {\isacharquery}F\ {\isacharparenleft}space\ {\isacharquery}F{\isacharparenright}\ {\isacharequal}\ {\isadigit{1}}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ one{\isacharunderscore}ereal{\isacharunderscore}def{\isacharparenright}\isanewline
\ \ \isacommand{qed}\isamarkupfalse%
\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}thesis\isanewline
\ \ \ \ \isacommand{proof}\isamarkupfalse%
\ \isacommand{qed}\isamarkupfalse%
\ simp{\isacharunderscore}all\isanewline
\isacommand{qed}\isamarkupfalse%
\end{isabellebody}

\medskip

Here \texttt{real\_distribution} is a locale for Borel probability measures, and \texttt{interval\_measure} is a function defined by H\"olzl which generates a measure from a nondecreasing, right-continuous function. Note the calculation paradigm \texttt{have...also have...finally show}; this is Isar syntax for chaining equations and is very convenient for writing calculations in Isar as opposed to a tactic style.

A method of proof similar to that used to prove all nondecreasing right-continuous functions with the appropriate limits at $\pm \infty$ are distribution functions also gives that the distribution function of a probability measure is unique in the sense that if $F_\mu = F_\nu$ then $\mu = \nu$, because $F_\mu = F_\nu$ implies $\mu (a,b] = \nu (a,b]$ for every $a,b$, and the half-open intervals are a $\pi$-system generating the Borel sets on $\R$, so $\mu = \nu$ by Dynkin's uniqueness lemma\footnote{This is an easy consequence of the $\pi$-$\lambda$ theorem; see \cite{billingsley}, p. 42.}. In Isabelle this is

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ cdf{\isacharunderscore}unique{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ M{\isadigit{1}}\ M{\isadigit{2}}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isadigit{1}}{\isachardoublequoteclose}\ \isakeyword{and}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isadigit{2}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}cdf\ M{\isadigit{1}}\ {\isacharequal}\ cdf\ M{\isadigit{2}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}M{\isadigit{1}}\ {\isacharequal}\ M{\isadigit{2}}{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}rule\ measure{\isacharunderscore}eqI{\isacharunderscore}generator{\isacharunderscore}eq{\isacharbrackleft}\isakeyword{where}\ {\isasymOmega}{\isacharequal}UNIV{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{fix}\isamarkupfalse%
\ X\ \isacommand{assume}\isamarkupfalse%
\ {\isachardoublequoteopen}X\ {\isasymin}\ range\ {\isacharparenleft}{\isasymlambda}{\isacharparenleft}a{\isacharcomma}\ b{\isacharparenright}{\isachardot}\ {\isacharbraceleft}a{\isacharless}{\isachardot}{\isachardot}b{\isacharcolon}{\isacharcolon}real{\isacharbraceright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{obtain}\isamarkupfalse%
\ a\ b\ \isakeyword{where}\ Xeq{\isacharcolon}\ {\isachardoublequoteopen}X\ {\isacharequal}\ {\isacharbraceleft}a{\isacharless}{\isachardot}{\isachardot}b{\isacharbraceright}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}emeasure\ M{\isadigit{1}}\ X\ {\isacharequal}\ emeasure\ M{\isadigit{2}}\ X{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}cases\ {\isachardoublequoteopen}a\ {\isasymle}\ b{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \ \ \ \ \ {\isacharparenleft}simp{\isacharunderscore}all\ add{\isacharcolon}\ assms{\isacharparenleft}{\isadigit{1}}{\isacharcomma}{\isadigit{2}}{\isacharparenright}{\isacharbrackleft}THEN\ real{\isacharunderscore}distribution{\isachardot}emeasure{\isacharunderscore}Ioc{\isacharbrackright}\ assms{\isacharparenleft}{\isadigit{3}}{\isacharparenright}{\isacharparenright}\isanewline
\isacommand{next}\isamarkupfalse%
\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymUnion}i{\isachardot}\ {\isacharbraceleft}{\isacharminus}\ real\ {\isacharparenleft}i{\isacharcolon}{\isacharcolon}nat{\isacharparenright}{\isacharless}{\isachardot}{\isachardot}real\ i{\isacharbraceright}{\isacharparenright}\ {\isacharequal}\ UNIV{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ UN{\isacharunderscore}Ioc{\isacharunderscore}eq{\isacharunderscore}UNIV{\isacharparenright}\isanewline
\isacommand{qed}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp{\isacharcolon}\ real{\isacharunderscore}distribution{\isachardot}emeasure{\isacharunderscore}Ioc{\isacharbrackleft}OF\ assms{\isacharparenleft}{\isadigit{1}}{\isacharparenright}{\isacharbrackright}\isanewline
\ \ assms{\isacharparenleft}{\isadigit{1}}{\isacharcomma}{\isadigit{2}}{\isacharparenright}{\isacharbrackleft}THEN\ real{\isacharunderscore}distribution{\isachardot}events{\isacharunderscore}eq{\isacharunderscore}borel{\isacharbrackright}\ borel{\isacharunderscore}sigma{\isacharunderscore}sets{\isacharunderscore}Ioc\isanewline
\ \ Int{\isacharunderscore}stable{\isacharunderscore}def{\isacharparenright}%
\end{isabellebody}

\subsection{Weak Convergence}

We are finally ready to give the definition of weak convergence. The fundamental notion is for distribution functions, and it immediately lifts to measures (distributions) and random variables.

\begin{definition}
A sequence $\bldseq{F_n}{n \in \N}$ of distribution functions {\em converges weakly} to a distribution function $F$ iff
\[ \lim_{n \rightarrow \infty} F_n(x) = F(x) \]
for every $x \in \R$ such that $F$ is continuous at $x$. A sequence $\bldseq{\mu_n}{n \in \N}$ of probability measures converges weakly to a probability measure $\mu$ iff the corresponding distribution functions converge weakly, and a sequence \linebreak $\bldseq{X_n}{n \in \N}$ of random variables converges weakly to a random variable $X$ iff the corresponding distributions converge weakly.
\end{definition}

To see why convergence is allowed to fail at continuity points of $F$, note that intuitively a sequence $\bldseq{\mu_n}{n \in \N}$ of unit masses at $a_n$ should converge to a unit mass $\mu$ at $a$ iff $a_n \rightarrow a$. The distribution functions $F_n$ of $\mu_n$ are two-valued, taking either the value zero or one, and so if $a_n > a$ for infinitely many $n$, $F_n(a)$ does not converge to $F(a)$ (since $F_n(a) = 0$ if $a_n > a$, while $F(a) = 1$). This example is taken from Billingsley \cite{billingsley}, and further explanation and examples can be found in sections 14 and 25 of that book.

In Isabelle we have:

\medskip

\begin{isabellebody}
\isacommand{definition}\isamarkupfalse%
\isanewline
\ \ weak{\isacharunderscore}conv\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}nat\ {\isasymRightarrow}\ {\isacharparenleft}real\ {\isasymRightarrow}\ real{\isacharparenright}{\isacharparenright}\ {\isasymRightarrow}\ {\isacharparenleft}real\ {\isasymRightarrow}\ real{\isacharparenright}\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\isanewline
\isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv\ F{\isacharunderscore}seq\ F\ {\isasymequiv}\ {\isasymforall}x{\isachardot}\ isCont\ F\ x\ {\isasymlongrightarrow}\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ F{\isacharunderscore}seq\ n\ x{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ F\ x{\isachardoublequoteclose}\isanewline\isanewline
\isacommand{definition}\isamarkupfalse%
\isanewline
\ \ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}nat\ {\isasymRightarrow}\ real\ measure{\isacharparenright}\ {\isasymRightarrow}\ real\ measure\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\isanewline
\isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ M{\isacharunderscore}seq\ M\ {\isasymequiv}\ weak{\isacharunderscore}conv\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ cdf\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}{\isacharparenright}\ {\isacharparenleft}cdf\ M{\isacharparenright}{\isachardoublequoteclose}\isanewline\isanewline
\isacommand{abbreviation}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ prob{\isacharunderscore}space{\isacharparenright}\isanewline
\ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}r\ X{\isacharunderscore}seq\ X\ {\isasymequiv}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ distr\ M\ borel\ {\isacharparenleft}X{\isacharunderscore}seq\ n{\isacharparenright}{\isacharparenright}\ {\isacharparenleft}distr\ M\ borel\ X{\isacharparenright}{\isachardoublequoteclose}
\end{isabellebody}

\medskip

One technical result we needed for working with weak convergence was the fact that a nondecreasing function $f\colon \R \rightarrow \R$ has just countably many discontinuities. For this we shall use the concept of the oscillation of a function. 

\begin{definition}
Let $f\colon \R \rightarrow \R$, and $x \in \R$. The {\em oscillation} of $f$ at $x$ is defined by
\[ \osc_x f = \limsup_{t \rightarrow x} f(t) - \liminf_{t \rightarrow x} f(t). \]
\end{definition}

Note that the oscillation is always nonnegative, and $f$ is continuous at $x$ iff $\osc_x f = 0$.

\begin{lemma}
Suppose $f\colon \R \rightarrow \R$ is nondecreasing. Then the discontinuity set $D = \bldset{x \in \R}{\osc_x f > 0}$ is countable.
\end{lemma}

\begin{proof}
We begin with showing that a finite interval contains at most countably many discontinuities of $f$. Suppose $a < b$, and let $D^{a,b}_k$ be the set of discontinuities of $f$ in the interval $[a,b]$ with oscillation at least $\frac{1}{k}$. Because $f$ is nondecreasing, $f(a) \le f(x) \le f(b)$ for every $x \in [a,b]$, and from the definition of oscillation it is immediate that for any $u > 0$, if $\osc_x f \ge u$, then $f(b) \ge f(a) + u$. Hence
\[ |D^{a,b}_k| \le \left\lfloor \frac{f(b) - f(a)}{k} \right\rfloor, \]
and in particular $D^{a,b}_k$ is finite. Thus we have that $D^{a,b} = \bigcup_{k \in \N} D^{a,b}_k$ is countable for every $a,b$ (being a countable union of finite sets), and hence so is \linebreak $D = \bigcup_{n \in \N} D^{-n,n}$.
\end{proof}

Rather than formalizing this directly, we formalized an argument which works for nondecreasing functions only defined on a subset $A \subseteq \R$, and concluded the above result from that. We omit the rather long proof of the more general result.

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ mono{\isacharunderscore}on{\isacharunderscore}ctble{\isacharunderscore}discont{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{fixes}\ A\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ set{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}mono{\isacharunderscore}on\ f\ A{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}countable\ {\isacharbraceleft}a{\isasymin}A{\isachardot}\ {\isasymnot}\ continuous\ {\isacharparenleft}at\ a\ within\ A{\isacharparenright}\ f{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ mono{\isacharunderscore}ctble{\isacharunderscore}discont{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}mono\ f{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}countable\ {\isacharbraceleft}a{\isachardot}\ {\isasymnot}\ isCont\ f\ a{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\isacommand{using}\isamarkupfalse%
\ assms\ mono{\isacharunderscore}on{\isacharunderscore}ctble{\isacharunderscore}discont\ {\isacharbrackleft}of\ f\ UNIV{\isacharbrackright}\ \isacommand{unfolding}\isamarkupfalse%
\ mono{\isacharunderscore}on{\isacharunderscore}def\ mono{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ auto%
\end{isabellebody}

\medskip

Another general lemma which we needed to formalize is the fact that nondecreasing functions on $\R$ are Borel measurable. This is intuitively because the preimage of a semi-infinite interval $(-\infty,x)$ under a monotone function is an interval, and the semi-infinite intervals generate the Borel $\sigma$-algebra on $\R$ (note they are a subbase for the open subsets of $\R$). In Isabelle we formalized something slightly more general, allowing application of the theorem when a function is only defined (or only of interest) on a subset of $\R$. This is useful in particular in the proof of Skorohod's theorem.

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ borel{\isacharunderscore}measurable{\isacharunderscore}mono{\isacharunderscore}on{\isacharunderscore}fnc{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\ \isakeyword{and}\ A\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ set{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}mono{\isacharunderscore}on\ f\ A{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}f\ {\isasymin}\ borel{\isacharunderscore}measurable\ {\isacharparenleft}restrict{\isacharunderscore}space\ borel\ A{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ measurable{\isacharunderscore}restrict{\isacharunderscore}countable{\isacharbrackleft}OF\ mono{\isacharunderscore}on{\isacharunderscore}ctble{\isacharunderscore}discont{\isacharbrackleft}OF\ assms{\isacharbrackright}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ image{\isacharunderscore}eqI{\isacharbrackleft}\isakeyword{where}\ x{\isacharequal}{\isachardoublequoteopen}{\isacharbraceleft}x{\isacharbraceright}{\isachardoublequoteclose}\ \isakeyword{for}\ x{\isacharbrackright}\ simp{\isacharcolon}\ sets{\isacharunderscore}restrict{\isacharunderscore}space{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ sets{\isacharunderscore}restrict{\isacharunderscore}restrict{\isacharunderscore}space\ continuous{\isacharunderscore}on{\isacharunderscore}eq{\isacharunderscore}continuous{\isacharunderscore}within\isanewline
\ \ \ \ \ \ \ \ \ \ \ \ \ \ cong{\isacharcolon}\ measurable{\isacharunderscore}cong{\isacharunderscore}sets\ \isanewline
\ \ \ \ \ \ \ \ \ \ \ \ \ \ intro{\isacharbang}{\isacharcolon}\ borel{\isacharunderscore}measurable{\isacharunderscore}continuous{\isacharunderscore}on{\isacharunderscore}restrict\ intro{\isacharcolon}\ continuous{\isacharunderscore}within{\isacharunderscore}subset{\isacharparenright}\isanewline
\ \ \isacommand{done}\isamarkupfalse%
\end{isabellebody}

\medskip

Though weak convergence has the advantage of being a flexible notion which applies much more generally than such notions as almost sure convergence or convergence in probability, it is often difficult to work with directly. The following theorem, known as Skorohod's theorem, allows one to replace weak convergence with pointwise convergence under appropriate conditions.

\begin{theorem}
Let $\bldseq{\mu_n}{n \in \N}$, $\mu$ be probability measures on the $\R$, and suppose $\mu_n \Rightarrow \mu$. Then there exists a probability space $(\Omega, \mathcal F, \P)$ and random variables $\bldseq{Y_n}{n \in \N}$, $Y$ on $\Omega$ such that $Y_n \sim \mu_n$ for each $n$, $Y \sim \mu$, and $Y_n \rightarrow Y$ pointwise.
\end{theorem}

\begin{proof}
The probability space will be simply the unit interval $(0,1)$ with Lebesgue measure. For each $n$, let $F_n$ be the distribution function of $\mu_n$, and $F$ be the distribution function of $\mu$. Let $Y_n$ be the pseudoinverse of the nondecreasing function $F_n$, that is $Y_n(\omega) = \inf \bldset{x \in \R}{\omega \le F_n(x)}$ for $\omega \in (0,1)$, and similarly $Y(\omega) = \inf \bldset{x \in \R}{\omega \le F(x)}$. Thus we have that for any $\omega \in (0,1)$, $x \in \R$, and $n \in \N$, $\omega \le F_n(x)$ iff $Y_n(\omega) \le x$, and similarly $\omega \le F(x)$ iff $Y(\omega) \le x$. Consequently
\[ \P(Y_n \le x) = \P \bldset{\omega \in (0,1)}{\omega \le F_n(x)} = F_n(x), \]
and so $F_n$ is the distribution function of $Y_n$. By the same reasoning $F$ is the distribution function of $Y$.

The idea of the proof that $Y_n \rightarrow Y$ pointwise is that we know $F_n \Rightarrow F$, and because $Y_n$ is the pseudoinverse of $F_n$ and $Y$ is the pseudoinverse of $F$, this is sufficient for $Y_n(\omega)$ to converge to $Y(\omega)$ for almost all $\omega \in (0,1)$. Note that this is certainly true in case $F_n$, $F$ are continuous (in which case $Y_n$, $Y$ are literal inverses of $F_n$, $F$).

Let $\omega \in (0,1)$ and $\eps > 0$. Choose $x$ such that $Y(\omega) - \eps < x < Y(\omega)$ and $\mu \{x\} = 0$, so $x$ is a continuity point of $F$ and $F_n(x) \rightarrow F(x)$. It is immediate from the definition of $Y$ that $F(x) < \omega$, and so for sufficiently large $n$ we have $F_n(x) < \omega$, which in turn gives $Y(\omega) - \eps < x < Y_n(\omega)$. Hence $\liminf_{n \rightarrow \infty} Y_n(\omega) \ge Y(\omega)$.

Now let $\omega' \in (0,1)$ and $\eps > 0$, and suppose $\omega \in (0,1)$ and $\omega < \omega'$. Choose $y$ a continuity point of $F$ (so $\mu \{y\} = 0$) such that $Y(\omega') < y < Y(\omega') + \eps$. From the definition of $Y$ we have $\omega < \omega' \le F(Y(\omega')) \le F(y)$, and thus for sufficiently large $n$, $\omega \le F_n(y)$, which gives $Y_n(\omega) \le y < Y(\omega') + \eps$ and hence $\limsup_{n \rightarrow \infty} Y_n(\omega) \le Y(\omega')$. Since this holds for arbitrary $\omega < \omega'$, we have that $Y_n(\omega) \rightarrow Y(\omega)$ if $Y$ is continuous at $\omega$.

It is immediate from the definition of $Y$ and the fact that $F$ is nondecreasing that $Y$ is nondecreasing, and hence has at most countably many discontinuities, a set of Lebesgue measure zero. Thus we may redefine $Y_n$, $Y$ to be zero at all the discontinuities of $Y$ without affecting the distributions of these random variables, and obtain $Y_n(\omega) \rightarrow Y(\omega)$ for every $\omega \in (0,1)$.
\end{proof}

This proof presented a number of technical challenges for formalization. For one, we needed to choose a continuity point of an arbitrary probability measure in an arbitrary  open interval. For this we needed to know that the set of continuity points of an arbitrary finite measure is dense. To see that, recall that there are at most countably many atoms, and note that the complement of a countable set is dense. Rather than formalizing directly the fact that the complement of a countable set is dense, we simply proved that an interval is uncountable and so the result of subtracting the set of atoms is still uncountable, and hence nonempty.

Here is our formalization of the fact that a finite measure has countably many atoms:

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ countable{\isacharunderscore}atoms{\isacharcolon}\ {\isachardoublequoteopen}countable\ {\isacharbraceleft}x{\isachardot}\ measure\ M\ {\isacharbraceleft}x{\isacharbraceright}\ {\isachargreater}\ {\isadigit{0}}{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{{\isacharbraceleft}}\isamarkupfalse%
\ \isacommand{fix}\isamarkupfalse%
\ B\ i\isanewline
\ \ \ \ \isacommand{assume}\isamarkupfalse%
\ finB{\isacharcolon}\ {\isachardoublequoteopen}finite\ B{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ \ \ subB{\isacharcolon}\ {\isachardoublequoteopen}B\ {\isasymsubseteq}\ {\isacharbraceleft}x{\isachardot}\ inverse\ {\isacharparenleft}real\ {\isacharparenleft}Suc\ i{\isacharparenright}{\isacharparenright}\ {\isacharless}\ Sigma{\isacharunderscore}Algebra{\isachardot}measure\ M\ {\isacharbraceleft}x{\isacharbraceright}{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}measure\ M\ B\ {\isacharequal}\ {\isacharparenleft}{\isasymSum}x{\isasymin}B{\isachardot}\ measure\ M\ {\isacharbraceleft}x{\isacharbraceright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ measure{\isacharunderscore}eq{\isacharunderscore}setsum{\isacharunderscore}singleton\ {\isacharbrackleft}OF\ finB{\isacharbrackright}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isasymge}\ {\isacharparenleft}{\isasymSum}x{\isasymin}B{\isachardot}\ inverse\ {\isacharparenleft}real\ {\isacharparenleft}Suc\ i{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\ {\isacharparenleft}\isakeyword{is}\ {\isachardoublequoteopen}{\isacharquery}lhs\ {\isasymge}\ {\isacharquery}rhs{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{using}\isamarkupfalse%
\ subB\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}intro\ setsum{\isacharunderscore}mono{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ {\isacharparenleft}xtrans{\isacharparenright}\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharquery}rhs\ {\isacharequal}\ card\ B\ {\isacharasterisk}\ inverse\ {\isacharparenleft}real\ {\isacharparenleft}Suc\ i{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}measure\ M\ B\ {\isasymge}\ card\ B\ {\isacharasterisk}\ inverse\ {\isacharparenleft}real\ {\isacharparenleft}Suc\ i{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\ \isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\ \ \isacommand{{\isacharbraceright}}\isamarkupfalse%
\ \isacommand{note}\isamarkupfalse%
\ {\isacharasterisk}\ {\isacharequal}\ this\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}measure\ M\ {\isacharparenleft}space\ M{\isacharparenright}\ {\isacharless}\ real\ {\isacharparenleft}Suc\ {\isacharparenleft}nat\ {\isacharparenleft}ceiling\ {\isacharparenleft}measure\ M\ {\isacharparenleft}space\ M{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ del{\isacharcolon}\ zero{\isacharunderscore}le{\isacharunderscore}ceiling\isanewline
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ simp\ add{\isacharcolon}\ measure{\isacharunderscore}nonneg\ ceiling{\isacharunderscore}nonneg\ intro{\isacharbang}{\isacharcolon}\ less{\isacharunderscore}add{\isacharunderscore}one{\isacharparenright}\isanewline
\ \ \ \ \ \ \ linarith\isanewline
\ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{obtain}\isamarkupfalse%
\ X\ {\isacharcolon}{\isacharcolon}\ nat\ \isakeyword{where}\ X{\isacharcolon}\ {\isachardoublequoteopen}measure\ M\ {\isacharparenleft}space\ M{\isacharparenright}\ {\isacharless}\ X{\isachardoublequoteclose}\ \isacommand{{\isachardot}{\isachardot}}\isamarkupfalse%
\isanewline
\ \ \isanewline
\ \ \isacommand{{\isacharbraceleft}}\isamarkupfalse%
\ \isacommand{fix}\isamarkupfalse%
\ i\ {\isacharcolon}{\isacharcolon}\ nat\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}finite\ {\isacharbraceleft}x{\isachardot}\ inverse\ {\isacharparenleft}real\ {\isacharparenleft}Suc\ i{\isacharparenright}{\isacharparenright}\ {\isacharless}\ Sigma{\isacharunderscore}Algebra{\isachardot}measure\ M\ {\isacharbraceleft}x{\isacharbraceright}{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ ccontr{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}drule\ infinite{\isacharunderscore}arbitrarily{\isacharunderscore}large\ {\isacharbrackleft}of\ {\isacharunderscore}\ {\isachardoublequoteopen}X\ {\isacharasterisk}\ Suc\ i{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ clarify\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}drule\ {\isacharasterisk}{\isacharcomma}\ assumption{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}drule\ leD{\isacharcomma}\ erule\ notE{\isacharcomma}\ erule\ ssubst{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ of{\isacharunderscore}nat{\isacharunderscore}mult{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ mult{\isachardot}assoc{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ right{\isacharunderscore}inverse{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ simp{\isacharunderscore}all\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ order{\isacharunderscore}le{\isacharunderscore}less{\isacharunderscore}trans\ {\isacharbrackleft}OF\ bounded{\isacharunderscore}measure\ X{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{{\isacharbraceright}}\isamarkupfalse%
\ \isacommand{note}\isamarkupfalse%
\ {\isacharasterisk}{\isacharasterisk}\ {\isacharequal}\ this\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharbraceleft}x{\isachardot}\ measure\ M\ {\isacharbraceleft}x{\isacharbraceright}\ {\isachargreater}\ {\isadigit{0}}{\isacharbraceright}\ {\isacharequal}\ {\isacharparenleft}{\isasymUnion}i\ {\isacharcolon}{\isacharcolon}\ nat{\isachardot}\ {\isacharbraceleft}x{\isachardot}\ measure\ M\ {\isacharbraceleft}x{\isacharbraceright}\ {\isachargreater}\ inverse\ {\isacharparenleft}Suc\ i{\isacharparenright}{\isacharbraceright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharcolon}\ reals{\isacharunderscore}Archimedean{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ ex{\isacharunderscore}inverse{\isacharunderscore}of{\isacharunderscore}nat{\isacharunderscore}Suc{\isacharunderscore}less\ \isacommand{apply}\isamarkupfalse%
\ auto\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}metis\ inverse{\isacharunderscore}positive{\isacharunderscore}iff{\isacharunderscore}positive\ less{\isacharunderscore}trans\ of{\isacharunderscore}nat{\isacharunderscore}{\isadigit{0}}{\isacharunderscore}less{\isacharunderscore}iff\ of{\isacharunderscore}nat{\isacharunderscore}Suc\ zero{\isacharunderscore}less{\isacharunderscore}Suc{\isacharparenright}\isanewline
\ \ \isacommand{thus}\isamarkupfalse%
\ {\isachardoublequoteopen}countable\ {\isacharbraceleft}x{\isachardot}\ measure\ M\ {\isacharbraceleft}x{\isacharbraceright}\ {\isachargreater}\ {\isadigit{0}}{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}elim\ ssubst{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ countable{\isacharunderscore}UN{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ countable{\isacharunderscore}finite{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ {\isacharasterisk}{\isacharasterisk}\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\isacommand{qed}\isamarkupfalse%
\end{isabellebody}

\medskip

And here is our formal statement of Skorohod's theorem; the proof is very long, and we do not include it.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ Skorohod{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ {\isasymmu}\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}{\isasymmu}\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isasymmu}\ M{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isasymexists}\ {\isacharparenleft}{\isasymOmega}\ {\isacharcolon}{\isacharcolon}\ real\ measure{\isacharparenright}\ {\isacharparenleft}Y{\isacharunderscore}seq\ {\isacharcolon}{\isacharcolon}\ nat\ {\isasymRightarrow}\ real\ {\isasymRightarrow}\ real{\isacharparenright}\ {\isacharparenleft}Y\ {\isacharcolon}{\isacharcolon}\ real\ {\isasymRightarrow}\ real{\isacharparenright}{\isachardot}\ \isanewline
\ \ \ \ prob{\isacharunderscore}space\ {\isasymOmega}\ {\isasymand}\isanewline
\ \ \ \ {\isacharparenleft}{\isasymforall}n{\isachardot}\ Y{\isacharunderscore}seq\ n\ {\isasymin}\ measurable\ {\isasymOmega}\ borel{\isacharparenright}\ {\isasymand}\isanewline
\ \ \ \ {\isacharparenleft}{\isasymforall}n{\isachardot}\ distr\ {\isasymOmega}\ borel\ {\isacharparenleft}Y{\isacharunderscore}seq\ n{\isacharparenright}\ {\isacharequal}\ {\isasymmu}\ n{\isacharparenright}\ {\isasymand}\isanewline
\ \ \ \ Y\ {\isasymin}\ measurable\ {\isasymOmega}\ lborel\ {\isasymand}\isanewline
\ \ \ \ distr\ {\isasymOmega}\ borel\ Y\ {\isacharequal}\ M\ {\isasymand}\isanewline
\ \ \ \ {\isacharparenleft}{\isasymforall}x\ {\isasymin}\ space\ {\isasymOmega}{\isachardot}\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ Y{\isacharunderscore}seq\ n\ x{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ Y\ x{\isacharparenright}{\isachardoublequoteclose}
\end{isabellebody}

\medskip

Another important fact which will be needed later is that a sequence \linebreak $\bldseq{\mu_n}{n \in \N}$ of probability measures converges weakly to a probability measure $\mu$ if and only if it converges to $\mu$ in the weak* topology of functional analysis. Weak* convergence of a sequence of probability measures can be defined in a variety of ways; two common ones are
\[ \lim_{n \rightarrow \infty} \int f \, d\mu_n = \int f \, d\mu \]
for every bounded continuous real-valued function $f$, and
\[ \lim_{n \rightarrow \infty} \mu_n(A) = \mu(A) \]
for every set $A$ such that $\mu(\partial A) = 0$ (where $\partial A$ is the boundary of $A$). The equivalence of weak convergence of probability measures with these two definitions of weak* convergence is called the portmanteau theorem.

\begin{theorem}
Let $\bldseq{\mu_n}{n \in \N}$ be a sequence of measures on $\R$. The following are equivalent:
\begin{enumerate}
\item $\mu_n \Rightarrow \mu$.
\item For each bounded continuous $f\colon \R \rightarrow \R$, $\int f \, d\mu_n \rightarrow \int f \, d\mu$.
\item If $\mu(\partial A) = 0$, then $\mu_n(A) \rightarrow \mu(A)$.
\end{enumerate}
\end{theorem}

\begin{proof}
We prove $(1) \Longleftrightarrow (2)$ and $(1) \Longleftrightarrow (3)$.

$(1) \Longrightarrow (2)$: Assume $\mu_n \Rightarrow \mu$. Let $Y_n \sim \mu_n$ and $Y \sim \mu$ be random variables on a probability space $(\Omega, \mathcal F, \P)$ such that $Y_n \rightarrow Y$ pointwise, the existence of such random variables being guaranteed by Skorohod's theorem. Let $f\colon \R \rightarrow \R$ be a bounded continuous function. Then $f \circ Y_n \rightarrow f \circ Y$ pointwise, and so changing variables using $Y_n$, $Y$ and invoking the bounded convergence theorem yields
\[ \int f \, d\mu_n = \int f \circ Y_n \, d\P \rightarrow \int f \circ Y \, d\P = \int f \, d\mu. \]

$(2) \Longrightarrow (1)$: For each $n$, let $F_n$ be the distribution function of $\mu_n$, and let $F$ be the distribution function of $\mu$. For $x < y$, define $f$ by
\[ f(t) = \begin{cases} 1 & \text{if $t < x$} \\
                        \frac{y - t}{y - x} & \text{if $x \le t \le y$} \\
                        0 & \text{if $y < t$} \end{cases} \]
Note that $f$ is continuous and bounded. For each $n$, $F_n(x) \le \int f \, d\mu_n$, and $\int f \, d\mu \le F(y)$, so by $(2)$ we have $\limsup_{n \rightarrow \infty} F_n(x) \le F(y)$. and so because $y > x$ was arbitrary and $F$ is right continuous, in fact $\limsup_{n \rightarrow \infty} F_n(x) \le F(x)$. A similar argument gives that $F(u) \le \liminf_{n \rightarrow \infty} F_n(x)$ for $u < x$, and so $\sup_{u < x} F(u) \le \liminf_{n \rightarrow \infty} F_n(x)$. If $F$ is continuous at $x$, then $\sup_{u < x} F(u) = F(x)$, and so we obtain $F_n(x) \rightarrow F(x)$, which gives $\mu_n \Rightarrow \mu$.

$(1) \Longleftrightarrow (3)$: The proof of $(1) \Longrightarrow (2)$ goes through if the hypothesis that $f$ is continuous is weakened to the hypothesis that $f$ is measurable and the discontinuity set of $f$ has $\mu$-measure zero: merely weaken $f \circ Y_n \rightarrow f \circ Y$ pointwise to convergence almost surely (with respect to $\mu$), and the rest of the proof is exactly the same. In particular, if $A \subseteq \R$ is measurable and \linebreak $f = \mathbbm 1_A$, then $f$ is bounded and has discontinuity set $\partial A$, so if $\mu(\partial A) = 0$, then $\int \mathbbm 1_A \, d\mu_n \rightarrow \int \mathbbm 1_A \, d\mu$, which is to say, $\mu_n(A) \rightarrow \mu(A)$. The converse is an immediate consequence of the definition of weak convergence and the fact that $\partial (-\infty, x] = \{x\}$.
\end{proof}

Rather than formalize this as a single result, we formalized various implications. First, we have the fact that $\mu_n \Rightarrow \mu$ implies $\int f \, d\mu_n \rightarrow \int f \, d\mu$ for $f$ measurable and bounded with a discontinuity set of $\mu$-measure zero.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ weak{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}bdd{\isacharunderscore}ae{\isacharunderscore}continuous{\isacharunderscore}conv{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ M{\isacharunderscore}seq\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ {\isacharprime}a{\isacharcolon}{\isacharcolon}{\isacharbraceleft}banach{\isacharcomma}\ second{\isacharunderscore}countable{\isacharunderscore}topology{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ distr{\isacharunderscore}M{\isacharunderscore}seq{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ distr{\isacharunderscore}M{\isacharcolon}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ wcM{\isacharcolon}\ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ M{\isacharunderscore}seq\ M{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ discont{\isacharunderscore}null{\isacharcolon}\ {\isachardoublequoteopen}M\ {\isacharparenleft}{\isacharbraceleft}x{\isachardot}\ {\isasymnot}\ isCont\ f\ x{\isacharbraceright}{\isacharparenright}\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ f{\isacharunderscore}bdd{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}x{\isachardot}\ norm\ {\isacharparenleft}f\ x{\isacharparenright}\ {\isasymle}\ B{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isacharbrackleft}measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}f\ {\isasymin}\ borel{\isacharunderscore}measurable\ borel{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}\ n{\isachardot}\ integral\isactrlsup L\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}\ f{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ integral\isactrlsup L\ M\ f{\isachardoublequoteclose}
\end{isabellebody}

\medskip

This of course immediately gives $(1) \Longrightarrow (2)$ from the informal theorem. The annotation \texttt{[measurable]} indicates that this fact should be used by a specialized tool for checking measurability of sets and functions, called \texttt{measurable} and implemented by H\"olzl. 

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ weak{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}integral{\isacharunderscore}bdd{\isacharunderscore}continuous{\isacharunderscore}conv{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ M{\isacharunderscore}seq\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ {\isacharprime}a{\isacharcolon}{\isacharcolon}{\isacharbraceleft}banach{\isacharcomma}\ second{\isacharunderscore}countable{\isacharunderscore}topology{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ M{\isacharunderscore}seq\ M{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isachardoublequoteopen}{\isasymAnd}x{\isachardot}\ isCont\ f\ x{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isachardoublequoteopen}{\isasymAnd}x{\isachardot}\ norm\ {\isacharparenleft}f\ x{\isacharparenright}\ {\isasymle}\ B{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}\ n{\isachardot}\ integral\isactrlsup L\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}\ f{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ integral\isactrlsup L\ M\ f{\isachardoublequoteclose}\isanewline
\isacommand{using}\isamarkupfalse%
\ assms\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}intro\ weak{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}bdd{\isacharunderscore}ae{\isacharunderscore}continuous{\isacharunderscore}conv{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ borel{\isacharunderscore}measurable{\isacharunderscore}continuous{\isacharunderscore}on{\isadigit{1}}{\isacharparenright}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ continuous{\isacharunderscore}at{\isacharunderscore}imp{\isacharunderscore}continuous{\isacharunderscore}on{\isacharcomma}\ auto{\isacharparenright}%
\end{isabellebody}

\medskip

As in the informal treatment, $(1) \Longrightarrow (3)$ can now be obtained in a straightforward manner.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ weak{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}continuity{\isacharunderscore}set{\isacharunderscore}conv{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ M{\isacharunderscore}seq\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}{\isachardoublequoteclose}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ M{\isacharunderscore}seq\ M{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isacharbrackleft}measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}A\ {\isasymin}\ sets\ borel{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isachardoublequoteopen}M\ {\isacharparenleft}frontier\ A{\isacharparenright}\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}\ n{\isachardot}\ {\isacharparenleft}measure\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}\ A{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ measure\ M\ A{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{interpret}\isamarkupfalse%
\ M{\isacharcolon}\ real{\isacharunderscore}distribution\ M\ \isacommand{by}\isamarkupfalse%
\ fact\isanewline
\ \ \isacommand{interpret}\isamarkupfalse%
\ M{\isacharunderscore}seq{\isacharcolon}\ real{\isacharunderscore}distribution\ {\isachardoublequoteopen}M{\isacharunderscore}seq\ n{\isachardoublequoteclose}\ \isakeyword{for}\ n\ \isacommand{by}\isamarkupfalse%
\ fact\isanewline
\ \ \isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ {\isacharparenleft}{\isasymintegral}x{\isachardot}\ indicator\ A\ x\ {\isasympartial}M{\isacharunderscore}seq\ n{\isacharparenright}\ {\isacharcolon}{\isacharcolon}\ real{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isacharparenleft}{\isasymintegral}x{\isachardot}\ indicator\ A\ x\ {\isasympartial}M{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}intro\ weak{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}bdd{\isacharunderscore}ae{\isacharunderscore}continuous{\isacharunderscore}conv{\isacharbrackleft}\isakeyword{where}\ B{\isacharequal}{\isadigit{1}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ \ \ {\isacharparenleft}auto\ intro{\isacharcolon}\ assms\ simp{\isacharcolon}\ isCont{\isacharunderscore}indicator{\isacharparenright}\isanewline
\ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}thesis\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\isacommand{qed}\isamarkupfalse%
\end{isabellebody}

\medskip

The converse is also easily obtained, as in the informal development.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ continuity{\isacharunderscore}set{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}weak{\isacharunderscore}conv{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ M{\isacharunderscore}seq\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ real{\isacharunderscore}dist{\isacharunderscore}Mn\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ real{\isacharunderscore}dist{\isacharunderscore}M\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ {\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}A{\isachardot}\ A\ {\isasymin}\ sets\ borel\ {\isasymLongrightarrow}\ M\ {\isacharparenleft}frontier\ A{\isacharparenright}\ {\isacharequal}\ {\isadigit{0}}\ {\isasymLongrightarrow}\isanewline
\ \ \ \ \ \ \ \ {\isacharparenleft}{\isasymlambda}\ n{\isachardot}\ {\isacharparenleft}measure\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}\ A{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ measure\ M\ A{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ M{\isacharunderscore}seq\ M{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{interpret}\isamarkupfalse%
\ real{\isacharunderscore}distribution\ M\ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}thesis\isanewline
\ \ \ \isacommand{unfolding}\isamarkupfalse%
\ weak{\isacharunderscore}conv{\isacharunderscore}m{\isacharunderscore}def\ weak{\isacharunderscore}conv{\isacharunderscore}def\ cdf{\isacharunderscore}def{\isadigit{2}}\ \isacommand{apply}\isamarkupfalse%
\ auto\isanewline
\ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ {\isacharasterisk}{\isacharcomma}\ auto\ simp\ add{\isacharcolon}\ frontier{\isacharunderscore}real{\isacharunderscore}Iic\ isCont{\isacharunderscore}cdf\ emeasure{\isacharunderscore}eq{\isacharunderscore}measure{\isacharparenright}\isanewline
\isacommand{qed}\isamarkupfalse%
\end{isabellebody}

\medskip

The informal proof of $(2) \Longrightarrow (1)$ uses an approximation of step functions by continuous functions, specifically for $x < y$ we defined
\[ f(t) = \begin{cases} 1 & \text{if $t < x$} \\
                        \frac{y - t}{y - x} & \text{if $x \le t \le y$} \\
                        0 & \text{if $y < t$} \end{cases}. \]

This is formalized in Isabelle by a general definition which is available to all further development.

\newpage

\begin{isabellebody}
\isacommand{definition}\isamarkupfalse%
\isanewline
\ \ cts{\isacharunderscore}step\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real\ {\isasymRightarrow}\ real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}cts{\isacharunderscore}step\ a\ b\ x\ {\isasymequiv}\ \isanewline
\ \ \ \ if\ x\ {\isasymle}\ a\ then\ {\isadigit{1}}\isanewline
\ \ \ \ else\ {\isacharparenleft}if\ x\ {\isasymge}\ b\ then\ {\isadigit{0}}\ else\ {\isacharparenleft}b\ {\isacharminus}\ x{\isacharparenright}\ {\isacharslash}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}
\end{isabellebody}

\medskip

The fact that these functions are in fact uniformly continuous is included as a remark after the proof of the portmanteau theorem on p. 335 of \cite{billingsley}, and is formalized in a natural manner:

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ cts{\isacharunderscore}step{\isacharunderscore}uniformly{\isacharunderscore}continuous{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ a\ b\isanewline
\ \ \isakeyword{assumes}\ {\isacharbrackleft}arith{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}a\ {\isacharless}\ b{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}uniformly{\isacharunderscore}continuous{\isacharunderscore}on\ UNIV\ {\isacharparenleft}cts{\isacharunderscore}step\ a\ b{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ uniformly{\isacharunderscore}continuous{\isacharunderscore}on{\isacharunderscore}def\ \isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}clarsimp{\isacharparenright}\isanewline
\ \ \isacommand{fix}\isamarkupfalse%
\ e\ {\isacharcolon}{\isacharcolon}\ real\isanewline
\ \ \isacommand{assume}\isamarkupfalse%
\ {\isacharbrackleft}arith{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}{\isadigit{0}}\ {\isacharless}\ e{\isachardoublequoteclose}\isanewline
\ \ \isacommand{let}\isamarkupfalse%
\ {\isacharquery}d\ {\isacharequal}\ {\isachardoublequoteopen}min\ {\isacharparenleft}e\ {\isacharasterisk}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isacharparenright}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharquery}d\ {\isachargreater}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ field{\isacharunderscore}simps{\isacharparenright}\isanewline
\ \ \isacommand{{\isacharbraceleft}}\isamarkupfalse%
\isanewline
\ \ \ \ \isacommand{fix}\isamarkupfalse%
\ x\ x{\isacharprime}\isanewline
\ \ \ \ \isacommand{assume}\isamarkupfalse%
\ {\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymbar}x{\isacharprime}\ {\isacharminus}\ x{\isasymbar}\ {\isacharless}\ e\ {\isacharasterisk}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\ {\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymbar}x{\isacharprime}\ {\isacharminus}\ x{\isasymbar}\ {\isacharless}\ b\ {\isacharminus}\ a{\isachardoublequoteclose}\ \isakeyword{and}\ {\isachardoublequoteopen}x\ {\isasymle}\ x{\isacharprime}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{hence}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymbar}cts{\isacharunderscore}step\ a\ b\ x{\isacharprime}\ {\isacharminus}\ cts{\isacharunderscore}step\ a\ b\ x{\isasymbar}\ {\isacharless}\ e{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ cts{\isacharunderscore}step{\isacharunderscore}def\ \isacommand{apply}\isamarkupfalse%
\ auto\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ field{\isacharunderscore}simps{\isacharparenright}{\isacharbrackleft}{\isadigit{2}}{\isacharbrackright}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ diff{\isacharunderscore}divide{\isacharunderscore}distrib\ {\isacharbrackleft}symmetric{\isacharbrackright}{\isacharcomma}\ simp\ add{\isacharcolon}\ field{\isacharunderscore}simps{\isacharparenright}\isanewline
\ \ \isacommand{{\isacharbraceright}}\isamarkupfalse%
\ \isacommand{note}\isamarkupfalse%
\ {\isacharasterisk}\ {\isacharequal}\ this\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymforall}x\ x{\isacharprime}{\isachardot}\ dist\ x{\isacharprime}\ x\ {\isacharless}\ {\isacharquery}d\ {\isasymlongrightarrow}\ dist\ {\isacharparenleft}cts{\isacharunderscore}step\ a\ b\ x{\isacharprime}{\isacharparenright}\ {\isacharparenleft}cts{\isacharunderscore}step\ a\ b\ x{\isacharparenright}\ {\isacharless}\ e{\isachardoublequoteclose}\isanewline
\ \ \isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}clarsimp\ simp\ add{\isacharcolon}\ dist{\isacharunderscore}real{\isacharunderscore}def{\isacharparenright}\isanewline
\ \ \ \ \isacommand{fix}\isamarkupfalse%
\ x\ x{\isacharprime}\isanewline
\ \ \ \ \isacommand{assume}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymbar}x{\isacharprime}\ {\isacharminus}\ x{\isasymbar}\ {\isacharless}\ e\ {\isacharasterisk}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\ {\isachardoublequoteopen}{\isasymbar}x{\isacharprime}\ {\isacharminus}\ x{\isasymbar}\ {\isacharless}\ b\ {\isacharminus}\ a{\isachardoublequoteclose}\ \isanewline
\ \ \ \ \isacommand{thus}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymbar}cts{\isacharunderscore}step\ a\ b\ x{\isacharprime}\ {\isacharminus}\ cts{\isacharunderscore}step\ a\ b\ x{\isasymbar}\ {\isacharless}\ e{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}case{\isacharunderscore}tac\ {\isachardoublequoteopen}x\ {\isasymle}\ x{\isacharprime}{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ {\isacharasterisk}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ abs{\isacharunderscore}minus{\isacharunderscore}commute{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ {\isacharasterisk}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{qed}\isamarkupfalse%
\isanewline
\ \ \isacommand{with}\isamarkupfalse%
\ {\isacharbackquoteopen}{\isacharquery}d\ {\isachargreater}\ {\isadigit{0}}{\isacharbackquoteclose}\ \isacommand{show}\isamarkupfalse%
\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isasymexists}d\ {\isachargreater}\ {\isadigit{0}}{\isachardot}\ {\isasymforall}x\ x{\isacharprime}{\isachardot}\ dist\ x{\isacharprime}\ x\ {\isacharless}\ d\ {\isasymlongrightarrow}\ dist\ {\isacharparenleft}cts{\isacharunderscore}step\ a\ b\ x{\isacharprime}{\isacharparenright}\ {\isacharparenleft}cts{\isacharunderscore}step\ a\ b\ x{\isacharparenright}\ {\isacharless}\ e{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ blast\isanewline
\isacommand{qed}
\end{isabellebody}

\medskip

To formalize $(2) \Longrightarrow (1)$ from the informal proof of the portmanteau theorem, we need that the continuous step functions are integrable and satisfy \[ F_\mu(x) \le \int f_{xy} \, d\mu \le F_\mu(y), \]
where $F_\mu$ is the distribution function of $\mu$ and $f_{xy}$ is the continuous step from $x$ to $y$ (we assume $x < y$).

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ real{\isacharunderscore}distribution{\isacharparenright}\ integrable{\isacharunderscore}cts{\isacharunderscore}step{\isacharcolon}\ {\isachardoublequoteopen}a\ {\isacharless}\ b\ {\isasymLongrightarrow}\ integrable\ M\ {\isacharparenleft}cts{\isacharunderscore}step\ a\ b{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ integrable{\isacharunderscore}const{\isacharunderscore}bound\ {\isacharbrackleft}of\ {\isacharunderscore}\ {\isadigit{1}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}force\ simp\ add{\isacharcolon}\ cts{\isacharunderscore}step{\isacharunderscore}def{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ measurable{\isacharunderscore}finite{\isacharunderscore}borel{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ borel{\isacharunderscore}measurable{\isacharunderscore}continuous{\isacharunderscore}on{\isadigit{1}}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ uniformly{\isacharunderscore}continuous{\isacharunderscore}imp{\isacharunderscore}continuous{\isacharparenright}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ cts{\isacharunderscore}step{\isacharunderscore}uniformly{\isacharunderscore}continuous{\isacharparenright}
\end{isabellebody}

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ real{\isacharunderscore}distribution{\isacharparenright}\ cdf{\isacharunderscore}cts{\isacharunderscore}step{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \ \isanewline
\ \ \ \ x\ y\ {\isacharcolon}{\isacharcolon}\ real\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}x\ {\isacharless}\ y{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}cdf\ M\ x\ {\isasymle}\ integral\isactrlsup L\ M\ {\isacharparenleft}cts{\isacharunderscore}step\ x\ y{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isachardoublequoteopen}integral\isactrlsup L\ M\ {\isacharparenleft}cts{\isacharunderscore}step\ x\ y{\isacharparenright}\ {\isasymle}\ cdf\ M\ y{\isachardoublequoteclose}\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ cdf{\isacharunderscore}def\ \isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}prob\ {\isacharbraceleft}{\isachardot}{\isachardot}x{\isacharbraceright}\ {\isacharequal}\ integral\isactrlsup L\ M\ {\isacharparenleft}indicator\ {\isacharbraceleft}{\isachardot}{\isachardot}x{\isacharbraceright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{thus}\isamarkupfalse%
\ {\isachardoublequoteopen}prob\ {\isacharbraceleft}{\isachardot}{\isachardot}x{\isacharbraceright}\ {\isasymle}\ expectation\ {\isacharparenleft}cts{\isacharunderscore}step\ x\ y{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}elim\ ssubst{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ integral{\isacharunderscore}mono{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ simp\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ integrable{\isacharunderscore}cts{\isacharunderscore}step\ assms{\isacharparenright}\ {\isacharbrackleft}{\isacharbrackright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ cts{\isacharunderscore}step{\isacharunderscore}def\ indicator{\isacharunderscore}def\ field{\isacharunderscore}simps{\isacharparenright}\isanewline
\ \ \ \ \isacommand{done}\isamarkupfalse%
\isanewline
\isacommand{next}\isamarkupfalse%
\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}prob\ {\isacharbraceleft}{\isachardot}{\isachardot}y{\isacharbraceright}\ {\isacharequal}\ integral\isactrlsup L\ M\ {\isacharparenleft}indicator\ {\isacharbraceleft}{\isachardot}{\isachardot}y{\isacharbraceright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{thus}\isamarkupfalse%
\ {\isachardoublequoteopen}expectation\ {\isacharparenleft}cts{\isacharunderscore}step\ x\ y{\isacharparenright}\ {\isasymle}\ prob\ {\isacharbraceleft}{\isachardot}{\isachardot}y{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}elim\ ssubst{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ integral{\isacharunderscore}mono{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ integrable{\isacharunderscore}cts{\isacharunderscore}step{\isacharcomma}\ rule\ assms{\isacharparenright}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ cts{\isacharunderscore}step{\isacharunderscore}def\ indicator{\isacharunderscore}def\ \isacommand{using}\isamarkupfalse%
\ {\isacharbackquoteopen}x\ {\isacharless}\ y{\isacharbackquoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ field{\isacharunderscore}simps{\isacharparenright}\isanewline
\isacommand{qed}
\end{isabellebody}

\medskip

The special case of $(2) \Longrightarrow (1)$ for continuous step functions can now be formalized; we omit the proof.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ integral{\isacharunderscore}cts{\isacharunderscore}step{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}weak{\isacharunderscore}conv{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ M{\isacharunderscore}seq\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ distr{\isacharunderscore}M{\isacharunderscore}seq{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ distr{\isacharunderscore}M{\isacharcolon}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ integral{\isacharunderscore}conv{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}x\ y{\isachardot}\ x\ {\isacharless}\ y\ {\isasymLongrightarrow}\isanewline
\ \ \ \ \ \ \ \ \ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ integral\isactrlsup L\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}\ {\isacharparenleft}cts{\isacharunderscore}step\ x\ y{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ integral\isactrlsup L\ M\ {\isacharparenleft}cts{\isacharunderscore}step\ x\ y{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ M{\isacharunderscore}seq\ M{\isachardoublequoteclose}\isanewline
\end{isabellebody}

\medskip

This can then be weakened to something slightly stronger than $(2) \Longrightarrow (1)$:

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ integral{\isacharunderscore}bdd{\isacharunderscore}continuous{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}weak{\isacharunderscore}conv{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ M{\isacharunderscore}seq\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\ \isakeyword{and}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}{\isasymAnd}f\ B{\isachardot}\ {\isacharparenleft}{\isasymAnd}x{\isachardot}\ isCont\ f\ x{\isacharparenright}\ {\isasymLongrightarrow}\ {\isacharparenleft}{\isasymAnd}x{\isachardot}\ abs\ {\isacharparenleft}f\ x{\isacharparenright}\ {\isasymle}\ B{\isacharparenright}\ {\isasymLongrightarrow}\isanewline
\ \ \ \ \ \ \ \ \ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ integral\isactrlsup L\ {\isacharparenleft}M{\isacharunderscore}seq\ n{\isacharparenright}\ f{\isacharcolon}{\isacharcolon}real{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ integral\isactrlsup L\ M\ f{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ \isanewline
\ \ \ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ M{\isacharunderscore}seq\ M{\isachardoublequoteclose}\isanewline
\isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ integral{\isacharunderscore}cts{\isacharunderscore}step{\isacharunderscore}conv{\isacharunderscore}imp{\isacharunderscore}weak{\isacharunderscore}conv\ {\isacharbrackleft}OF\ assms{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ continuous{\isacharunderscore}on{\isacharunderscore}interior{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ uniformly{\isacharunderscore}continuous{\isacharunderscore}imp{\isacharunderscore}continuous{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ cts{\isacharunderscore}step{\isacharunderscore}uniformly{\isacharunderscore}continuous{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subgoal{\isacharunderscore}tac\ {\isachardoublequoteopen}abs{\isacharparenleft}cts{\isacharunderscore}step\ x\ y\ xa{\isacharparenright}\ {\isasymle}\ {\isadigit{1}}{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ assumption\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ cts{\isacharunderscore}step{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ auto%
\end{isabellebody}

\subsection{Helly Selection Theorem and Tightness} \label{sec:helly}

As described in section \ref{sec:summary}, for the proof of the L\'evy continuity theorem (which allows us to study weak convergence through characteristic functions), an analogue of the Bolzano-Weierstrass theorem in the space of probability measures with the topology of weak convergence is needed. In order to prove this, we need the Helly selection theorem, which is itself an analogue of the Bolzano-Weierstrass theorem, and a result of independent interest in functional analysis.

\subsubsection{Helly Selection Theorem}

We begin with some definitions.

\begin{definition} \label{def:subdist}
A function $F\colon \R \rightarrow \R$ is a {\em subdistribution function} iff $F$ is nondecreasing, right-continuous, and satisfies $\lim_{x \rightarrow -\infty} F(x) = 0$ and \linebreak $\lim_{x \rightarrow \infty} F(x) \le 1$.
\end{definition}

Thus a subdistribution function is the natural analogue of a distribution function in the case of a measure which has total mass at most $1$ (a {\em subprobability measure}). The correspondence between subdistribution functions and subprobability measures can be proved in an analogous manner to the proof of the same correspondence between distribution functions and probability measures.

We now come to the subdistribution function analogue of weak convergence:

\begin{definition} \label{def:vague}
A sequence $\bldseq{F_n}{n \in \N}$ of subdistribution functions {\em converges vaguely} to a subdistribution function $F$ iff $\lim_{n \rightarrow \infty} F_n(x) = F(x)$ for all $x \in \R$ such that $F$ is continuous at $x$. This is denoted $F_n \Rightarrow F$, just as with weak convergence. The two notions can be easily seen to coincide in case the functions $F_n$, $F$ are all distribution functions.
\end{definition}

These definitions permit a natural statement of the Helly selection theorem.

\begin{theorem}
Let $\bldseq{F_n}{n \in \N}$ be a sequence of distribution functions. Then there exists a subsequence $\bldseq{F_{n_k}}{n \in \N}$ and a subdistribution function $F$ such that $F_{n_k} \Rightarrow F$.
\end{theorem}

The proof requires an application of the diagonal method.

\begin{lemma} \label{lem:diag}
Suppose, for each $n \in \N$, that $\bldseq{a_{n,k}}{k \in \N}$ is a bounded sequence of real numbers. Then there is a uniform subsequence (a single increasing sequence $\bldseq{n_k}{k \in \N}$ of natural numbers) such that $\lim_{k \rightarrow \infty} a_{i,n_k}$ exists for every $i \in \N$.
\end{lemma}

\begin{proof}
Invoking the Bolzano-Weierstrass theorem, select $\bldseq{n_{0,k}}{k \in \N}$ such that $\bldseq{a_{0,n_{0,k}}}{k \in \N}$ converges. Now inductively choose $\bldseq{n_{i+1,k}}{k \in \N}$ to be a subsequence of $\bldseq{n_{i,k}}{k \in \N}$ such that $\bldseq{a_{i+1,k}}{k \in \N}$ converges. It is now easy to see that the subsequence $n_k = n_{k,k}$ is such that $\lim_{k \rightarrow \infty} a_{i,n_k}$ exists for every $i \in \N$, as required.
\end{proof}

We were fortunate that Fabian Immler at Technische Universit\"at M\"unchen had already formalized a diagonal subsequence library as part of his effort to formalize the theory of differential equations.

We are finally ready for an informal presentation of the proof of the Helly selection theorem.

\begin{proof}[Helly selection theorem]
Using the diagonal method \ref{lem:diag}, obtain a subsequence $\bldseq{n_k}{k \in \N}$ such that $\lim_{k \rightarrow \infty} F_{n_k}(q)$ exists for each rational $q$. Call the value of this limit $G(q)$. Define $F(x) = \inf \bldset{G(q)}{q \in \Q, \ x < q}$ and note $F$ is nondecreasing because each $F_n$ is.

Let $x \in \R$ and $\eps > 0$. By the definition of $F$ there is $q \in \Q$, $q > x$ such that $G(q) < F(x) + \eps$. $F$ is right-continuous because for $x \le y < q$, $F(y) \le G(q) < F(x) + \eps$.

Suppose now that $F$ is continuous at $x$. Choose $y < x$ such that $F(x) < F(y) + \eps$, and rationals $p,q$ such that $y < p < x < q$ and $G(p) < F(x) + \eps$. Thus it follows that $F(x) - \eps < G(p) \le G(q) < F(x) + \eps$ and that $F_n(p) \le F_n(x) \le F_n(q)$ for each $n \in \N$. Consequently we have that
\[\left|\liminf_{k \rightarrow \infty} F_{n_k}(x) - F(x)\right|, \left|\limsup_{k \rightarrow \infty} F_{n_k}(x) - F(x)\right| < \eps, \]
and hence $\lim_{k \rightarrow \infty} F_{n_k}(x) = F(x)$, which establishes that $F_{n_k} \Rightarrow F$.
\end{proof}

The formal statement of the Helly selection theorem follows; we omit the very long proof, but note that the first hurdle was to establish a bijection between the naturals and the rationals! Fortunately this could be handled with library support for reasoning about countable sets; the bijection did not need to be constructed explicitly. It should be noted that we did not formalize the definitions of subdistribution functions and vague convergence, as these are not needed anywhere else in our formal development. The predicate \texttt{rcont\_inc} indicates a function which is nondecreasing and right continuous.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ Helly{\isacharunderscore}selection{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ f\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ rcont{\isacharunderscore}inc{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ rcont{\isacharunderscore}inc\ {\isacharparenleft}f\ n{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{and}\ unif{\isacharunderscore}bdd{\isacharcolon}\ {\isachardoublequoteopen}{\isasymforall}n\ x{\isachardot}\ {\isasymbar}f\ n\ x{\isasymbar}\ {\isasymle}\ M{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isasymexists}s{\isachardot}\ subseq\ s\ {\isasymand}\ {\isacharparenleft}{\isasymexists}F{\isachardot}\ rcont{\isacharunderscore}inc\ F\ {\isasymand}\ {\isacharparenleft}{\isasymforall}x{\isachardot}\ {\isasymbar}F\ x{\isasymbar}\ {\isasymle}\ M{\isacharparenright}\ {\isasymand}\isanewline
\ \ \ \ {\isacharparenleft}{\isasymforall}x{\isachardot}\ \ continuous\ {\isacharparenleft}at\ x{\isacharparenright}\ F\ {\isasymlongrightarrow}\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ f\ {\isacharparenleft}s\ n{\isacharparenright}\ x{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ F\ x{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}
\end{isabellebody}

\medskip

\subsubsection{Tightness of Sequences of Measures}

The applications of Helly's theorem in which we are interested concern tightness of sequences of measures; this is an analogue of boundedness of ordinary sequences, and prevents any mass in a sequence $\bldseq{\mu_n}{n \in \N}$ from ``escaping to infinity'' in the (weak) limit. An example of a sequence of probability measure which is not tight is $\bldseq{\mu_n}{n \in \N}$, where for each $n \in \N$, $\mu_n$ is a unit mass at $n$ (it is intuitively clear that all the mass of this sequence ``escapes to infinity.'')

\begin{definition}
Let $\bldseq{\mu_n}{n \in \N}$ be a sequence of Borel probability measures on $\R$. This sequence is called {\em tight} iff for each $\eps > 0$ there exist $a < b$ such that $\mu_n (a,b] < 1 - \eps$ for every $n \in \N$. 
\end{definition}

It should be clear how the tightness condition keeps mass from getting too far away and ultimately escaping to infinity. In terms of distribution functions, the tightness condition is equivalent to the requirement that for each $\eps > 0$ there exist $x, y \in \R$ such that $F_n(x) < \eps$ and $F_n(y) > 1 - \eps$ for every $n \in \N$.

We can now state the promised analogue of the Bolzano-Weierstrass theorem for tight sequences of probability measures.

\begin{theorem}
A sequence $\bldseq{\mu_n}{n \in \N}$ of probability measures is tight if and only if for every subsequence $\bldseq{\mu_{n_k}}{k \in \N}$ there exists a subsubsequence $\bldseq{\mu_{n_{k_j}}}{j \in \N}$ which converges weakly to some probability measure $\mu$.
\end{theorem}

\begin{proof}
$(\Longrightarrow)$: Suppose for contradiction that $\bldseq{\mu_n}{n \in \N}$ is not tight. Choose $\eps > 0$ such that for every choice of $a < b$, $\mu_n (a,b] \le 1 - \eps$ for some $n$. Using this, choose $n_k$ for each $k \in \N$ such that $\mu_{n_k} (-k,k] \le 1 - \eps$. Let $\bldseq{\mu_{n_{k_j}}}{j \in \N}$ be a subsequence of $\bldseq{\mu_{n_k}}{k \in \N}$, and suppose for contradiction that $\mu_{n_{k_j}} \Rightarrow \mu$ for some probability measure $\mu$. Choose $a < b$ nonatoms such that $\mu (a,b] > 1 - \eps$ (which is possible as there are only countably many atoms). There exists $j_0$ such that $(a,b] \subseteq (-k_j, k_j]$ for $j \ge j_0$, and thus we have
\[ 1 - \eps \ge \mu_{n_{k_j}} (-k_j, k_j] \ge \mu_{n_{k_j}} (a,b] \rightarrow \mu (a,b] \]
as $j \rightarrow \infty$. This implies that $\mu (a,b] \le 1 - \eps$, contradicting the earlier established fact that $\mu (a,b] > 1 - \eps$.

$(\Longleftarrow)$: Let $\bldseq{F_{n_k}}{k \in \N}$ be the sequence of distribution functions corresponding to $\bldseq{\mu_{n_k}}{k \in \N}$. Apply the Helly selection theorem to obtain a subsequence $\bldseq{F_{n_{k_j}}}{j \in \N}$ which converges vaguely to a subdistribution function $F$. Let $\mu$ be the subprobability measure corresponding to $F$. For $\eps > 0$ use tightness to obtain $a < b$ such that $\mu_n (a,b] > 1 - \eps$ for every $n \in \N$. Since $F$ has just countably many discontinuity points, $a,b$ may be chosen to be continuity points of $F$. Thus $\mu (a,b] > 1 - \eps$, and since $\eps > 0$ was arbitrary we see that in fact $\mu$ is a probability measure, and hence the vague convergence $F_{n_{k_j}} \Rightarrow F$ is in fact weak convergence, which is to say $\mu_{n_{k_j}} \Rightarrow \mu$ as desired.
\end{proof}

The corresponding formalized proof is again very long, so we provide just the statement (and the formalized definition of tightness).

\medskip

\begin{isabellebody}
\isacommand{definition}\isamarkupfalse%
\ tight\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}nat\ {\isasymRightarrow}\ real\ measure{\isacharparenright}\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\isanewline
\isakeyword{where}\ {\isachardoublequoteopen}tight\ {\isasymmu}\ {\isasymequiv}\ {\isacharparenleft}{\isasymforall}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}{\isasymmu}\ n{\isacharparenright}{\isacharparenright}\ {\isasymand}\ {\isacharparenleft}{\isasymforall}{\isacharparenleft}{\isasymepsilon}{\isacharcolon}{\isacharcolon}real{\isacharparenright}{\isachargreater}{\isadigit{0}}{\isachardot}\ {\isasymexists}a\ b{\isacharcolon}{\isacharcolon}real{\isachardot}\ a\ {\isacharless}\ b\ {\isasymand}\ {\isacharparenleft}{\isasymforall}n{\isachardot}\ measure\ {\isacharparenleft}{\isasymmu}\ n{\isacharparenright}\ {\isacharbraceleft}a{\isacharless}{\isachardot}{\isachardot}b{\isacharbraceright}\ {\isachargreater}\ {\isadigit{1}}\ {\isacharminus}\ {\isasymepsilon}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}
\end{isabellebody}

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ tight{\isacharunderscore}iff{\isacharunderscore}convergent{\isacharunderscore}subsubsequence{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ {\isasymmu}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}{\isasymmu}\ n{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}tight\ {\isasymmu}\ {\isacharequal}\ {\isacharparenleft}{\isasymforall}s{\isachardot}\ subseq\ s\ {\isasymlongrightarrow}\ {\isacharparenleft}{\isasymexists}r{\isachardot}\ {\isasymexists}M{\isachardot}\ \ subseq\ r\ {\isasymand}\ real{\isacharunderscore}distribution\ M\ {\isasymand}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ s\ {\isasymcirc}\ r{\isacharparenright}\ M{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}
\end{isabellebody}

\medskip

A corollary of this result will also be useful.

\begin{corollary}
If $\bldseq{\mu_n}{n \in \N}$ is a tight sequence of probability measures such that each subsequence which has a weak limit in fact has the probability measure $\mu$ as its weak limit, then $\mu_n \Rightarrow \mu$.
\end{corollary}

\begin{proof}
By the preceding theorem, for every subsequence $\bldseq{\mu_{n_k}}{k \in \N}$ there is a subsubsequence $\bldseq{\mu_{n_{k_j}}}{j \in \N}$ which converges weakly; by hypothesis the weak limit must be $\mu$.

Suppose now for contradiction that $\mu$ is not the weak limit of $\bldseq{\mu_n}{n \in \N}$. Then there exists $x \in \R$ such that $\mu \{x\} = 0$ but $\bldseq{\mu_n (-\infty, x]}{n \in \N}$ does not converge to $\mu (-\infty, x]$. Thus for some $\eps > 0$ there are infinitely many $i \in \N$ such that $|\mu_i (-\infty, x] - \mu (-\infty, x]| > \eps$. Letting $\bldseq{n_k}{k \in \N}$ enumerate these $i$'s gives a subsequence $\bldseq{\mu_{n_k}}{k \in \N}$ no subsequence of which can converge weakly to $\mu$, which contradicts what was established in the first paragraph.
\end{proof}

This is formalized as follows.

\medskip

\begin{isabellebody}
\isacommand{corollary}\isamarkupfalse%
\ tight{\isacharunderscore}subseq{\isacharunderscore}weak{\isacharunderscore}converge{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ {\isasymmu}\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}{\isasymmu}\ n{\isacharparenright}{\isachardoublequoteclose}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\ \isakeyword{and}\ tight{\isacharcolon}\ {\isachardoublequoteopen}tight\ {\isasymmu}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ subseq{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}s\ {\isasymnu}{\isachardot}\ subseq\ s\ {\isasymLongrightarrow}\ real{\isacharunderscore}distribution\ {\isasymnu}\ {\isasymLongrightarrow}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ s{\isacharparenright}\ {\isasymnu}\ {\isasymLongrightarrow}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ s{\isacharparenright}\ M{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isasymmu}\ M{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}rule\ ccontr{\isacharparenright}\isanewline
\ \ \isacommand{from}\isamarkupfalse%
\ tight\ tight{\isacharunderscore}iff{\isacharunderscore}convergent{\isacharunderscore}subsubsequence\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ subsubseq{\isacharcolon}\ {\isachardoublequoteopen}{\isasymforall}s{\isachardot}\ subseq\ s\ {\isasymlongrightarrow}\ {\isacharparenleft}{\isasymexists}r\ M{\isachardot}\ subseq\ r\ {\isasymand}\ real{\isacharunderscore}distribution\ M\ {\isasymand}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ s\ {\isasymcirc}\ r{\isacharparenright}\ M{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ assms\ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{{\isacharbraceleft}}\isamarkupfalse%
\isanewline
\ \ \ \ \isacommand{fix}\isamarkupfalse%
\ s\ \isacommand{assume}\isamarkupfalse%
\ s{\isacharcolon}\ {\isachardoublequoteopen}subseq\ s{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{with}\isamarkupfalse%
\ subsubseq\ subseq\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymexists}r\ M{\isachardot}\ subseq\ r\ {\isasymand}\ real{\isacharunderscore}distribution\ M\ {\isasymand}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ s\ {\isasymcirc}\ r{\isacharparenright}\ M{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{guess}\isamarkupfalse%
\ r\ \isacommand{{\isachardot}{\isachardot}}\isamarkupfalse%
\ \isacommand{note}\isamarkupfalse%
\ r\ {\isacharequal}\ this\isanewline
\ \ \ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{guess}\isamarkupfalse%
\ {\isasymnu}\ \isacommand{{\isachardot}{\isachardot}}\isamarkupfalse%
\ \isacommand{note}\isamarkupfalse%
\ {\isasymnu}\ {\isacharequal}\ this\isanewline
\ \ \ \ \isacommand{hence}\isamarkupfalse%
\ subsubseq{\isacharunderscore}conv{\isacharcolon}\ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ {\isacharparenleft}s\ {\isasymcirc}\ r{\isacharparenright}{\isacharparenright}\ {\isasymnu}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ o{\isacharunderscore}assoc{\isacharparenright}\isanewline
\ \ \ \ \isacommand{from}\isamarkupfalse%
\ s\ r\ \isacommand{have}\isamarkupfalse%
\ sr{\isacharcolon}\ {\isachardoublequoteopen}subseq\ {\isacharparenleft}s\ {\isasymcirc}\ r{\isacharparenright}{\isachardoublequoteclose}\ \isacommand{using}\isamarkupfalse%
\ subseq{\isacharunderscore}o\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \ \ \isacommand{with}\isamarkupfalse%
\ subsubseq{\isacharunderscore}conv\ subseq\ {\isasymnu}\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ {\isacharparenleft}s\ {\isasymcirc}\ r{\isacharparenright}{\isacharparenright}\ M{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \ \ \isacommand{with}\isamarkupfalse%
\ r\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymexists}r{\isachardot}\ subseq\ r\ {\isasymand}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ {\isacharparenleft}s\ {\isasymcirc}\ r{\isacharparenright}{\isacharparenright}\ M{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \isacommand{{\isacharbraceright}}\isamarkupfalse%
\isanewline
\ \ \isacommand{hence}\isamarkupfalse%
\ {\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}s{\isachardot}\ subseq\ s\ {\isasymLongrightarrow}\ {\isasymexists}r{\isachardot}\ subseq\ r\ {\isasymand}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ {\isacharparenleft}s\ {\isasymcirc}\ r{\isacharparenright}{\isacharparenright}\ M{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \isacommand{def}\isamarkupfalse%
\ f\ {\isasymequiv}\ {\isachardoublequoteopen}{\isasymlambda}n{\isachardot}\ cdf\ {\isacharparenleft}{\isasymmu}\ n{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isacommand{def}\isamarkupfalse%
\ F\ {\isasymequiv}\ {\isachardoublequoteopen}cdf\ M{\isachardoublequoteclose}\isanewline
\ \ \isacommand{assume}\isamarkupfalse%
\ CH{\isacharcolon}\ {\isachardoublequoteopen}{\isasymnot}\ weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isasymmu}\ M{\isachardoublequoteclose}\isanewline
\ \ \isacommand{hence}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymexists}x{\isachardot}\ isCont\ F\ x\ {\isasymand}\ {\isasymnot}{\isacharparenleft}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ f\ n\ x{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ F\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ weak{\isacharunderscore}conv{\isacharunderscore}m{\isacharunderscore}def\ weak{\isacharunderscore}conv{\isacharunderscore}def\ f{\isacharunderscore}def\ F{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{guess}\isamarkupfalse%
\ x\ \isacommand{{\isachardot}{\isachardot}}\isamarkupfalse%
\ \isacommand{note}\isamarkupfalse%
\ x\ {\isacharequal}\ this\isanewline
\ \ \isacommand{hence}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymexists}{\isasymepsilon}{\isachargreater}{\isadigit{0}}{\isachardot}\ {\isasymexists}s{\isachardot}\ subseq\ s\ {\isasymand}\ {\isacharparenleft}{\isasymforall}n{\isachardot}\ {\isasymbar}f\ {\isacharparenleft}s\ n{\isacharparenright}\ x\ {\isacharminus}\ F\ x{\isasymbar}\ {\isasymge}\ {\isasymepsilon}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ {\isacharparenleft}asm{\isacharparenright}\ tendsto{\isacharunderscore}iff{\isacharcomma}\ auto\ simp\ add{\isacharcolon}\ not{\isacharunderscore}less{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ {\isacharparenleft}asm{\isacharparenright}\ eventually{\isacharunderscore}sequentially{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ dist{\isacharunderscore}real{\isacharunderscore}def\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ not{\isacharunderscore}less{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ subseq{\isacharunderscore}Suc{\isacharunderscore}iff{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule{\isacharunderscore}tac\ x\ {\isacharequal}\ e\ \isakeyword{in}\ exI{\isacharcomma}\ safe{\isacharparenright}\isanewline
\ \ \ \ \isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \ \ \ \ \isacommand{fix}\isamarkupfalse%
\ e\ \isacommand{assume}\isamarkupfalse%
\ e{\isacharcolon}\ {\isachardoublequoteopen}{\isadigit{0}}\ {\isacharless}\ e{\isachardoublequoteclose}\ {\isachardoublequoteopen}{\isasymforall}N{\isachardot}\ {\isasymexists}n{\isasymge}N{\isachardot}\ e\ {\isasymle}\ {\isasymbar}f\ n\ x\ {\isacharminus}\ F\ x{\isasymbar}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{obtain}\isamarkupfalse%
\ n\ \isakeyword{where}\ n{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}N{\isachardot}\ N\ {\isasymle}\ n\ N{\isachardoublequoteclose}\ {\isachardoublequoteopen}{\isasymAnd}N{\isachardot}\ e\ {\isasymle}\ {\isasymbar}f\ {\isacharparenleft}n\ N{\isacharparenright}\ x\ {\isacharminus}\ F\ x{\isasymbar}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ metis\isanewline
\ \ \ \ \ \ \isacommand{def}\isamarkupfalse%
\ s\ {\isasymequiv}\ {\isachardoublequoteopen}rec{\isacharunderscore}nat\ {\isacharparenleft}n\ {\isadigit{0}}{\isacharparenright}\ {\isacharparenleft}{\isasymlambda}{\isacharunderscore}\ i{\isachardot}\ n\ {\isacharparenleft}Suc\ i{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ s{\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}s\ {\isadigit{0}}\ {\isacharequal}\ n\ {\isadigit{0}}{\isachardoublequoteclose}\ {\isachardoublequoteopen}{\isasymAnd}i{\isachardot}\ s\ {\isacharparenleft}Suc\ i{\isacharparenright}\ {\isacharequal}\ n\ {\isacharparenleft}Suc\ {\isacharparenleft}s\ i{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp{\isacharunderscore}all\isanewline
\ \ \ \ \ \ \isacommand{{\isacharbraceleft}}\isamarkupfalse%
\ \isacommand{fix}\isamarkupfalse%
\ i\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}s\ i\ {\isacharless}\ s\ {\isacharparenleft}Suc\ i{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \ \ \ \ \isacommand{using}\isamarkupfalse%
\ n{\isacharparenleft}{\isadigit{1}}{\isacharparenright}{\isacharbrackleft}of\ {\isachardoublequoteopen}Suc\ {\isacharparenleft}s\ i{\isacharparenright}{\isachardoublequoteclose}{\isacharbrackright}\ n{\isacharparenleft}{\isadigit{2}}{\isacharparenright}{\isacharbrackleft}of\ {\isadigit{0}}{\isacharbrackright}\ \ \isacommand{by}\isamarkupfalse%
\ simp{\isacharunderscore}all\ \isacommand{{\isacharbraceright}}\isamarkupfalse%
\isanewline
\ \ \ \ \ \ \isacommand{moreover}\isamarkupfalse%
\ \isacommand{{\isacharbraceleft}}\isamarkupfalse%
\ \isacommand{fix}\isamarkupfalse%
\ i\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}e\ {\isasymle}\ {\isasymbar}f\ {\isacharparenleft}s\ i{\isacharparenright}\ x\ {\isacharminus}\ F\ x{\isasymbar}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}cases\ i{\isacharparenright}\ {\isacharparenleft}simp{\isacharunderscore}all\ add{\isacharcolon}\ n{\isacharparenright}\ \isacommand{{\isacharbraceright}}\isamarkupfalse%
\isanewline
\ \ \ \ \ \ \isacommand{ultimately}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymexists}s{\isachardot}\ {\isacharparenleft}{\isasymforall}n{\isachardot}\ s\ n\ {\isacharless}\ s\ {\isacharparenleft}Suc\ n{\isacharparenright}{\isacharparenright}\ {\isasymand}\ {\isacharparenleft}{\isasymforall}n{\isachardot}\ e\ {\isasymle}\ {\isasymbar}f\ {\isacharparenleft}s\ n{\isacharparenright}\ x\ {\isacharminus}\ F\ x{\isasymbar}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ metis\isanewline
\ \ \ \ \isacommand{qed}\isamarkupfalse%
\isanewline
\ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{obtain}\isamarkupfalse%
\ {\isasymepsilon}\ s\ \isakeyword{where}\ {\isasymepsilon}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymepsilon}\ {\isachargreater}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isakeyword{and}\ s{\isacharcolon}\ {\isachardoublequoteopen}subseq\ s\ {\isasymand}\ {\isacharparenleft}{\isasymforall}n{\isachardot}\ {\isasymbar}f\ {\isacharparenleft}s\ n{\isacharparenright}\ x\ {\isacharminus}\ F\ x{\isasymbar}\ {\isasymge}\ {\isasymepsilon}{\isacharparenright}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \isacommand{hence}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymAnd}r{\isachardot}\ subseq\ r\ {\isasymLongrightarrow}\ {\isasymnot}weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymmu}\ {\isasymcirc}\ s\ {\isasymcirc}\ r{\isacharparenright}\ M{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}unfold\ weak{\isacharunderscore}conv{\isacharunderscore}m{\isacharunderscore}def\ weak{\isacharunderscore}conv{\isacharunderscore}def{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule{\isacharunderscore}tac\ x\ {\isacharequal}\ x\ \isakeyword{in}\ exI{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ tendsto{\isacharunderscore}iff{\isacharparenright}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ dist{\isacharunderscore}real{\isacharunderscore}def\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ eventually{\isacharunderscore}sequentially{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ x\ \isacommand{unfolding}\isamarkupfalse%
\ F{\isacharunderscore}def\ \isacommand{apply}\isamarkupfalse%
\ auto\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ not{\isacharunderscore}less{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subgoal{\isacharunderscore}tac\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ cdf\ {\isacharparenleft}{\isasymmu}\ {\isacharparenleft}s\ {\isacharparenleft}r\ n{\isacharparenright}{\isacharparenright}{\isacharparenright}\ x{\isacharparenright}\ {\isacharequal}\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ f\ {\isacharparenleft}s\ {\isacharparenleft}r\ n{\isacharparenright}{\isacharparenright}\ x{\isacharparenright}{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}erule\ ssubst{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule{\isacharunderscore}tac\ x\ {\isacharequal}\ {\isasymepsilon}\ \isakeyword{in}\ exI{\isacharparenright}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ f{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \isacommand{thus}\isamarkupfalse%
\ False\ \isacommand{using}\isamarkupfalse%
\ subseq\ {\isacharasterisk}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}metis\ fun{\isachardot}map{\isacharunderscore}comp\ s{\isacharparenright}\ \isanewline
\isacommand{qed}
\end{isabellebody}

\subsection{Integration}

Improving the integration library of Isabelle was one of the primary motivations of the central limit theorem formalization project. A complete rewrite of the library, implementing a change from Lebesgue to Bochner integration, was completed by H\"olzl in response to our feedback concerning the usability of the integration library. We begin with a general discussion of the problems and tradeoffs in formalizing integration, and then describe how we used the integration library in the computation of the limit of the sine integral function at infinity.

\subsubsection{General Remarks on Formalizing Integration} \label{sec:form_int}

The proofs of the L\'evy inversion and continuity theorems required formal work with integrals, and brought a number of design issues into focus. First, one frequently wishes to integrate a function only over a subset $A$ of the space on which it is defined rather than over the whole space. This can be handled in two ways: The integral over the whole space can be taken as primitive, with the integral of a function $f$ over a set $A$ defined by $\int_A f \, d\mu = \int f \mathbbm{1}_A \, d\mu$, or the integral over a set can be taken as primitive with the integral of a function $f$ over the whole space being defined by $\int f \, d\mu = \int_X f \, d\mu$. There is some small advantage to taking the integral over a set as primitive, because this avoids failures of pattern-matching when automated simplifications move indicator functions around or unfold the definition, but this advantage is not major as far as we can tell and could easily be outweighed by complications in proving fundamental lemmata when the domain of integration is an additional parameter. In particular, the Isabelle Bochner integration library takes integration over the entire space as primitive. In any case it is certainly useful to have notation for integration over a set.

One particular type of set occurs particularly frequently as the domain of integration with respect to Lebesgue measure on $\R$, namely a closed interval. In calculus the integral (with respect to Lebesgue meausre) of a function $f$ over a closed interval $[a,b]$ ($a \le b$) is denoted $\int_a^b f(x) \, dx$, and it is convenient to have a similar notation for integrals over intervals in Isabelle. A number of design issues immediately present themselves: What should be the types of $a$ and $b$? One might assume these should be reals, but frequently integrals are computed over unbounded intervals ($\int_0^\infty e^{-x} \, dx$, $\int_{-\infty}^\infty e^{-x^2} \, dx$), and so there is some advantage to taking $a$ and $b$ to be extended reals to avoid the need for separate lemmata for integrals of the form $\int_a^\infty$, $\int_{-\infty}^b$ and $\int_{-\infty}^\infty$ (this last form being a notational variant of $\int$). However, this advantage is achieved at a cost, because it entails annoying casts between reals and extended reals that we found in practice frequently prevent automated tools from proving apparently obvious facts (which they do in fact obtain when the endpoints are taken to be of type real). This is largely because the extended reals are not as algebraically well-behaved as the reals (they are not a field, for example).

As noted in the preceding paragraph, for interval integrals with respect to Lebesgue measure the interval is generally assumed to be closed (so any continuous function defined on it is uniformly continuous, and other nice properties hold); since Lebesgue measure is continuous, it makes no difference to the value of the integral whether the endpoints are included. However, for general measures this does make a difference if one of the endpoints is an atom, and in particular the interval partition formula, valid for $f$ integrable with respect to Lebesgue measure and $a \le b \le c$:
\[ \int_a^b f(x) \, dx + \int_b^c f(x) \, dx = \int_a^c f(x) \, dx \]
fails in general if $\int_a^b$ is defined as $\int_{[a,b]}$. What holds instead for arbitrary measures $\mu$ (and functions $f$ integrable over $[a,c]$ with respect to $\mu$) is that
\[ \int_{[a,b]} f \, d\mu + \int_{[b,c]} f \, d\mu = \int_{[a,c]} f \, d\mu + f(b)\mu \{b\}. \]
Intuitively this is because the mass of the point $b$ is counted twice. This is obviously less convenient than the ordinary interval partition formula, especially for partitions into large numbers of pieces. The problem can be fixed by using a half-open interval such as $(a,b]$ to ensure pieces of an interval partition are disjoint; such a solution preserves the equality $\int_a^b f \, d\mu = \int_{[a,b]} f \, d\mu$ for continuous measures, and satisfies the intuitive partition formula
\[ \int_a^b f \, d\mu + \int_b^c f \, d\mu = \int_a^c f \, d\mu \]
for all $a,b,c$ with $a < b < c$.

A further constellation of design issues arises from considering what should happen if $b < a$ in $\int_a^b f(x) \, dx$. The natural option is to take $\int_a^b f(x) \, dx = -\int_b^a f(x) \, dx$ in this case, but this would require introducing a case split in the definition of $\int_a^b f(x) \, dx$ (e.g. $\int_a^b f(x) \, dx = \int_{[a,b]} f(x) \, dx$ if $a \le b$, otherwise $\int_a^b f(x) \, dx = -\int_{[b,a]} f(x) \, dx$), which then causes headaches for formalization both for human users and automated tools. $\int_a^b f(x) \, dx$ could also be taken simply to be notation for $\int_{[a,b]} f(x) \, dx$, in which case $b < a$ implies $[a,b] = \emptyset$ and so the integral is zero, but this makes it hard to state results such as the fundamental theorem of calculus or integration by substitution in a natural manner.

Another set of issues concern integrability. Not all functions have integrals, and the notation $\int f \, d\mu$ only makes sense if $f$ is integrable (over $X$). Isabelle requires that all functions be total, so $\int f \, d\mu$ necessarily has a value no matter what $f$ is. If $f$ is not integrable, the value which $\int f \, d\mu$ receives is arbitrary. A proof that $\int f \, d\mu = c$ is useless unless $f$ is known to be integrable (for otherwise it could be that $c$ just happens to be the default value in the case of integrating $f$). These are general problems concerning the representation of partial functions, and we shall pause to briefly consider them in full generality.

A partial function with domain $X$ and codomain $Y$ can be thought of as a relation $R \subseteq X \times Y$ such that for every $x \in X$ and $y, z \in Y$, $xRy$ and $xRz$ implies $y=z$ (a [total] function corresponds to such a relation where in addition for every $x \in X$ there exists $y \in Y$ such that $xRy$, though the higher-order logic used by Isabelle treats functions somewhat differently [not as relations]). Let $y^*$ be some distinguished element of the type of elements of $Y$, and consider the function $f\colon X \rightarrow Y \cup \{y^*\}$ where $f(x) = y$ if there exists $y \in Y$ such that $xRy$, and otherwise $f(x) = y^*$. The value $y^*$ should be thought of as hidden; the fact that $f(x) = y^*$ if there does not exist $y \in Y$ such that $xRy$ should not be exploited in proofs. In this case the conclusion that $f(x) = y$ is useless unless it is known that there exists $y \in Y$ such that $xRy$. Since the existence of $y \in Y$ such that $xRy$ means intuitively that $f$ is ``defined'' at $x$; let us denote it by $Dx$. Then $xRy$ is equivalent to $Dx$ and $f(x) = y$. Since $f(x) = y$ is useless without knowing $Dx$, the conclusions of computations of $f$ for various arguments should either be stated in terms of $R$ or have the auxilliary conclusion that $Dx$ for each argument $x$ of $f$ considered in the computation. $xRy$ is a robust conclusion and functions well as the fundamental notion in terms of which $f$ and $D$ are defined, while it is convenient to have $f$ both to allow statement of results in a manner more similar to mathematical practice, and to allow more convenient computation with values of the partial function (e.g. $f(x_1) + f(x_2)$ is easier to work with than \texttt{(THE $y$.\!\!\! $x_1Ry$) + (THE $y$.\!\!\! $x_2Ry$)} or something like that).

The Isabelle libraries we used during the formalization of the central limit theorem employed an integral operator and an integrability predicate; there was no instantiation of the relation $R$ from the preceding paragraph. This could have worked had every use of the integral operator been accompanied by a corresponding proof of integrability, but unfortunately that was not the case, and occasionally we needed to either modify a library proof to obtain integrability as well as the value of an integral, or repeat long arguments from library lemmata with trivial modifications so as to obtain integrability. This is striking, because other partial functions such as limits and derivatives had already been implemented with relations such as \texttt{has\_derivative} and what one may think of as \texttt{has\_limit} (though the actual definition of limits uses two filters as described in section \ref{sec:filterlim}). The problem of partial functions was not new, but it required experience to determine the best method of implementing them in Isabelle. Another consideration in the case of integration was that when working with concrete functions, one often wishes to prove integrability by computing the integral (e.g. the integral of $e^{-x}$ over $[0, \infty)$ is $1$), and this is generally very inconvenient to do when integrability must be verified separately. A better plan in such cases is to have an instantiation \texttt{has\_integral} of the relation $R$ from the preceding paragraph, and obtain integrability by proving that \texttt{$f$ has\_integral $c$} for appropriate $c$ when working with specific integrals. Thus it is convenient to have not only an integral operator and an integrability predicate, but also a \texttt{has\_integral} relation. In some sense it does not matter which is taken as fundamental, but as noted in the preceding paragraph it seems more natural to take \texttt{has\_integral} as fundamental.

The change from a fundamental integral operator and integrability predicate to a fundamental \texttt{has\_integral} relation was accomplished by H\"olzl when reimplementing the integration library using the Bochner integral. This change was motivated largely by a desire to provide a unified framework for vector-valued integrals, and was of direct importance to the central limit theorem formalization because the complex-valued integrals arising from characteristic functions can be handled as Bochner integrals.

There is also the question of how to handle improper integrals; for example, the $\sinc$ function ($x\inv \sin x$ away from zero, and $1$ at zero) is not integrable over $[0,\infty)$, and yet 
\[ \lim_{t \rightarrow \infty} \int_0^t \sinc x \, dx = \frac{\pi}{2}. \]
Often this is written simply as $\int_0^\infty \sinc x \, dx = \pi/2$, perhaps with a warning that notation is being abused (see note regarding this limit in \cite{billingsley}, p. 223). Improper integrals also occur over finite intervals, for example
\[ \lim_{t \rightarrow 0} \int_t^1 \frac{(-1)^{\floor x + 1}}{\floor x} \mathbbm 1_{(0,1]} \, dx = \ln 2, \]
but the integrand is not integrable over $(0,1]$ because the harmonic series diverges. It would be possible to implement the integral over an interval to include improper integrals, as is standard practice in calculus texts, by including a limit in the definition of such an integral. However, this seems to carry with it too many disadvantages, simply because of the complication that a hidden limit introduces; it is inconvenient for users to constantly need to eliminate the limit whenever they use integrals, and difficult to set up automated tools to deal with it effectively.

\subsubsection{The Sine Integral Function} \label{sec:Si}

First a note on theorems fundamental to working with integrals: The fundamental theorem of calculus was present in some form when we started, but we found it useful to extend it significantly. We also proved lemmata concerning integration by substitution (change of variables), and defined integrals over sets and intervals. During the course of the formalization H\"olzl improved our fundamental lemmata and our definitions of integrals over sets and intervals and incorporated them into the integration library he was developing. We do not include pieces of that library in this paper, but the reader may readily find them on the Isabelle website (under HOL-Probability).

On p. 223 of \cite{billingsley}, Billingsley notes that it is ``an important analytic fact'' that
\[ \lim_{t \rightarrow \infty} \int_0^t \frac{\sin x}{x} \, dx = \frac{\pi}{2}. \]
Partly because of this, but mostly because this important analytic fact is used in the proof of the L\'evy inversion theorem, we decided to formalize the proof of this limit.

The function $\frac{\sin x}{x}$ has a removable discontinuity (due to not being defined) at zero; the result of filling in that discontinuity (with the value $1$) is called the function $\sinc$: $\sinc x = \frac{\sin x}{x}$ if $x \ne 0$, $\sinc 0 = 1$. The indefinite integral of the $\sinc$ function, starting at $0$, is called the {\em sine integral function}:
\[ \Si(x) = \int_0^t \sinc x \, dx. \]

These definitions, and the basic properties of the $\sinc$ and $\Si$ functions, are formalized as expected. Note that \texttt{LINT} is ASCII notation for the Lebesgue integral, and \texttt{LBINT} is ASCII notation for the Lebesgue integral with respect to Lebesgue measure (otherwise known as Lebesgue-Borel measure).\phantom{)}

\medskip

\begin{isabellebody}
\isacommand{abbreviation}\isamarkupfalse%
\ sinc\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}sinc\ {\isasymequiv}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ if\ x\ {\isacharequal}\ {\isadigit{0}}\ then\ {\isadigit{1}}\ else\ sin\ x\ {\isacharslash}\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ sinc{\isacharunderscore}at{\isacharunderscore}{\isadigit{0}}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}{\isacharparenleft}{\isasymlambda}x{\isachardot}\ sin\ x\ {\isacharslash}\ x{\isacharcolon}{\isacharcolon}real{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{1}}{\isacharparenright}\ {\isacharparenleft}at\ {\isadigit{0}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{using}\isamarkupfalse%
\ DERIV{\isacharunderscore}sin\ {\isacharbrackleft}of\ {\isadigit{0}}{\isacharbrackright}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ has{\isacharunderscore}field{\isacharunderscore}derivative{\isacharunderscore}def\ field{\isacharunderscore}has{\isacharunderscore}derivative{\isacharunderscore}at{\isacharparenright}%
\isanewline\isanewline
\isacommand{lemma}\isamarkupfalse%
\ isCont{\isacharunderscore}sinc{\isacharcolon}\ {\isachardoublequoteopen}isCont\ sinc\ x{\isachardoublequoteclose}\isanewline
\isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}case{\isacharunderscore}tac\ {\isachardoublequoteopen}x\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ isCont{\isacharunderscore}def{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ LIM{\isacharunderscore}equal\ {\isacharbrackleft}\isakeyword{where}\ g\ {\isacharequal}\ {\isachardoublequoteopen}{\isasymlambda}x{\isachardot}\ sin\ x\ {\isacharslash}\ x{\isachardoublequoteclose}{\isacharbrackright}{\isacharcomma}\ auto\ intro{\isacharcolon}\ sinc{\isacharunderscore}at{\isacharunderscore}{\isadigit{0}}{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ continuous{\isacharunderscore}transform{\isacharunderscore}at\ {\isacharbrackleft}\isakeyword{where}\ d\ {\isacharequal}\ {\isachardoublequoteopen}abs\ x{\isachardoublequoteclose}\ \isakeyword{and}\ f\ {\isacharequal}\ {\isachardoublequoteopen}{\isasymlambda}x{\isachardot}\ sin\ x\ {\isacharslash}\ x{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ dist{\isacharunderscore}real{\isacharunderscore}def{\isacharparenright}%
\isanewline\isanewline
\isacommand{lemma}\isamarkupfalse%
\ continuous{\isacharunderscore}on{\isacharunderscore}sinc{\isacharbrackleft}continuous{\isacharunderscore}intros{\isacharbrackright}{\isacharcolon}\isanewline
\ \ {\isachardoublequoteopen}continuous{\isacharunderscore}on\ S\ f\ {\isasymLongrightarrow}\ continuous{\isacharunderscore}on\ S\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ sinc\ {\isacharparenleft}f\ x{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{using}\isamarkupfalse%
\ continuous{\isacharunderscore}on{\isacharunderscore}compose{\isacharbrackleft}of\ S\ f\ sinc{\isacharcomma}\ OF\ {\isacharunderscore}\ continuous{\isacharunderscore}at{\isacharunderscore}imp{\isacharunderscore}continuous{\isacharunderscore}on{\isacharbrackright}\isanewline
\ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp{\isacharcolon}\ isCont{\isacharunderscore}sinc{\isacharparenright}%
\isanewline\isanewline
\isacommand{lemma}\isamarkupfalse%
\ borel{\isacharunderscore}measurable{\isacharunderscore}sinc{\isacharbrackleft}measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}sinc\ {\isasymin}\ borel{\isacharunderscore}measurable\ borel{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}intro\ borel{\isacharunderscore}measurable{\isacharunderscore}continuous{\isacharunderscore}on{\isadigit{1}}\ continuous{\isacharunderscore}at{\isacharunderscore}imp{\isacharunderscore}continuous{\isacharunderscore}on\ ballI\ isCont{\isacharunderscore}sinc{\isacharparenright}%
\isanewline\isanewline
\isacommand{lemma}\isamarkupfalse%
\ sinc{\isacharunderscore}AE{\isacharcolon}\ {\isachardoublequoteopen}AE\ x\ in\ lborel{\isachardot}\ sin\ x\ {\isacharslash}\ x\ {\isacharequal}\ sinc\ x{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ AE{\isacharunderscore}I\ {\isacharbrackleft}\isakeyword{where}\ N\ {\isacharequal}\ {\isachardoublequoteopen}{\isacharbraceleft}{\isadigit{0}}{\isacharbraceright}{\isachardoublequoteclose}{\isacharbrackright}{\isacharcomma}\ auto{\isacharparenright}%
\isanewline\isanewline
\isacommand{definition}\isamarkupfalse%
\ Si\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\ \isakeyword{where}\ {\isachardoublequoteopen}Si\ t\ {\isasymequiv}\ LBINT\ x{\isacharequal}{\isadigit{0}}{\isachardot}{\isachardot}t{\isachardot}\ sin\ x\ {\isacharslash}\ x{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ Si{\isacharunderscore}alt{\isacharunderscore}def\ {\isacharcolon}\ {\isachardoublequoteopen}Si\ t\ {\isacharequal}\ LBINT\ x{\isacharequal}{\isadigit{0}}{\isachardot}{\isachardot}t{\isachardot}\ sinc\ x{\isachardoublequoteclose}\isanewline
\isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}case{\isacharunderscore}tac\ {\isachardoublequoteopen}{\isadigit{0}}\ {\isasymle}\ t{\isachardoublequoteclose}{\isacharparenright}\isanewline
\ \ \isacommand{unfolding}\isamarkupfalse%
\ Si{\isacharunderscore}def\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ interval{\isacharunderscore}lebesgue{\isacharunderscore}integral{\isacharunderscore}cong{\isacharunderscore}AE{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ AE{\isacharunderscore}I{\isacharprime}\ {\isacharbrackleft}\isakeyword{where}\ N\ {\isacharequal}\ {\isachardoublequoteopen}{\isacharbraceleft}{\isadigit{0}}{\isacharbraceright}{\isachardoublequoteclose}{\isacharbrackright}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ {\isacharparenleft}{\isadigit{1}}\ {\isadigit{2}}{\isacharparenright}\ interval{\isacharunderscore}integral{\isacharunderscore}endpoints{\isacharunderscore}reverse{\isacharcomma}\ simp{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ interval{\isacharunderscore}lebesgue{\isacharunderscore}integral{\isacharunderscore}cong{\isacharunderscore}AE{\isacharcomma}\ auto{\isacharparenright}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ AE{\isacharunderscore}I{\isacharprime}\ {\isacharbrackleft}\isakeyword{where}\ N\ {\isacharequal}\ {\isachardoublequoteopen}{\isacharbraceleft}{\isadigit{0}}{\isacharbraceright}{\isachardoublequoteclose}{\isacharbrackright}{\isacharcomma}\ auto{\isacharparenright}%
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ sinc{\isacharunderscore}neg\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}sinc\ {\isacharparenleft}{\isacharminus}\ x{\isacharparenright}\ {\isacharequal}\ sinc\ x{\isachardoublequoteclose}%
\isacommand{by}\isamarkupfalse%
\ auto%
\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ Si{\isacharunderscore}neg{\isacharcolon}\ \isanewline
\ \ \isakeyword{fixes}\ T\ {\isacharcolon}{\isacharcolon}\ real\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}T\ {\isasymge}\ {\isadigit{0}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}Si\ {\isacharparenleft}{\isacharminus}\ T{\isacharparenright}\ {\isacharequal}\ {\isacharminus}\ Si\ T{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}LBINT\ x{\isacharequal}ereal\ {\isadigit{0}}{\isachardot}{\isachardot}T{\isachardot}\ {\isacharminus}{\isadigit{1}}\ {\isacharasterisk}\isactrlsub R\ sinc\ {\isacharparenleft}{\isacharminus}\ x{\isacharparenright}\ {\isacharequal}\ LBINT\ y{\isacharequal}\ ereal\ {\isacharparenleft}{\isacharminus}\ {\isadigit{0}}{\isacharparenright}{\isachardot}{\isachardot}ereal\ {\isacharparenleft}{\isacharminus}\ T{\isacharparenright}{\isachardot}\ sinc\ y{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ interval{\isacharunderscore}integral{\isacharunderscore}substitution{\isacharunderscore}finite\ {\isacharbrackleft}OF\ assms{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharcolon}\ derivative{\isacharunderscore}intros\ continuous{\isacharunderscore}at{\isacharunderscore}imp{\isacharunderscore}continuous{\isacharunderscore}on\ isCont{\isacharunderscore}sinc{\isacharparenright}\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}LBINT\ x{\isacharequal}ereal\ {\isadigit{0}}{\isachardot}{\isachardot}T{\isachardot}\ {\isacharminus}{\isadigit{1}}\ {\isacharasterisk}\isactrlsub R\ sinc\ {\isacharparenleft}{\isacharminus}\ x{\isacharparenright}{\isacharparenright}\ {\isacharequal}\ {\isacharminus}{\isacharparenleft}LBINT\ x{\isacharequal}ereal\ {\isadigit{0}}{\isachardot}{\isachardot}T{\isachardot}\ sinc\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ sinc{\isacharunderscore}neg{\isacharparenright}\ {\isacharparenleft}simp{\isacharunderscore}all\ add{\isacharcolon}\ interval{\isacharunderscore}lebesgue{\isacharunderscore}integral{\isacharunderscore}uminus{\isacharparenright}\isanewline
\ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharminus}{\isacharparenleft}LBINT\ x{\isacharequal}ereal\ {\isadigit{0}}{\isachardot}{\isachardot}T{\isachardot}\ sinc\ x{\isacharparenright}\ {\isacharequal}\ LBINT\ y{\isacharequal}\ ereal\ {\isadigit{0}}{\isachardot}{\isachardot}ereal\ {\isacharparenleft}{\isacharminus}\ T{\isacharparenright}{\isachardot}\ sinc\ y{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}thesis\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ assms\ \isacommand{unfolding}\isamarkupfalse%
\ Si{\isacharunderscore}alt{\isacharunderscore}def\isanewline
\ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ zero{\isacharunderscore}ereal{\isacharunderscore}def{\isacharparenright}{\isacharplus}\isanewline
\ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ {\isacharasterisk}\ {\isacharbrackleft}symmetric{\isacharbrackright}{\isacharparenright}\isanewline
\isacommand{qed}\isamarkupfalse%
\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ iSi{\isacharunderscore}isCont{\isacharcolon}\ {\isachardoublequoteopen}isCont\ Si\ x{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}Si\ {\isacharequal}\ {\isacharparenleft}{\isasymlambda}t{\isachardot}\ LBINT\ x{\isacharequal}ereal\ {\isadigit{0}}{\isachardot}{\isachardot}ereal\ t{\isachardot}\ sinc\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ ext{\isacharcomma}\ simp\ add{\isacharcolon}\ Si{\isacharunderscore}def\ zero{\isacharunderscore}ereal{\isacharunderscore}def{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ interval{\isacharunderscore}integral{\isacharunderscore}cong{\isacharunderscore}AE{\isacharparenright}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ AE{\isacharunderscore}I{\isacharprime}\ {\isacharbrackleft}\isakeyword{where}\ N\ {\isacharequal}\ {\isachardoublequoteopen}{\isacharbraceleft}{\isadigit{0}}{\isacharbraceright}{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{thus}\isamarkupfalse%
\ {\isacharquery}thesis\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}elim\ ssubst{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ DERIV{\isacharunderscore}isCont{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ has{\isacharunderscore}field{\isacharunderscore}derivative{\isacharunderscore}within{\isacharunderscore}open\ {\isacharbrackleft}symmetric{\isacharcomma}\ \isanewline
\ \ \ \ \ \ \isakeyword{where}\ s\ {\isacharequal}\ {\isachardoublequoteopen}{\isacharbraceleft}{\isacharparenleft}min\ {\isacharparenleft}x\ {\isacharminus}\ {\isadigit{1}}{\isacharparenright}\ {\isacharparenleft}{\isacharminus}\ {\isadigit{1}}{\isacharparenright}{\isacharparenright}{\isacharless}{\isachardot}{\isachardot}{\isacharless}{\isacharparenleft}max\ {\isadigit{1}}\ {\isacharparenleft}x{\isacharplus}{\isadigit{1}}{\isacharparenright}{\isacharparenright}{\isacharbraceright}{\isachardoublequoteclose}{\isacharbrackright}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ DERIV{\isacharunderscore}subset\ {\isacharbrackleft}\isakeyword{where}\ s\ {\isacharequal}\ {\isachardoublequoteopen}{\isacharbraceleft}{\isacharparenleft}min\ {\isacharparenleft}x\ {\isacharminus}\ {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isacharminus}\ {\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isachardot}{\isachardot}{\isacharparenleft}max\ {\isadigit{2}}\ {\isacharparenleft}x{\isacharplus}{\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isacharbraceright}{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ has{\isacharunderscore}field{\isacharunderscore}derivative{\isacharunderscore}iff{\isacharunderscore}has{\isacharunderscore}vector{\isacharunderscore}derivative\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ interval{\isacharunderscore}integral{\isacharunderscore}FTC{\isadigit{2}}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ continuous{\isacharunderscore}on{\isacharunderscore}sinc\ continuous{\isacharunderscore}on{\isacharunderscore}id{\isacharparenright}\isanewline
\isacommand{qed}\isamarkupfalse%
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ borel{\isacharunderscore}measurable{\isacharunderscore}iSi{\isacharbrackleft}measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}Si\ {\isasymin}\ borel{\isacharunderscore}measurable\ borel{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharcolon}\ iSi{\isacharunderscore}isCont\ continuous{\isacharunderscore}at{\isacharunderscore}imp{\isacharunderscore}continuous{\isacharunderscore}on\ borel{\isacharunderscore}measurable{\isacharunderscore}continuous{\isacharunderscore}on{\isadigit{1}}{\isacharparenright}
\end{isabellebody}

\medskip

The \texttt{abbreviation} keyword indicates a definition which is always to be expanded; normally Isabelle does not expand definitions unless explicitly told to do so in order to avoid the associated explosion in proof search possibilities. Whether a definition should be made using \texttt{abbreviation} (so it is conveniently always expanded) or \texttt{definition} is an important design decision affecting the usability of a library, and there can be many conflicting factors. For example, case splits are difficult for automated tools to work with, but in the case of the $\sinc$ function we chose an abbreviation because the function was not used in a sufficiently fundamental way to warrant developing a reasonably complete list of its basic properties, as is needed for a definition made with the \texttt{definition} keyword to function well (without requiring that it constantly be expanded).

Billingsely's proof that $\lim_{x \rightarrow \infty} \Si(x) = \frac{\pi}{2}$ uses Fubini's theorem, a result concerning product measures which allows integrals with respect to product measures to be computed as iterated integrals, in either order, under very general circumstances. The product of two measure spaces $(X_1, \Sigma_1, \mu_1)$ and $(X_2, \Sigma_2, \mu_2)$ has as $\sigma$-algebra the algebra $\sigma(\Sigma_1 \times \Sigma_2)$ generated by rectangles $A \times B$ where $A \in \Sigma_1$ and $B \in \Sigma_2$, and measure given by $(\mu_1 \times \mu_2)(A \times B) = \mu_1(A)\mu_2(B)$ for $A \in \Sigma_1$ and $B \in \Sigma_2$, extended to the entire $\sigma$-algebra $\sigma(\Sigma_1 \times \Sigma_2)$ by Carath\'eodory's theorem. For a formal statement of Fubini's theorem we refer the reader to any standard treatment of measure theory, such as that in \cite{billingsley}. The basics of product measures had already been formalized by H\"olzl \cite{hoelzl-measure}, including Fubini's theorem. We formalized the result displayed in figure \ref{fig:isar} to facilitate the use of Fubini's theorem in proofs involving concrete integrals.

Let us now examine the informal computation of the limit of $\Si(x)$ at infinity, following Billingsley \cite{billingsley} as usual. The fundamental theorem of calculus immediately yields
\[ \int_0^t e^{-ux} \sin x \, dx \frac{1}{1+u^2}[1 - e^{-ut}(u \sin t + \cos t)]. \]
Taking $t \rightarrow \infty$, we see that
\[ \int_0^t \left( \int_0^\infty |e^{-ux} \sin x| \, du\right) \, dx = \int_0^t x\inv |\sin x| \, dx \le t, \]
\newpage
so Fubini's theorem may be used in the integration of $e^{-ux} \sin x$ over $(0,t) \times (0, \infty)$:
\begin{align*}
\int_0^t \frac{\sin x}{x} \, dx &= \int_0^t \sin x \left(\int_0^\infty e^{-ux} \, du\right) \, dx \\
                                &= \int_0^\infty \left(\int_0^t e^{-ux} \sin x \, dx\right) \, du \\
                                &= \int_0^\infty \frac{du}{1+u^2} - \int_0^\infty \frac{e^{-ut}}{1+u^2} (u \sin t + \cos t) \, du.
\end{align*}

It is an elementary fact that $\int_0^\infty \frac{du}{1+u^2} = \frac{\pi}{2}$, and the change of variable $v = ut$ can be used to see that the second integral in the final result of the above calculation converges to $0$ as $t \rightarrow \infty$. Hence
\[ \lim_{t \rightarrow \infty} \Si(t) = \lim_{t \rightarrow \infty} \int_0^t \frac{\sin x}{x} \, dx = \frac{\pi}{2}. \]

Formalizing this argument was quite possibly the most painful part of our formalization of the CLT, but it paid off with improvements to the integration library made because of lessons learned; see the preceding section for an outline of these. I won't include all the technical lemmata we employed during this painful formalization, but give formal statements of the main result and the fact that the subtracted ``error term'' in the last line of the informal calculation goes to zero (in inverted order, of course).

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ Si{\isacharunderscore}at{\isacharunderscore}top{\isacharunderscore}lemma{\isacharcolon}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isasymAnd}t{\isachardot}\ t\ {\isasymge}\ {\isadigit{0}}\ {\isasymLongrightarrow}\ interval{\isacharunderscore}lebesgue{\isacharunderscore}integrable\ lborel\ {\isadigit{0}}\ {\isasyminfinity}\isanewline
\ \ \ \ \ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ exp\ {\isacharparenleft}{\isacharminus}\ {\isacharparenleft}x\ {\isacharasterisk}\ t{\isacharparenright}{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}x\ {\isacharasterisk}\ sin\ t\ {\isacharplus}\ cos\ t{\isacharparenright}\ {\isacharslash}\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{and}\isanewline
\ \ \ \ {\isachardoublequoteopen}{\isacharparenleft}{\isacharparenleft}{\isasymlambda}t{\isachardot}\ {\isacharparenleft}LBINT\ x{\isacharequal}{\isadigit{0}}{\isachardot}{\isachardot}{\isasyminfinity}{\isachardot}\ exp\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}x\ {\isacharasterisk}\ t{\isacharparenright}{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}x\ {\isacharasterisk}\ sin\ t\ {\isacharplus}\ cos\ t{\isacharparenright}\ {\isacharslash}\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ x{\isacharcircum}{\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{0}}{\isacharparenright}\ at{\isacharunderscore}top{\isachardoublequoteclose}
\end{isabellebody}

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ Si{\isacharunderscore}at{\isacharunderscore}top{\isacharcolon}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isacharparenleft}Si\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ pi\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ at{\isacharunderscore}top{\isachardoublequoteclose}
\end{isabellebody}

\medskip

We shall see more use of the Isabelle integration library when working with characteristic functions, and in particular the proofs of the L\'evy inversion and continuity theorems. Much more than is outlined in this paper is present in the full formalization.

\subsection{Characteristic Functions} \label{sec:char}

As noted in the summary section \ref{sec:summary}, in a probabilistic context the Fourier transform of a probability measure (equivalently, of a random variable distributed as the given measure) is called its characteristic function. Here we describe our formalization of the definition and basic properties of characteristic functions.

First we need some properties of $e^{ix}$:

\newpage

\begin{isabellebody}
\isacommand{abbreviation}\isamarkupfalse%
\ iexp\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ {\isasymRightarrow}\ complex{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}iexp\ {\isasymequiv}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ Exp\ {\isacharparenleft}{\isasymi}\ {\isacharasterisk}\ complex{\isacharunderscore}of{\isacharunderscore}real\ x{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ isCont{\isacharunderscore}iexp\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}isCont\ iexp\ x{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}intro\ continuous{\isacharunderscore}intros{\isacharparenright}%
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ cmod{\isacharunderscore}iexp\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}cmod\ {\isacharparenleft}Exp\ {\isacharparenleft}{\isasymi}\ {\isacharasterisk}\ {\isacharparenleft}x{\isacharcolon}{\isacharcolon}real{\isacharparenright}{\isacharparenright}{\isacharparenright}\ {\isacharequal}\ {\isadigit{1}}{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ simp%
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ iexp{\isacharunderscore}alt{\isacharcolon}\ {\isachardoublequoteopen}iexp\ x\ {\isacharequal}\ cos\ x\ {\isacharplus}\ {\isasymi}\ {\isacharasterisk}\ sin\ x{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ complex{\isacharunderscore}eq{\isacharunderscore}iff\ cis{\isacharunderscore}conv{\isacharunderscore}exp{\isacharbrackleft}symmetric{\isacharbrackright}\ cos{\isacharunderscore}of{\isacharunderscore}real\ sin{\isacharunderscore}of{\isacharunderscore}real{\isacharparenright}%
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ has{\isacharunderscore}vector{\isacharunderscore}derivative{\isacharunderscore}iexp{\isacharbrackleft}derivative{\isacharunderscore}intros{\isacharbrackright}{\isacharcolon}\isanewline
\ \ {\isachardoublequoteopen}{\isacharparenleft}iexp\ has{\isacharunderscore}vector{\isacharunderscore}derivative\ {\isasymi}\ {\isacharasterisk}\ iexp\ x{\isacharparenright}\ {\isacharparenleft}at\ x\ within\ s{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ derivative{\isacharunderscore}eq{\isacharunderscore}intros\ simp{\isacharcolon}\ Re{\isacharunderscore}exp\ Im{\isacharunderscore}exp\ has{\isacharunderscore}vector{\isacharunderscore}derivative{\isacharunderscore}complex{\isacharunderscore}iff{\isacharparenright}%
\end{isabellebody}

\medskip

When we initially began formalizing properties of characteristic functions, the Isabelle library had no support for integrals of functions of type $\R \rightarrow \C$; fortunately the formalization of Bochner integration corrects that problem.

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ interval{\isacharunderscore}integral{\isacharunderscore}iexp{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ a\ b\ {\isacharcolon}{\isacharcolon}\ real\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isacharparenleft}CLBINT\ x{\isacharequal}a{\isachardot}{\isachardot}b{\isachardot}\ iexp\ x{\isacharparenright}\ {\isacharequal}\ ii\ {\isacharasterisk}\ iexp\ a\ {\isacharminus}\ ii\ {\isacharasterisk}\ iexp\ b{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ interval{\isacharunderscore}integral{\isacharunderscore}FTC{\isacharunderscore}finite\ {\isacharbrackleft}\isakeyword{where}\ F\ {\isacharequal}\ {\isachardoublequoteopen}{\isasymlambda}x{\isachardot}\ {\isacharminus}ii\ {\isacharasterisk}\ iexp\ x{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ derivative{\isacharunderscore}eq{\isacharunderscore}intros\ continuous{\isacharunderscore}intros{\isacharparenright}%
\end{isabellebody}

\medskip

Here \text{CLBINT} is ASCII notation for the Lebesgue integral of a function of type $\R \rightarrow \C$ with the canonical Lebesgue measure. As discussed in section \ref{sec:form_int}, computing the value of an integral is useless without also showing the function is integrable, so we do that as well.

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ prob{\isacharunderscore}space{\isacharparenright}\ integrable{\isacharunderscore}iexp{\isacharcolon}\ \isanewline
\ \ \isakeyword{assumes}\ f{\isacharcolon}\ {\isachardoublequoteopen}f\ {\isasymin}\ borel{\isacharunderscore}measurable\ M{\isachardoublequoteclose}\ {\isachardoublequoteopen}{\isasymAnd}x{\isachardot}\ Im\ {\isacharparenleft}f\ x{\isacharparenright}\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}integrable\ M\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ Exp\ {\isacharparenleft}ii\ {\isacharasterisk}\ {\isacharparenleft}f\ x{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}intro\ integrable{\isacharunderscore}const{\isacharunderscore}bound\ {\isacharbrackleft}of\ {\isacharunderscore}\ {\isadigit{1}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \isacommand{from}\isamarkupfalse%
\ f\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymAnd}x{\isachardot}\ of{\isacharunderscore}real\ {\isacharparenleft}Re\ {\isacharparenleft}f\ x{\isacharparenright}{\isacharparenright}\ {\isacharequal}\ f\ x{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ complex{\isacharunderscore}eq{\isacharunderscore}iff{\isacharparenright}\isanewline
\ \ \isacommand{then}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}AE\ x\ in\ M{\isachardot}\ cmod\ {\isacharparenleft}Exp\ {\isacharparenleft}{\isasymi}\ {\isacharasterisk}\ f\ x{\isacharparenright}{\isacharparenright}\ {\isasymle}\ {\isadigit{1}}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ cmod{\isacharunderscore}iexp{\isacharbrackleft}of\ {\isachardoublequoteopen}Re\ {\isacharparenleft}f\ x{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{for}\ x{\isacharbrackright}\ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\isacommand{qed}\isamarkupfalse%
\ {\isacharparenleft}insert\ f{\isacharcomma}\ simp{\isacharparenright}%
\end{isabellebody}

\medskip

We can now define the characteristic function of a measure and prove some basic properties. Informally, the characteristic function of a probability measure $\mu$ is simply the function $\phi(t) = \int e^{itx} \, \mu(dx)$, which is of course continuous (in fact uniformly continuous, see \cite{billingsley} p. 343).

\medskip

\begin{isabellebody}
\isacommand{definition}\isamarkupfalse%
\isanewline
\ \ char\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure\ {\isasymRightarrow}\ real\ {\isasymRightarrow}\ complex{\isachardoublequoteclose}\isanewline
\isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}char\ M\ t\ {\isasymequiv}\ complex{\isacharunderscore}lebesgue{\isacharunderscore}integral\ M\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ x{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ real{\isacharunderscore}distribution{\isacharparenright}\ char{\isacharunderscore}zero{\isacharcolon}\ {\isachardoublequoteopen}char\ M\ {\isadigit{0}}\ {\isacharequal}\ {\isadigit{1}}{\isachardoublequoteclose}\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ char{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ del{\isacharcolon}\ space{\isacharunderscore}eq{\isacharunderscore}univ\ add{\isacharcolon}\ prob{\isacharunderscore}space{\isacharparenright}
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ real{\isacharunderscore}distribution{\isacharparenright}\ cmod{\isacharunderscore}char{\isacharunderscore}le{\isacharunderscore}{\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}norm\ {\isacharparenleft}char\ M\ t{\isacharparenright}\ {\isasymle}\ {\isadigit{1}}{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}norm\ {\isacharparenleft}char\ M\ t{\isacharparenright}\ {\isasymle}\ {\isacharparenleft}{\isasymintegral}x{\isachardot}\ norm\ {\isacharparenleft}iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ x{\isacharparenright}{\isacharparenright}\ {\isasympartial}M{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ char{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}intro\ integral{\isacharunderscore}norm{\isacharunderscore}bound\ integrable{\isacharunderscore}iexp{\isacharparenright}\ auto\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isasymle}\ {\isadigit{1}}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ del{\isacharcolon}\ of{\isacharunderscore}real{\isacharunderscore}mult{\isacharparenright}\isanewline
\ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}thesis\ \isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\isacommand{qed}
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ real{\isacharunderscore}distribution{\isacharparenright}\ isCont{\isacharunderscore}char{\isacharcolon}\ {\isachardoublequoteopen}isCont\ {\isacharparenleft}char\ M{\isacharparenright}\ t{\isachardoublequoteclose}\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ continuous{\isacharunderscore}at{\isacharunderscore}sequentially\isanewline
\isacommand{proof}\isamarkupfalse%
\ safe\isanewline
\ \ \isacommand{fix}\isamarkupfalse%
\ X\ \isacommand{assume}\isamarkupfalse%
\ X{\isacharcolon}\ {\isachardoublequoteopen}X\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ t{\isachardoublequoteclose}\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}char\ M\ {\isasymcirc}\ X{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ char\ M\ t{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ comp{\isacharunderscore}def\ char{\isacharunderscore}def\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ integral{\isacharunderscore}dominated{\isacharunderscore}convergence{\isacharbrackleft}\isakeyword{where}\ w{\isacharequal}{\isachardoublequoteopen}{\isasymlambda}{\isacharunderscore}{\isachardot}\ {\isadigit{1}}{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ \ \ {\isacharparenleft}auto\ simp\ del{\isacharcolon}\ of{\isacharunderscore}real{\isacharunderscore}mult\ intro{\isacharbang}{\isacharcolon}\ AE{\isacharunderscore}I{\isadigit{2}}\ tendsto{\isacharunderscore}intros\ X{\isacharparenright}\isanewline
\isacommand{qed}
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ real{\isacharunderscore}distribution{\isacharparenright}\ char{\isacharunderscore}measurable\ {\isacharbrackleft}measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}char\ M\ {\isasymin}\ borel{\isacharunderscore}measurable\ borel{\isachardoublequoteclose}\isanewline
\isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ borel{\isacharunderscore}measurable{\isacharunderscore}continuous{\isacharunderscore}on{\isadigit{1}}\ continuous{\isacharunderscore}at{\isacharunderscore}imp{\isacharunderscore}continuous{\isacharunderscore}on\ isCont{\isacharunderscore}char{\isacharparenright}%
\end{isabellebody}

\medskip

It is instrumental to the proof of the central limit theorem that if $X$ and $Y$ are independent random variables (say on the space $(\Omega, \mathcal F, \P))$, then the characteristic function of their sum is the (pointwise) product of their characteristic functions. To see this, note that the random vectors $(\cos X, \sin X)$ and $(\cos Y, \sin Y)$ are independent, and so, letting $\phi_1$ be the characteristic function of $X$, $\phi_2$ be the characteristic function of $Y$, and $t \in \R$, we have (following Billingsley \cite{billingsley} as usual)
\begin{align*}
\phi_1(t)\phi_2(t) &= (\E(\cos X) + i\E(\sin X))(\E(\cos Y) + i\E(\sin Y)) \\
                   &= \E(\cos X) \E(\cos Y) - \E(\sin X)\E(\sin Y) \\
                   & \ + i(\E(\cos X)\E(\sin Y) + \E(\sin X)\E(\cos Y)) \\
                   &= \E(\cos X \cos Y - \sin X \sin Y + i(\cos X \sin Y + \sin X \cos Y)) \\
                   &= \E(e^{it(X + Y)}).
\end{align*}
Since if $X \indep Y$ and $X \sim \mu$, $Y \sim \nu$, then $X + Y \sim \mu * \nu$, the convulution of $\mu$ and $\nu$, we see that in general the characteristic function of a convolution is the (pointwise) product of the characteristic functions.

All this is formalized as follows. The setsum version handles finite sums, as will occur in the proof of the CLT.\phantom{)}

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ prob{\isacharunderscore}space{\isacharparenright}\ char{\isacharunderscore}distr{\isacharunderscore}sum{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ X{\isadigit{1}}\ X{\isadigit{2}}\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\ \isakeyword{and}\ t\ {\isacharcolon}{\isacharcolon}\ real\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}indep{\isacharunderscore}var\ borel\ X{\isadigit{1}}\ borel\ X{\isadigit{2}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}char\ {\isacharparenleft}distr\ M\ borel\ {\isacharparenleft}{\isasymlambda}{\isasymomega}{\isachardot}\ X{\isadigit{1}}\ {\isasymomega}\ {\isacharplus}\ X{\isadigit{2}}\ {\isasymomega}{\isacharparenright}{\isacharparenright}\ t\ {\isacharequal}\isanewline
\ \ \ \ char\ {\isacharparenleft}distr\ M\ borel\ X{\isadigit{1}}{\isacharparenright}\ t\ {\isacharasterisk}\ char\ {\isacharparenleft}distr\ M\ borel\ X{\isadigit{2}}{\isacharparenright}\ t{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{from}\isamarkupfalse%
\ assms\ \isacommand{have}\isamarkupfalse%
\ {\isacharbrackleft}measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}random{\isacharunderscore}variable\ borel\ X{\isadigit{1}}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}elim\ indep{\isacharunderscore}var{\isacharunderscore}rv{\isadigit{1}}{\isacharparenright}\isanewline
\ \ \isacommand{from}\isamarkupfalse%
\ assms\ \isacommand{have}\isamarkupfalse%
\ {\isacharbrackleft}measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}random{\isacharunderscore}variable\ borel\ X{\isadigit{2}}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}elim\ indep{\isacharunderscore}var{\isacharunderscore}rv{\isadigit{2}}{\isacharparenright}\isanewline
\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}char\ {\isacharparenleft}distr\ M\ borel\ {\isacharparenleft}{\isasymlambda}{\isasymomega}{\isachardot}\ X{\isadigit{1}}\ {\isasymomega}\ {\isacharplus}\ X{\isadigit{2}}\ {\isasymomega}{\isacharparenright}{\isacharparenright}\ t\ {\isacharequal}\ {\isacharparenleft}CLINT\ x{\isacharbar}M{\isachardot}\ iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ {\isacharparenleft}X{\isadigit{1}}\ x\ {\isacharplus}\ X{\isadigit{2}}\ x{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ char{\isacharunderscore}def\ integral{\isacharunderscore}distr{\isacharparenright}\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ {\isacharparenleft}CLINT\ x{\isacharbar}M{\isachardot}\ iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ {\isacharparenleft}X{\isadigit{1}}\ x{\isacharparenright}{\isacharparenright}\ {\isacharasterisk}\ iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ {\isacharparenleft}X{\isadigit{2}}\ x{\isacharparenright}{\isacharparenright}{\isacharparenright}\ {\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ field{\isacharunderscore}simps\ exp{\isacharunderscore}add{\isacharparenright}\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ {\isacharparenleft}CLINT\ x{\isacharbar}M{\isachardot}\ iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ {\isacharparenleft}X{\isadigit{1}}\ x{\isacharparenright}{\isacharparenright}{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}CLINT\ x{\isacharbar}M{\isachardot}\ iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ {\isacharparenleft}X{\isadigit{2}}\ x{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}intro\ indep{\isacharunderscore}var{\isacharunderscore}lebesgue{\isacharunderscore}integral\ indep{\isacharunderscore}var{\isacharunderscore}compose{\isacharbrackleft}unfolded\ comp{\isacharunderscore}def{\isacharcomma}\ OF\ assms{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ \ \ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ integrable{\isacharunderscore}iexp{\isacharparenright}\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ char\ {\isacharparenleft}distr\ M\ borel\ X{\isadigit{1}}{\isacharparenright}\ t\ {\isacharasterisk}\ char\ {\isacharparenleft}distr\ M\ borel\ X{\isadigit{2}}{\isacharparenright}\ t{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ char{\isacharunderscore}def\ integral{\isacharunderscore}distr{\isacharparenright}\isanewline
\ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}thesis\ \isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\isacommand{qed}\isamarkupfalse%
\isanewline\isanewline
\isacommand{lemma}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ prob{\isacharunderscore}space{\isacharparenright}\ char{\isacharunderscore}distr{\isacharunderscore}setsum{\isacharcolon}\isanewline
\ \ {\isachardoublequoteopen}indep{\isacharunderscore}vars\ {\isacharparenleft}{\isasymlambda}i{\isachardot}\ borel{\isacharparenright}\ X\ A\ {\isasymLongrightarrow}\isanewline
\ \ \ \ char\ {\isacharparenleft}distr\ M\ borel\ {\isacharparenleft}{\isasymlambda}{\isasymomega}{\isachardot}\ {\isasymSum}i{\isasymin}A{\isachardot}\ X\ i\ {\isasymomega}{\isacharparenright}{\isacharparenright}\ t\ {\isacharequal}\ {\isacharparenleft}{\isasymProd}i{\isasymin}A{\isachardot}\ char\ {\isacharparenleft}distr\ M\ borel\ {\isacharparenleft}X\ i{\isacharparenright}{\isacharparenright}\ t{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}induct\ A\ rule{\isacharcolon}\ infinite{\isacharunderscore}finite{\isacharunderscore}induct{\isacharparenright}\isanewline
\ \ \isacommand{case}\isamarkupfalse%
\ {\isacharparenleft}insert\ x\ F{\isacharparenright}\ \isacommand{with}\isamarkupfalse%
\ indep{\isacharunderscore}vars{\isacharunderscore}subset{\isacharbrackleft}of\ {\isachardoublequoteopen}{\isasymlambda}{\isacharunderscore}{\isachardot}\ borel{\isachardoublequoteclose}\ X\ {\isachardoublequoteopen}insert\ x\ F{\isachardoublequoteclose}\ F{\isacharbrackright}\ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}case\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ char{\isacharunderscore}distr{\isacharunderscore}sum\ indep{\isacharunderscore}vars{\isacharunderscore}setsum{\isacharparenright}\isanewline
\isacommand{qed}\isamarkupfalse%
\ {\isacharparenleft}simp{\isacharunderscore}all\ add{\isacharcolon}\ char{\isacharunderscore}def\ integral{\isacharunderscore}distr\ prob{\isacharunderscore}space\ del{\isacharcolon}\ distr{\isacharunderscore}const{\isacharparenright}%
\end{isabellebody}

\medskip

We shall also need the characteristic function of the standard normal distribution, in order to show that the product of characteristic functions of independent identically distributed random variables of finite variance converges to it. The characteristic function of the standard normal distribution is $e^{-t^2/2}$; the detailed calculation and its associated technical lemmata are ommited.

\medskip

\begin{isabellebody}
\isacommand{abbreviation}\isamarkupfalse%
\isanewline
\ \ {\isachardoublequoteopen}std{\isacharunderscore}normal{\isacharunderscore}distribution\ {\isasymequiv}\ density\ lborel\ std{\isacharunderscore}normal{\isacharunderscore}density{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ real{\isacharunderscore}dist{\isacharunderscore}normal{\isacharunderscore}dist{\isacharcolon}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ std{\isacharunderscore}normal{\isacharunderscore}distribution{\isachardoublequoteclose}\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ real{\isacharunderscore}distribution{\isacharunderscore}def\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ conjI{\isacharparenright}\isanewline
\ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ prob{\isacharunderscore}space{\isacharunderscore}normal{\isacharunderscore}density{\isacharcomma}\ auto{\isacharparenright}\isanewline
\isacommand{unfolding}\isamarkupfalse%
\ real{\isacharunderscore}distribution{\isacharunderscore}axioms{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ auto
\isanewline
\isanewline
\isacommand{theorem}\isamarkupfalse%
\ char{\isacharunderscore}std{\isacharunderscore}normal{\isacharunderscore}distribution{\isacharcolon}\isanewline
\ \ {\isachardoublequoteopen}char\ std{\isacharunderscore}normal{\isacharunderscore}distribution\ {\isacharequal}\ {\isacharparenleft}{\isasymlambda}t{\isachardot}\ complex{\isacharunderscore}of{\isacharunderscore}real\ {\isacharparenleft}exp\ {\isacharparenleft}{\isacharminus}\ {\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}
\end{isabellebody}

\subsection{The L\'evy Theorems}

Here we formalize some significant results about characteristic functions which are essential to their usefullness for studying distribution functions. The L\'evy inversion theorem shows that the characteristic function of a distribution uniquely determines that distribution, while the L\'evy continuity theorem shows that weak convergence of distributions is equivalent to pointwise convergence of the associated characteristic functions.

\subsubsection{The L\'evy Inversion Theorem}

In preparation for the informal proof of the L\'evy inversion theorem, note that
\begin{equation*} \tag{*}
\int_0^t \frac{\sin x\theta}{x} \, dx = \sgn \theta \, \Si(t|\theta|),
\end{equation*}
where $\sgn x$ is the sign of $x$ ($\sgn x = 1$ if $x > 0$, $\sgn 0 = 0$, and $\sgn x = -1$ if $x < 0$).

\begin{theorem}
Let $\mu$ be a probability measure, and $\phi$ be the characteristic function of $\mu$. If $a$ and $b$ are continuity points of $\mu$ and $a < b$, then
\[ \mu (a,b] = \lim_{T \rightarrow \infty} \frac{1}{2\pi} \int_{-T}^T \frac{e^{-ita} - e^{-itb}}{it} \phi(t) \, dt. \]
Hence distinct probability measures have distinct characteristic functions.
\end{theorem}

\begin{proof}
Define
\[ I(T) = \frac{1}{2\pi} \int_{-T}^T \frac{e^{ita} - e^{itb}}{it} \phi(t) \, dt. \]
Since $[-T,T] \times \R$ has finite measure with respect to $\lambda \times \mu$ (where $\lambda$ is Lebesgue measure), and $|\phi(t)| \le 1$ and
\[ \left|\frac{e^{ita} - e^{itb}}{it}\right| \le |b-a| \]
for all $t$, we have by Fubini's theorem that
\[ I(T) = \frac{1}{2\pi} \int_{-\infty}^\infty \int_{-T}^T \frac{e^{it(x-a)} - e^{it(x-b)}}{it} \, dt \, \mu(dx). \]
Using DeMoivre's formula to rewrite the integrand and noting $(*)$ (from before the statement of the theorem) and the fact that $\sin$ is an odd, and $\cos$ an even, function reveals that
\[ I(T) = \int_{-\infty}^\infty \left(\frac{\sgn (x-a)}{\pi} \Si(T|x-a|) - \frac{\sgn (x-b)}{\pi} \Si(T|x-b|)\right) \, \mu(dx). \]
Since $\lim_{T \rightarrow \infty} \Si(T) = \frac{\pi}{2}$, we have that $\Si$ is bounded, and hence the integrand is bounded. Moreover, the integrand converges to the function given by
\[ \psi_{a,b}(x) = \begin{cases} 0 & \text{if $x < a$,} \\
                                 \frac{1}{2} & \text{if $x = a$,} \\
                                 1 & \text{if $a < x < b$,} \\
                                 \frac{1}{2} & \text{if $x = b$,} \\
                                 0 & \text{if $b < x$.} \end{cases} \]
Thus by the bounded convergence theorem we have that $I(T) \rightarrow \int \psi_{a,b} \, d\mu$ as $T \rightarrow \infty$, which implies the desired conclusion when $\mu \{a\} = \mu \{b\} = 0$.
\end{proof}

Uniqueness follows because if two Borel probability measures $\mu$, $\nu$ have the same characteristic function, they agree on the $\pi$-system of half-open intervals $(a,b]$ where $\mu \{a\} = \nu \{a\} = \mu \{b\} = \nu \{b\} = 0$ (this is a $\pi$-system generating the Borel sets because $\mu$ and $\nu$ each have countably many atoms), and hence everywhere by the Carath\'eodory extension theorem.

The bound
\[ \left|\frac{e^{ita} - e^{itb}}{it}\right| \le |b-a| \]
is formalized as

\medskip

\begin{isabellebody}
\isacommand{lemma}\isamarkupfalse%
\ Levy{\isacharunderscore}Inversion{\isacharunderscore}aux{\isadigit{2}}{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ a\ b\ t\ {\isacharcolon}{\isacharcolon}\ real\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}a\ {\isasymle}\ b{\isachardoublequoteclose}\ \isakeyword{and}\ {\isachardoublequoteopen}t\ {\isasymnoteq}\ {\isadigit{0}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}cmod\ {\isacharparenleft}{\isacharparenleft}iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ b{\isacharparenright}\ {\isacharminus}\ iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ a{\isacharparenright}{\isacharparenright}\ {\isacharslash}\ {\isacharparenleft}ii\ {\isacharasterisk}\ t{\isacharparenright}{\isacharparenright}\ {\isasymle}\ b\ {\isacharminus}\ a{\isachardoublequoteclose}\isanewline
\ \ \ \ {\isacharparenleft}\isakeyword{is}\ {\isachardoublequoteopen}{\isacharquery}F\ {\isasymle}\ {\isacharunderscore}{\isachardoublequoteclose}{\isacharparenright}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharquery}F\ {\isacharequal}\ cmod\ {\isacharparenleft}iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ a{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isacharparenright}\ {\isacharminus}\ {\isadigit{1}}{\isacharparenright}\ {\isacharslash}\ {\isacharparenleft}ii\ {\isacharasterisk}\ t{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ {\isacharbackquoteopen}t\ {\isasymnoteq}\ {\isadigit{0}}{\isacharbackquoteclose}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}intro\ arg{\isacharunderscore}cong{\isacharbrackleft}\isakeyword{where}\ f{\isacharequal}norm{\isacharbrackright}{\isacharparenright}\ {\isacharparenleft}simp\ add{\isacharcolon}\ field{\isacharunderscore}simps\ exp{\isacharunderscore}diff\ exp{\isacharunderscore}minus{\isacharparenright}\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ cmod\ {\isacharparenleft}iexp\ {\isacharparenleft}t\ {\isacharasterisk}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isacharparenright}\ {\isacharminus}\ {\isadigit{1}}{\isacharparenright}\ {\isacharslash}\ abs\ t{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ norm{\isacharunderscore}divide{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ norm{\isacharunderscore}mult{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ cmod{\isacharunderscore}iexp{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ {\isacharbackquoteopen}t\ {\isasymnoteq}\ {\isadigit{0}}{\isacharbackquoteclose}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ complex{\isacharunderscore}eq{\isacharunderscore}iff\ norm{\isacharunderscore}mult{\isacharparenright}\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isasymle}\ abs\ {\isacharparenleft}t\ {\isacharasterisk}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isacharparenright}\ {\isacharslash}\ abs\ t{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ divide{\isacharunderscore}right{\isacharunderscore}mono{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ equation{\isacharunderscore}{\isadigit{2}}{\isadigit{6}}p{\isadigit{4}}a\ {\isacharbrackleft}of\ {\isachardoublequoteopen}t\ {\isacharasterisk}\ {\isacharparenleft}b\ {\isacharminus}\ a{\isacharparenright}{\isachardoublequoteclose}\ {\isadigit{0}}{\isacharbrackright}\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ field{\isacharunderscore}simps\ eval{\isacharunderscore}nat{\isacharunderscore}numeral{\isacharparenright}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ force\isanewline
\ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ b\ {\isacharminus}\ a{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ assms\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ abs{\isacharunderscore}mult{\isacharparenright}\ \isanewline
\ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isacharquery}thesis\ \isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\isacommand{qed}
\end{isabellebody}

\medskip

The formal statements of the inversion and uniqueness theorems follow; both proofs are long and omitted, though it should be noted that obtaining uniqueness from inversion was not as straightforward as it appears it ought to be from the informal proof.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ Levy{\isacharunderscore}Inversion{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{and}\ a\ b\ {\isacharcolon}{\isacharcolon}\ real\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}a\ {\isasymle}\ b{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{defines}\ {\isachardoublequoteopen}{\isasymmu}\ {\isasymequiv}\ measure\ M{\isachardoublequoteclose}\ \isakeyword{and}\ {\isachardoublequoteopen}{\isasymphi}\ {\isasymequiv}\ char\ M{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{and}\ {\isachardoublequoteopen}{\isasymmu}\ {\isacharbraceleft}a{\isacharbraceright}\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isakeyword{and}\ {\isachardoublequoteopen}{\isasymmu}\ {\isacharbraceleft}b{\isacharbraceright}\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\isanewline
\ \ {\isachardoublequoteopen}{\isacharparenleft}{\isacharparenleft}{\isasymlambda}T\ {\isacharcolon}{\isacharcolon}\ nat{\isachardot}\ {\isadigit{1}}\ {\isacharslash}\ {\isacharparenleft}{\isadigit{2}}\ {\isacharasterisk}\ pi{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}CLBINT\ t{\isacharequal}{\isacharminus}T{\isachardot}{\isachardot}T{\isachardot}\ {\isacharparenleft}iexp\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t\ {\isacharasterisk}\ a{\isacharparenright}{\isacharparenright}\ {\isacharminus}\isanewline
\ \ iexp\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t\ {\isacharasterisk}\ b{\isacharparenright}{\isacharparenright}{\isacharparenright}\ {\isacharslash}\ {\isacharparenleft}ii\ {\isacharasterisk}\ t{\isacharparenright}\ {\isacharasterisk}\ {\isasymphi}\ t{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isasymmu}\ {\isacharbraceleft}a{\isacharless}{\isachardot}{\isachardot}b{\isacharbraceright}{\isacharparenright}\ at{\isacharunderscore}top{\isachardoublequoteclose}\isanewline
\ \ {\isacharparenleft}\isakeyword{is}\ {\isachardoublequoteopen}{\isacharparenleft}{\isacharparenleft}{\isasymlambda}T\ {\isacharcolon}{\isacharcolon}\ nat{\isachardot}\ {\isadigit{1}}\ {\isacharslash}\ {\isacharparenleft}{\isadigit{2}}\ {\isacharasterisk}\ pi{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}CLBINT\ t{\isacharequal}{\isacharminus}T{\isachardot}{\isachardot}T{\isachardot}\ {\isacharquery}F\ t\ {\isacharasterisk}\ {\isasymphi}\ t{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ \isanewline
\ \ \ \ \ \ of{\isacharunderscore}real\ {\isacharparenleft}{\isasymmu}\ {\isacharbraceleft}a{\isacharless}{\isachardot}{\isachardot}b{\isacharbraceright}{\isacharparenright}{\isacharparenright}\ at{\isacharunderscore}top{\isachardoublequoteclose}{\isacharparenright}
\end{isabellebody}

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ Levy{\isacharunderscore}uniqueness{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ M{\isadigit{1}}\ M{\isadigit{2}}\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isadigit{1}}{\isachardoublequoteclose}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isadigit{2}}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isachardoublequoteopen}char\ M{\isadigit{1}}\ {\isacharequal}\ char\ M{\isadigit{2}}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}M{\isadigit{1}}\ {\isacharequal}\ M{\isadigit{2}}{\isachardoublequoteclose}
\end{isabellebody}

\subsubsection{The L\'evy Continuity Theorem}

We are finally ready to connect characteristic functions to weak convergence.

\begin{theorem}
Let $\bldseq{\mu_n}{n \in \N}$ be a sequence of probability measures with characteristic functions $\bldseq{\phi_n}{n \in \N}$, and $\mu$ be a probability measure with characteristic function $\phi$. Then $\mu_n \Rightarrow \mu$ iff $\phi_n \rightarrow \phi$ pointwise.
\end{theorem}

\begin{proof}
$(\Longrightarrow)$: Since $e^{itx}$ has bounded modulus and is continuous in $x$ for each $t \in \R$, this follows immediately from the portmanteau theorem applied to the real and imaginary parts of $e^{itx}$.

$(\Longleftarrow)$: We have another opportunity to use Fubini's theorem.
\begin{align*}
\frac{1}{u} \int_{-u}^u (1 - \phi_n(t)) \, dt &= \int_{-\infty}^\infty \left(\frac{1}{u}\int_{-u}^u (1 - e^{itx}) \, dt\right) \, \mu_n(dx) \\
                                              &= 2\int_{-\infty}^\infty (1 - \sinc ux) \, \mu_n(dx) \\
                                              &\ge 2\int_{|x| \ge 2/u} \left(1 - \frac{1}{|ux|}\right) \, \mu_n(dx) \\
                                              &\ge \mu_n \bldset{x \in \R}{|x| \ge \frac{2}{u}}.
\end{align*}
Since $\phi$ is continuous and $\phi(0) = 1$, for every $\eps > 0$ there exists $u \in \R$ such that
\[ \frac{1}{u} \int_{-u}^u (1 - \phi(t)) \, dt < \eps. \]
Because $\phi_n \rightarrow \phi$ pointwise, by the bounded convergence theorem there is $n_0 \in \N$ such that
\[ \frac{1}{u} \int_{-u}^u (1 - \phi_n(t)) \, dt < 2\eps. \]
for $n \ge n_0$. Thus $\mu_n \bldset{x \in \R}{|x| \ge 2u\inv} < 2\eps$, and so for some $a \ge 2u\inv$ we have $\mu_n \bldset{x \in \R}{|x| \ge a} < 2\eps$. Consequently the sequence $\bldseq{\mu_n}{n \in \N}$ is tight.

By the corollary concerning tightness (see the end of section \ref{sec:helly}) it is sufficient to show that every subsequece $\bldseq{\mu_{n_k}}{k \in \N}$ which has a weak limit in fact converges weakly to $\mu$. If $\mu_{n_k} \Rightarrow \nu$ for some probability measure $\nu$, then by the first half of the theorem we have that $\lim_{k \rightarrow \infty} \phi_{n_k}(t) = \phi(t)$ is the characteristic function of $\nu$, and hence $\nu = \mu$ by the uniqueness theorem.
\end{proof}

As the reader may anticipate, the formal proof is long and difficult. The formal statement of the L\'evy continuity theorem suffices to be written here.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ levy{\isacharunderscore}continuity{\isadigit{1}}{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\isanewline
\ \ \ \ M\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ M{\isacharprime}\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ \isanewline
\ \ \ \ real{\isacharunderscore}distr{\isacharunderscore}M\ {\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ real{\isacharunderscore}distribution\ {\isacharparenleft}M\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ real{\isacharunderscore}distr{\isacharunderscore}M{\isacharprime}{\isacharcolon}\ {\isachardoublequoteopen}real{\isacharunderscore}distribution\ M{\isacharprime}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ measure{\isacharunderscore}conv{\isacharcolon}\ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ M\ M{\isacharprime}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\isanewline
\ \ \ \ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ char\ {\isacharparenleft}M\ n{\isacharparenright}\ t{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ char\ M{\isacharprime}\ t{\isachardoublequoteclose}
\end{isabellebody}

\subsection{The Central Limit Theorem}

All the pieces are now in place for the proof of the central limit theorem; we just need to put them together. To remind the reader: we shall show that if $\mu$ is the distribution of a random variable with finite nonzero variance and $\phi$ is the characteristic function of $\mu$, then $\phi(\sigma\inv n^{-1/2} x)^n \rightarrow e^{-x^2/2}$ for each $x \in \R$, where $e^{-x^2/2}$ is the characteristic function of a standard normal distribution. From this and facts proven earlier about characteristic functions of independent random variables it follows that the normalized sums $\frac{1}{\sigma \sqrt n} \sum_{k=0}^n (X_k - \E(X_k))$ converge weakly to a standard normal distribution. For the remainder of this section, we assume without loss of generality that the random variables we work with have mean zero and variance one (otherwise a random variable with finite nonzero variance can be translated and scaled).

The central limit theorem is proved simply by showing that if $X$ is a random variable with zero mean and unit variance, then the characteristic function $\phi$ of $x$ satisfies $\phi(t) = 1 - t^2/2 + o(t^2)$, as follows from Taylor expansion about zero. Thus
\[ \phi\left(\frac{t}{\sqrt n}\right)^n = \left(1 - \frac{t^2}{2n} + o\left(\frac{t^2}{n}\right)\right) \rightarrow e^{-t^2/2}, \]
by basic facts about limits. Since $e^{-t^2/2}$ is the characteristic function of a standard normal distribution, and the characteristic function of $\frac{1}{\sqrt n} \sum_{k=0}^n X_k$ is $\phi(t/\sqrt n)^n$, we have by the L\'evy continuity theorem that
\[ \frac{1}{\sqrt n} \sum_{k=0}^n X_k \Rightarrow N, \]
where $N$ is a random variable with standard normal distribution, as desired.

Because it is the primary goal of our formalization, we present the formal proof of the central limit theorem in full.

\medskip

\begin{isabellebody}
\isacommand{theorem}\isamarkupfalse%
\ {\isacharparenleft}\isakeyword{in}\ prob{\isacharunderscore}space{\isacharparenright}\ central{\isacharunderscore}limit{\isacharunderscore}theorem{\isacharcolon}\isanewline
\ \ \isakeyword{fixes}\ \isanewline
\ \ \ \ X\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isasymmu}\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}real\ measure{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isasymsigma}\ {\isacharcolon}{\isacharcolon}\ real\ \isakeyword{and}\isanewline
\ \ \ \ S\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ real{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\isanewline
\ \ \ \ X{\isacharunderscore}indep{\isacharcolon}\ {\isachardoublequoteopen}indep{\isacharunderscore}vars\ {\isacharparenleft}{\isasymlambda}i{\isachardot}\ borel{\isacharparenright}\ X\ UNIV{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}integrable{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ integrable\ M\ {\isacharparenleft}X\ n{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}mean{\isacharunderscore}{\isadigit{0}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ expectation\ {\isacharparenleft}X\ n{\isacharparenright}\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ {\isasymsigma}{\isacharunderscore}pos{\isacharcolon}\ {\isachardoublequoteopen}{\isasymsigma}\ {\isachargreater}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}square{\isacharunderscore}integrable{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ integrable\ M\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ {\isacharparenleft}X\ n\ x{\isacharparenright}\isactrlsup {\isadigit{2}}{\isacharparenright}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}variance{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ variance\ {\isacharparenleft}X\ n{\isacharparenright}\ {\isacharequal}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isachardoublequoteclose}\ \isakeyword{and}\isanewline
\ \ \ \ X{\isacharunderscore}distrib{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ distr\ M\ borel\ {\isacharparenleft}X\ n{\isacharparenright}\ {\isacharequal}\ {\isasymmu}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{defines}\isanewline
\ \ \ \ {\isachardoublequoteopen}S\ n\ {\isasymequiv}\ {\isasymlambda}x{\isachardot}\ {\isasymSum}i{\isacharless}n{\isachardot}\ X\ i\ x{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\isanewline
\ \ \ \ {\isachardoublequoteopen}weak{\isacharunderscore}conv{\isacharunderscore}m\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ distr\ M\ borel\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ S\ n\ x\ {\isacharslash}\ sqrt\ {\isacharparenleft}n\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isacharparenright}\ \isanewline
\ \ \ \ \ \ \ \ {\isacharparenleft}density\ lborel\ std{\isacharunderscore}normal{\isacharunderscore}density{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \isacommand{def}\isamarkupfalse%
\ S{\isacharprime}\ {\isasymequiv}\ {\isachardoublequoteopen}{\isasymlambda}n\ x{\isachardot}\ S\ n\ x\ {\isacharslash}\ sqrt\ {\isacharparenleft}n\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isacommand{def}\isamarkupfalse%
\ {\isasymphi}\ {\isasymequiv}\ {\isachardoublequoteopen}{\isasymlambda}n{\isachardot}\ char\ {\isacharparenleft}distr\ M\ borel\ {\isacharparenleft}S{\isacharprime}\ n{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \isacommand{def}\isamarkupfalse%
\ {\isasympsi}\ {\isasymequiv}\ {\isachardoublequoteopen}{\isasymlambda}n\ t{\isachardot}\ char\ {\isasymmu}\ {\isacharparenleft}t\ {\isacharslash}\ sqrt\ {\isacharparenleft}{\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharasterisk}\ n{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ X{\isacharunderscore}rv\ {\isacharbrackleft}simp{\isacharcomma}\ measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ random{\isacharunderscore}variable\ borel\ {\isacharparenleft}X\ n{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ X{\isacharunderscore}indep\ \isacommand{unfolding}\isamarkupfalse%
\ indep{\isacharunderscore}vars{\isacharunderscore}def{\isadigit{2}}\ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{interpret}\isamarkupfalse%
\ {\isasymmu}{\isacharcolon}\ real{\isacharunderscore}distribution\ {\isasymmu}\isanewline
\ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ X{\isacharunderscore}distrib\ {\isacharbrackleft}symmetric{\isacharcomma}\ of\ {\isadigit{0}}{\isacharbrackright}{\isacharcomma}\ rule\ real{\isacharunderscore}distribution{\isacharunderscore}distr{\isacharcomma}\ simp{\isacharparenright}\isanewline
\ \ \isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isasymmu}{\isacharunderscore}integrable\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}integrable\ {\isasymmu}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ X{\isacharunderscore}distrib\ {\isacharbrackleft}symmetric{\isacharcomma}\ of\ {\isadigit{0}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ assms\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ integrable{\isacharunderscore}distr{\isacharunderscore}eq{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isasymmu}{\isacharunderscore}mean{\isacharunderscore}integrable\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymmu}{\isachardot}expectation\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ x{\isacharparenright}\ {\isacharequal}\ {\isadigit{0}}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ X{\isacharunderscore}distrib\ {\isacharbrackleft}symmetric{\isacharcomma}\ of\ {\isadigit{0}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ assms\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ integral{\isacharunderscore}distr{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isasymmu}{\isacharunderscore}square{\isacharunderscore}integrable\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}integrable\ {\isasymmu}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ x{\isacharcircum}{\isadigit{2}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ X{\isacharunderscore}distrib\ {\isacharbrackleft}symmetric{\isacharcomma}\ of\ {\isadigit{0}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ assms\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ integrable{\isacharunderscore}distr{\isacharunderscore}eq{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isasymmu}{\isacharunderscore}variance\ {\isacharbrackleft}simp{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymmu}{\isachardot}expectation\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ x{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharequal}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ X{\isacharunderscore}distrib\ {\isacharbrackleft}symmetric{\isacharcomma}\ of\ {\isadigit{0}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{using}\isamarkupfalse%
\ assms\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ integral{\isacharunderscore}distr{\isacharcomma}\ auto{\isacharparenright}\isanewline
\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ main{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}t{\isachardot}\ eventually\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ cmod\ {\isacharparenleft}{\isasymphi}\ n\ t\ {\isacharminus}\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ n{\isacharparenright}{\isacharcircum}n{\isacharparenright}\ {\isasymle}\ \isanewline
\ \ \ \ \ \ \ \ {\isacharparenleft}t\isactrlsup {\isadigit{2}}\ {\isacharslash}\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}t\ {\isacharslash}\ sqrt\ {\isacharparenleft}{\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharasterisk}\ n{\isacharparenright}{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isacharparenright}\isanewline
\ \ \ \ \ \ sequentially{\isachardoublequoteclose}\isanewline
\ \ \isacommand{proof}\isamarkupfalse%
\ {\isacharparenleft}rule\ eventually{\isacharunderscore}sequentiallyI{\isacharparenright}\isanewline
\ \ \ \ \isacommand{fix}\isamarkupfalse%
\ n\ {\isacharcolon}{\isacharcolon}\ nat\ \isakeyword{and}\ t\ {\isacharcolon}{\isacharcolon}\ real\isanewline
\ \ \ \ \isacommand{assume}\isamarkupfalse%
\ {\isachardoublequoteopen}n\ {\isasymge}\ nat\ {\isacharparenleft}ceiling\ {\isacharparenleft}t{\isacharcircum}{\isadigit{2}}\ {\isacharslash}\ {\isadigit{4}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{hence}\isamarkupfalse%
\ n{\isacharcolon}\ {\isachardoublequoteopen}n\ {\isasymge}\ t{\isacharcircum}{\isadigit{2}}\ {\isacharslash}\ {\isadigit{4}}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ nat{\isacharunderscore}ceiling{\isacharunderscore}le{\isacharunderscore}eq\ {\isacharbrackleft}symmetric{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{let}\isamarkupfalse%
\ {\isacharquery}t\ {\isacharequal}\ {\isachardoublequoteopen}t\ {\isacharslash}\ sqrt\ {\isacharparenleft}{\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharasterisk}\ n{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isanewline
\ \ \ \ \isacommand{def}\isamarkupfalse%
\ {\isasympsi}{\isacharprime}\ {\isasymequiv}\ {\isachardoublequoteopen}{\isasymlambda}n\ i{\isachardot}\ char\ {\isacharparenleft}distr\ M\ borel\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ X\ i\ x\ {\isacharslash}\ sqrt\ {\isacharparenleft}{\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharasterisk}\ n{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n\ i\ t{\isachardot}\ {\isasympsi}{\isacharprime}\ n\ i\ t\ {\isacharequal}\ {\isasympsi}\ n\ t{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ {\isasympsi}{\isacharunderscore}def\ {\isasympsi}{\isacharprime}{\isacharunderscore}def\ char{\isacharunderscore}def\ \isacommand{apply}\isamarkupfalse%
\ auto\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ X{\isacharunderscore}distrib\ {\isacharbrackleft}symmetric{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ integral{\isacharunderscore}distr{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ integral{\isacharunderscore}distr{\isacharcomma}\ auto{\isacharparenright}\isanewline
\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}S{\isacharprime}\ n\ {\isacharequal}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ {\isacharparenleft}{\isasymSum}\ i\ {\isacharless}\ n{\isachardot}\ X\ i\ x\ {\isacharslash}\ sqrt\ {\isacharparenleft}{\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharasterisk}\ n{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\ \isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ ext{\isacharcomma}\ simp\ add{\isacharcolon}\ S{\isacharprime}{\isacharunderscore}def\ S{\isacharunderscore}def\ setsum{\isacharunderscore}divide{\isacharunderscore}distrib\ ac{\isacharunderscore}simps{\isacharparenright}\isanewline
\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymphi}\ n\ t\ {\isacharequal}\ {\isacharparenleft}{\isasymProd}\ i\ {\isacharless}\ n{\isachardot}\ {\isasympsi}{\isacharprime}\ n\ i\ t{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ {\isasymphi}{\isacharunderscore}def\ {\isasympsi}{\isacharprime}{\isacharunderscore}def\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ {\isadigit{1}}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ char{\isacharunderscore}distr{\isacharunderscore}setsum{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ indep{\isacharunderscore}vars{\isacharunderscore}compose{\isadigit{2}}{\isacharbrackleft}\isakeyword{where}\ X{\isacharequal}X{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ indep{\isacharunderscore}vars{\isacharunderscore}subset{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ X{\isacharunderscore}indep{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ auto\isanewline
\ \ \ \ \ \ \isacommand{done}\isamarkupfalse%
\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ {\isacharparenleft}{\isasympsi}\ n\ t{\isacharparenright}{\isacharcircum}n{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}auto\ simp\ add{\isacharcolon}\ {\isacharasterisk}\ setprod{\isacharunderscore}constant{\isacharparenright}\isanewline
\ \ \ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymphi}\ n\ t\ {\isacharequal}{\isacharparenleft}{\isasympsi}\ n\ t{\isacharparenright}{\isacharcircum}n{\isachardoublequoteclose}\ \isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}cmod\ {\isacharparenleft}{\isasympsi}\ n\ t\ {\isacharminus}\ {\isacharparenleft}{\isadigit{1}}\ {\isacharminus}\ {\isacharquery}t{\isacharcircum}{\isadigit{2}}\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}{\isacharparenright}\ {\isasymle}\ \isanewline
\ \ \ \ \ \ \ \ {\isacharquery}t\isactrlsup {\isadigit{2}}\ {\isacharslash}\ {\isadigit{6}}\ {\isacharasterisk}\ {\isacharparenleft}LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}{\isacharquery}t{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ {\isasympsi}{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ {\isasymmu}{\isachardot}aux{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharquery}t{\isacharcircum}{\isadigit{2}}\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharequal}\ t{\isacharcircum}{\isadigit{2}}\ {\isacharslash}\ n{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{using}\isamarkupfalse%
\ {\isasymsigma}{\isacharunderscore}pos\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ power{\isacharunderscore}divide{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}t{\isacharcircum}{\isadigit{2}}\ {\isacharslash}\ n\ {\isacharslash}\ {\isadigit{2}}\ {\isacharequal}\ {\isacharparenleft}t{\isacharcircum}{\isadigit{2}}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ n{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isacharasterisk}{\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}cmod\ {\isacharparenleft}{\isasympsi}\ n\ t\ {\isacharminus}\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ n{\isacharparenright}{\isacharparenright}\ {\isasymle}\ \isanewline
\ \ \ \ \ \ {\isacharquery}t\isactrlsup {\isadigit{2}}\ {\isacharslash}\ {\isadigit{6}}\ {\isacharasterisk}\ {\isacharparenleft}LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}{\isacharquery}t{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}cmod\ {\isacharparenleft}{\isasymphi}\ n\ t\ {\isacharminus}\ {\isacharparenleft}complex{\isacharunderscore}of{\isacharunderscore}real\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ n{\isacharparenright}{\isacharparenright}{\isacharcircum}n{\isacharparenright}\ {\isasymle}\ \isanewline
\ \ \ \ \ \ \ \ \ n\ {\isacharasterisk}\ cmod\ {\isacharparenleft}{\isasympsi}\ n\ t\ {\isacharminus}\ {\isacharparenleft}complex{\isacharunderscore}of{\isacharunderscore}real\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ n{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ {\isadigit{2}}{\isacharcomma}\ rule\ norm{\isacharunderscore}power{\isacharunderscore}diff{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ {\isasympsi}{\isacharunderscore}def\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ {\isasymmu}{\isachardot}cmod{\isacharunderscore}char{\isacharunderscore}le{\isacharunderscore}{\isadigit{1}}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ only{\isacharcolon}\ norm{\isacharunderscore}of{\isacharunderscore}real{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ abs{\isacharunderscore}leI{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{using}\isamarkupfalse%
\ n\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ divide{\isacharunderscore}le{\isacharunderscore}eq{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isasymle}\ n\ {\isacharasterisk}\ {\isacharparenleft}{\isacharquery}t\isactrlsup {\isadigit{2}}\ {\isacharslash}\ {\isadigit{6}}\ {\isacharasterisk}\ {\isacharparenleft}LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}{\isacharquery}t{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ mult{\isacharunderscore}left{\isacharunderscore}mono\ {\isacharbrackleft}OF\ {\isacharasterisk}{\isacharasterisk}{\isacharbrackright}{\isacharcomma}\ simp{\isacharparenright}\isanewline
\ \ \ \ \isacommand{also}\isamarkupfalse%
\ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymdots}\ {\isacharequal}\ {\isacharparenleft}t\isactrlsup {\isadigit{2}}\ {\isacharslash}\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}{\isacharquery}t{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\ \isanewline
\ \ \ \ \ \ \isacommand{using}\isamarkupfalse%
\ {\isasymsigma}{\isacharunderscore}pos\ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ field{\isacharunderscore}simps\ min{\isacharunderscore}absorb{\isadigit{2}}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{finally}\isamarkupfalse%
\ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}cmod\ {\isacharparenleft}{\isasymphi}\ n\ t\ {\isacharminus}\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ n{\isacharparenright}{\isacharcircum}n{\isacharparenright}\ {\isasymle}\ \isanewline
\ \ \ \ \ \ \ \ {\isacharparenleft}t\isactrlsup {\isadigit{2}}\ {\isacharslash}\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}{\isacharquery}t{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\ \isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \isacommand{qed}\isamarkupfalse%
\isanewline
\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ S{\isacharunderscore}rv\ {\isacharbrackleft}simp{\isacharcomma}\ measurable{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ random{\isacharunderscore}variable\ borel\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ S\ n\ x\ {\isacharslash}\ sqrt\ {\isacharparenleft}n\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ S{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ measurable\isanewline
\ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isasymAnd}t{\isachardot}\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ {\isasymphi}\ n\ t{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ char\ std{\isacharunderscore}normal{\isacharunderscore}distribution\ t{\isachardoublequoteclose}\isanewline
\ \ \isacommand{proof}\isamarkupfalse%
\ {\isacharminus}\isanewline
\ \ \ \ \isacommand{fix}\isamarkupfalse%
\ t\isanewline
\ \ \ \ \isacommand{let}\isamarkupfalse%
\ {\isacharquery}t\ {\isacharequal}\ {\isachardoublequoteopen}{\isasymlambda}n{\isachardot}\ t\ {\isacharslash}\ sqrt\ {\isacharparenleft}{\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharasterisk}\ n{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ integrable\ {\isasymmu}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ {\isadigit{6}}\ {\isacharasterisk}\ x{\isacharcircum}{\isadigit{2}}{\isacharparenright}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ auto\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isacharasterisk}{\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}n{\isachardot}\ integrable\ {\isasymmu}\ {\isacharparenleft}{\isasymlambda}x{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}t\ {\isacharslash}\ sqrt\ {\isacharparenleft}{\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharasterisk}\ real\ n{\isacharparenright}{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ integrable{\isacharunderscore}bound\ {\isacharbrackleft}OF\ {\isacharasterisk}{\isacharbrackright}{\isacharparenright}\ auto\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isacharasterisk}{\isacharasterisk}{\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymAnd}x{\isachardot}\ {\isacharparenleft}{\isasymlambda}n{\isachardot}\ {\isasymbar}t{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}\ {\isacharslash}\ {\isasymbar}sqrt\ {\isacharparenleft}{\isasymsigma}\isactrlsup {\isadigit{2}}\ {\isacharasterisk}\ real\ n{\isacharparenright}{\isasymbar}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{0}}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ divide{\isacharunderscore}inverse{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}mult{\isacharunderscore}right{\isacharunderscore}zero{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{using}\isamarkupfalse%
\ {\isasymsigma}{\isacharunderscore}pos\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}subst\ abs{\isacharunderscore}of{\isacharunderscore}nonneg{\isacharcomma}\ simp{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ real{\isacharunderscore}sqrt{\isacharunderscore}mult{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}mult{\isacharunderscore}right{\isacharunderscore}zero{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}inverse{\isacharunderscore}{\isadigit{0}}{\isacharunderscore}at{\isacharunderscore}top{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ filterlim{\isacharunderscore}compose\ {\isacharbrackleft}OF\ sqrt{\isacharunderscore}at{\isacharunderscore}top\ filterlim{\isacharunderscore}real{\isacharunderscore}sequentially{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}{\isacharquery}t\ n{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isacharparenleft}LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ {\isadigit{0}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ integral{\isacharunderscore}dominated{\isacharunderscore}convergence\ {\isacharbrackleft}\isakeyword{where}\ w\ {\isacharequal}\ {\isachardoublequoteopen}{\isasymlambda}x{\isachardot}\ {\isadigit{6}}\ {\isacharasterisk}\ x{\isacharcircum}{\isadigit{2}}{\isachardoublequoteclose}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{using}\isamarkupfalse%
\ {\isasymsigma}{\isacharunderscore}pos\ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ AE{\isacharunderscore}I{\isadigit{2}}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}sandwich\ {\isacharbrackleft}OF\ {\isacharunderscore}\ {\isacharunderscore}\ tendsto{\isacharunderscore}const\ {\isacharasterisk}{\isacharasterisk}{\isacharasterisk}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}auto\ intro{\isacharbang}{\isacharcolon}\ always{\isacharunderscore}eventually\ min{\isachardot}cobounded{\isadigit{2}}{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{done}\isamarkupfalse%
\isanewline
\ \ \ \ \isacommand{hence}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}{\isacharquery}t\ n{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{0}}{\isachardoublequoteclose}\ \isacommand{by}\isamarkupfalse%
\ simp\isanewline
\ \ \ \ \isacommand{hence}\isamarkupfalse%
\ main{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ t\isactrlsup {\isadigit{2}}\ {\isacharslash}\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ {\isasymsigma}\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharasterisk}\ {\isacharparenleft}LINT\ x{\isacharbar}{\isasymmu}{\isachardot}\ min\ {\isacharparenleft}{\isadigit{6}}\ {\isacharasterisk}\ x\isactrlsup {\isadigit{2}}{\isacharparenright}\ {\isacharparenleft}{\isasymbar}{\isacharquery}t\ n{\isasymbar}\ {\isacharasterisk}\ {\isasymbar}x{\isasymbar}\ {\isacharcircum}\ {\isadigit{3}}{\isacharparenright}{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ {\isadigit{0}}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}mult{\isacharunderscore}right{\isacharunderscore}zero{\isacharparenright}\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isacharasterisk}{\isacharasterisk}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ {\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ n{\isacharparenright}{\isacharcircum}n{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ exp\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ tendsto{\isacharunderscore}exp{\isacharunderscore}limit{\isacharunderscore}sequentially{\isacharparenright}\isanewline
\ \ \ \ \isacommand{have}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ complex{\isacharunderscore}of{\isacharunderscore}real\ {\isacharparenleft}{\isacharparenleft}{\isadigit{1}}\ {\isacharplus}\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ n{\isacharparenright}{\isacharcircum}n{\isacharparenright}{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ \isanewline
\ \ \ \ \ \ \ \ complex{\isacharunderscore}of{\isacharunderscore}real\ {\isacharparenleft}exp\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ isCont{\isacharunderscore}tendsto{\isacharunderscore}compose\ {\isacharbrackleft}OF\ {\isacharunderscore}\ {\isacharasterisk}{\isacharasterisk}{\isacharbrackright}{\isacharcomma}\ auto{\isacharparenright}\isanewline
\ \ \ \ \isacommand{hence}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ {\isasymphi}\ n\ t{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ complex{\isacharunderscore}of{\isacharunderscore}real\ {\isacharparenleft}exp\ {\isacharparenleft}{\isacharminus}{\isacharparenleft}t{\isacharcircum}{\isadigit{2}}{\isacharparenright}\ {\isacharslash}\ {\isadigit{2}}{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ Lim{\isacharunderscore}transform{\isacharparenright}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}rule\ Lim{\isacharunderscore}null{\isacharunderscore}comparison\ {\isacharbrackleft}OF\ main\ main{\isadigit{2}}{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{thus}\isamarkupfalse%
\ {\isachardoublequoteopen}{\isacharparenleft}{\isasymlambda}n{\isachardot}\ {\isasymphi}\ n\ t{\isacharparenright}\ {\isacharminus}{\isacharminus}{\isacharminus}{\isacharminus}{\isachargreater}\ char\ std{\isacharunderscore}normal{\isacharunderscore}distribution\ t{\isachardoublequoteclose}\isanewline
\ \ \ \ \ \ \isacommand{by}\isamarkupfalse%
\ {\isacharparenleft}subst\ char{\isacharunderscore}std{\isacharunderscore}normal{\isacharunderscore}distribution{\isacharparenright}\isanewline
\ \ \isacommand{qed}\isamarkupfalse%
\isanewline
\ \ \isacommand{thus}\isamarkupfalse%
\ {\isacharquery}thesis\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}intro\ levy{\isacharunderscore}continuity{\isacharparenright}\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}rule\ real{\isacharunderscore}distribution{\isacharunderscore}distr\ {\isacharbrackleft}OF\ S{\isacharunderscore}rv{\isacharbrackright}{\isacharparenright}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ real{\isacharunderscore}distribution{\isacharunderscore}def\ real{\isacharunderscore}distribution{\isacharunderscore}axioms{\isacharunderscore}def\isanewline
\ \ \ \ \isacommand{apply}\isamarkupfalse%
\ {\isacharparenleft}simp\ add{\isacharcolon}\ prob{\isacharunderscore}space{\isacharunderscore}normal{\isacharunderscore}density{\isacharparenright}\isanewline
\ \ \ \ \isacommand{unfolding}\isamarkupfalse%
\ {\isasymphi}{\isacharunderscore}def\ S{\isacharprime}{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
\ {\isacharminus}\isanewline
\isacommand{qed}
\end{isabellebody}

\section{Conclusion: Opportunities for Improvement and Extension}

The version of the central limit theorem we proved is not the most general presented in Billingsley \cite{billingsley}. With some more calculational effort we could formalize the Lindeberg central limit theorem, which relaxes the condition that the random variables being summed be identically distributed (they merely need to not deviate too much in distribution, as made precise by the {\em Lindeberg condition} given on p. 359 of \cite{billingsley}). Even the condition that the variables being summed be independent can be weakened to a condition of weak dependence; Billingsley begins to outline this on p. 363. Both of these are good candidates for further formalization now that the background theory of characteristic functions is in place, with the dependent variables generalization being the more ambitious. Other generalizations include the CLT for random vectors \linebreak (\cite{billingsley}, p. 385) and various versions of the CLT for martingales (\cite{billingsley}, pp. 475--478). Many other refinements and generalizations for the central limit theorem exist in the mathematical literature.

During the formalization process, it was often surprising how far the analysis libraries of Isabelle extend, but at the same time frustrating that the automated tools would get stuck on seemingly trivial matters like determining whether an instance of zero should be interpreted as a real or an extended real. Clearly much more remains to be done to encode basic human analytical intuition into proof procedures.

Our formalization sometimes approximated an informal presentation quite well, but as the reader can perceive looking through the proof scripts we have presented formal proofs still tend to be much longer. This should be remedied as the library is developed further and automated tools are improved.

Our main goal for the central limit formalization project was to improve the Isabelle integration libraries, and this succeeded very well, first with the author and Avigad extending them as needed for proofs, and then with H\"olzl unifying everything as he rewrote the library to accomodate vector-valued integrals, such as integrals of functions of type $\R \rightarrow \C$, natively.

As remarked in section \ref{sec:Si}, calculating with integrals was perhaps the most painful part of the formalization, and it is interesting to speculate how computer algebra systems could help remedy this situation. Perhaps a computer algebra system could be modified to keep track of enough information for Isabelle to reconstruct a proof (including a proof of integrability), or alternatively an interactive proof assistant could be used to verify the correctness of a computer algebra system and then the results obtained by that system could be used freely.

The depth of formalized analysis has increased dramatically in recent years, and we hope that our addition of the central limit theorem is valuable both as a milestone in the formalization of probability and statistics, and for the library infrastructure which was developed to support it (integration, Fourier transforms, cumulative distribution functions, etc.).

\bibliographystyle{plain}
\bibliography{itp}

\end{document}
